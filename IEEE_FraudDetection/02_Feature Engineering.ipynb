{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idf = pd.read_csv(\"data/train_identity.csv\")\n",
    "train_trans = pd.read_csv(\"data/train_transaction.csv\")\n",
    "test_idf = pd.read_csv(\"data/test_identity.csv\")\n",
    "test_trans = pd.read_csv(\"data/test_transaction.csv\")\n",
    "\n",
    "test_trans[\"isFraud\"] = -1\n",
    "\n",
    "train_trans = train_trans.merge(train_idf, on=\"TransactionID\", how=\"left\")\n",
    "test_trans = test_trans.merge(train_idf, on=\"TransactionID\", how=\"left\")\n",
    "\n",
    "train_trans[\"type\"] = \"train\"\n",
    "test_trans[\"type\"] = \"test\"\n",
    "\n",
    "df = pd.concat([train_trans, test_trans], axis=0)\n",
    "\n",
    "start_date = datetime.datetime.strptime(\"2017.12.01\", \"%Y.%m.%d\") # 시작일 설정\n",
    "df[\"time\"] = df[\"TransactionDT\"].apply(\n",
    "    lambda x: datetime.timedelta(seconds=x) + start_date\n",
    ")\n",
    "df['year'] = df['time'].dt.year\n",
    "df['month'] = df['time'].dt.month\n",
    "\n",
    "del train_trans, test_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"ProductCD\", \"card1\"]\n",
    "for col in cat_cols:\n",
    "    df[col + \"_ce\"] = df[col].map(df[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProductCD별로 TransactionAmt의 평균값과 표준편차를 구해 ex에 담음\n",
    "ex = df.groupby(\"ProductCD\").agg({\"TransactionAmt\" : [\"mean\", \"std\"]})\n",
    "ex.reset_index(inplace=True)\n",
    "ex.columns = [\"ProductCD\", \"ProductCD_Amt_mean\", \"ProductCD_Amt_std\"]\n",
    "\n",
    "# 기존 데이터의 ProductCD를 기준으로 join\n",
    "df = df.merge(ex, on=\"ProductCD\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Account_make_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Account Start date를 만드는 함수 생성\n",
    "def account_start_date(val):\n",
    "    if np.isnan(val):\n",
    "        return np.NaN\n",
    "    else:\n",
    "        days = int(str(val).split(\".\")[0])\n",
    "        return pd.Timedelta(str(days) + \" days\")\n",
    "\n",
    "# Account_make_Date 변수 생성\n",
    "for i in [\"D1\", \"D2\", \"D4\", \"D8\", \"D10\", \"D15\"]:\n",
    "    df[\"account_start_day\"] = df[i].apply(account_start_date)\n",
    "    df[\"account_make_date\"] = (df[\"time\"] - df[\"account_start_day\"]).dt.date\n",
    "    df[\"account_make_date_{}\".format(i)] = (\n",
    "        (10000 * pd.to_datetime(df[\"account_make_date\"]).dt.year)\n",
    "        + (100 * pd.to_datetime(df[\"account_make_date\"]).dt.month)\n",
    "        + (1 * pd.to_datetime(df[\"account_make_date\"]).dt.day)\n",
    "    )\n",
    "\n",
    "ex = (\n",
    "    df.groupby([\"card1\", \"account_make_date_D1\", \"ProductCD\"])\n",
    "    .agg({\"TransactionAmt\" : [\"mean\", \"std\"]})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "ex.columns = [\n",
    "    \"card1\",\n",
    "    \"account_make_date_D1\",\n",
    "    \"ProductCD\",\n",
    "    \"D1_card_Product_mean\",\n",
    "    \"D1_card_Product_std\",\n",
    "]\n",
    "\n",
    "df = df.merge(ex, on=[\"card1\", \"account_make_date_D1\", \"ProductCD\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prev/Next click, Amt feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"device_prev_trans\"] = df[\"TransactionDT\"] - df.groupby([\"id_30\", \"id_31\", \"id_33\", \"DeviceType\", \"DeviceInfo\"])[\"TransactionDT\"].shift(1)\n",
    "df[\"device_after_trans\"] = df[\"TransactionDT\"] - df.groupby([\"id_30\", \"id_31\", \"id_33\", \"DeviceType\", \"DeviceInfo\"])[\"TransactionDT\"].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA\n",
    "\n",
    "- 카디널리티가 매우 높은 카테고리형 변수의 피쳐엔지니어링에 활용\n",
    "- 각 카테고리를 토픽에 대한 확률 분포로 변환. 결과적으로 원본 카테고리를 K차원의 연속형 벡터로 변환\n",
    "- 카테고리 간의 잠재적 관계를 포착"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA를 진행할 변수 선정\n",
    "col1 = \"card1\"\n",
    "col2 = \"addr1\"\n",
    "\n",
    "temp = df[[col1, col2]]\n",
    "col1col2_dict = {}\n",
    "\n",
    "# col1을 키로, col2를 값 리스트로 하는 딕셔너리 생성\n",
    "def col1col2(row):\n",
    "    col1col2_dict.setdefault(row[col1], []).append(str(row[col2])) # 키가 없으면 빈 리스트 생성\n",
    "\n",
    "# 각 행에 대해 col1col2 적용\n",
    "temp.apply(lambda row: col1col2(row), axis=1)\n",
    "\n",
    "# 각 card1에 대한 addr1들을 하나의 문자열로 변환\n",
    "col1_keys = list(col1col2_dict.keys())\n",
    "col1col2_dict_as_sentence = [\" \".join(col1col2_dict[c]) for c in col1_keys]\n",
    "\n",
    "# 각 문서(card1) 대해 각 단어(addr1)의 출현 빈도 계산\n",
    "_as_matrix = CountVectorizer().fit_transform(col1col2_dict_as_sentence)\n",
    "\n",
    "# card1을 5개의 토픽에 대한 확률 분포로 표현\n",
    "# topics_of_col1 행렬의 각 행은 하나의 card1에 대한 5개 토픽의 확률 분포\n",
    "topics_of_col1 = LDA(\n",
    "                     n_components=5, # 토픽 수\n",
    "                     n_jobs=-1, \n",
    "                     random_state=0 # 랜덤 시드\n",
    "                     )\n",
    "topics_of_col1 = topics_of_col1.fit_transform(_as_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
