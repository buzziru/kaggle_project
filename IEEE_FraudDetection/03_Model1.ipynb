{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import  GroupKFold\n",
    "import lightgbm as lgb\n",
    "from lightgbm import log_evaluation, early_stopping\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idf = pd.read_csv(\"data/train_identity.csv\")\n",
    "train_trans = pd.read_csv(\"data/train_transaction.csv\")\n",
    "test_idf = pd.read_csv(\"data/test_identity.csv\")\n",
    "test_trans = pd.read_csv(\"data/test_transaction.csv\")\n",
    "\n",
    "test_trans[\"isFraud\"] = -1\n",
    "\n",
    "train_trans = train_trans.merge(train_idf, on=\"TransactionID\", how=\"left\")\n",
    "test_trans = test_trans.merge(train_idf, on=\"TransactionID\", how=\"left\")\n",
    "\n",
    "train_trans[\"type\"] = \"train\"\n",
    "test_trans[\"type\"] = \"test\"\n",
    "\n",
    "df = pd.concat([train_trans, test_trans], axis=0)\n",
    "\n",
    "start_date = datetime.datetime.strptime(\"2017.12.01\", \"%Y.%m.%d\") # 시작일 설정\n",
    "df[\"time\"] = df[\"TransactionDT\"].apply(\n",
    "    lambda x: datetime.timedelta(seconds=x) + start_date\n",
    ")\n",
    "df['year'] = df['time'].dt.year\n",
    "df['month'] = df['time'].dt.month\n",
    "df['DT_M'] = (df['year']-2017)*12 + df['month']\n",
    "\n",
    "del train_trans, test_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"ProductCD\", \"card1\"]\n",
    "for col in cat_cols:\n",
    "    df[col + \"_ce\"] = df[col].map(df[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProductCD별로 TransactionAmt의 평균값과 표준편차를 구해 ex에 담음\n",
    "ex = df.groupby(\"ProductCD\").agg({\"TransactionAmt\" : [\"mean\", \"std\"]})\n",
    "ex.reset_index(inplace=True)\n",
    "ex.columns = [\"ProductCD\", \"ProductCD_Amt_mean\", \"ProductCD_Amt_std\"]\n",
    "\n",
    "# 기존 데이터의 ProductCD를 기준으로 join\n",
    "df = df.merge(ex, on=\"ProductCD\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Account Start date를 만드는 함수 생성\n",
    "def account_start_date(val):\n",
    "    if np.isnan(val):\n",
    "        return np.NaN\n",
    "    else:\n",
    "        days = int(str(val).split(\".\")[0])\n",
    "        return pd.Timedelta(str(days) + \" days\")\n",
    "\n",
    "# Account_make_Date 변수 생성\n",
    "for i in [\"D1\", \"D2\", \"D4\", \"D8\", \"D10\", \"D15\"]:\n",
    "    df[\"account_start_day\"] = df[i].apply(account_start_date)\n",
    "    df[\"account_make_date\"] = (df[\"time\"] - df[\"account_start_day\"]).dt.date\n",
    "    df[\"account_make_date_{}\".format(i)] = (\n",
    "        (10000 * pd.to_datetime(df[\"account_make_date\"]).dt.year)\n",
    "        + (100 * pd.to_datetime(df[\"account_make_date\"]).dt.month)\n",
    "        + (1 * pd.to_datetime(df[\"account_make_date\"]).dt.day)\n",
    "    )\n",
    "\n",
    "ex = (\n",
    "    df.groupby([\"card1\", \"account_make_date_D1\", \"ProductCD\"])\n",
    "    .agg({\"TransactionAmt\" : [\"mean\", \"std\"]})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "ex.columns = [\n",
    "    \"card1\",\n",
    "    \"account_make_date_D1\",\n",
    "    \"ProductCD\",\n",
    "    \"D1_card_Product_mean\",\n",
    "    \"D1_card_Product_std\",\n",
    "]\n",
    "\n",
    "df = df.merge(ex, on=[\"card1\", \"account_make_date_D1\", \"ProductCD\"], how=\"left\")\n",
    "del df[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"device_prev_trans\"] = df[\"TransactionDT\"] - df.groupby([\"id_30\", \"id_31\", \"id_33\", \"DeviceType\", \"DeviceInfo\"])[\"TransactionDT\"].shift(1)\n",
    "df[\"device_after_trans\"] = df[\"TransactionDT\"] - df.groupby([\"id_30\", \"id_31\", \"id_33\", \"DeviceType\", \"DeviceInfo\"])[\"TransactionDT\"].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.loc[df.isFraud != -1].copy()\n",
    "test_df = df.loc[df.isFraud == -1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52201ffc6eb64c199da7038d85863400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/454 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col in tqdm(train_df.columns):\n",
    "    if train_df[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train_df[col].astype(str).values) + list(test_df[col].astype(str).values))\n",
    "        train_df[col] = le.transform(list(train_df[col].astype(str).values))\n",
    "        test_df[col] = le.transform(list(test_df[col].astype(str).values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['TransactionID', 'isFraud','TransactionDT','timeblock','account_start_day', 'date'\n",
    "                                                    , 'year', 'month', 'target', 'day','account_make_date_D11', 'account_make_date_D3', 'account_make_date_D5', 'account_make_date_D4' , 'account_make_date_D8', 'account_make_date_D14', 'account_make_date_D6', 'account_make_date_D12', 'account_make_date_D7'\n",
    "                                                    , 'card_1_2_3_5_nunique', 'card_1_2_3_5_prev_click', 'card_1_2_3_5_next_click', 'card_1_3_TransactionAmt_prev_click', 'card_1_3_TransactionAmt_next_click', 'account_make_date'\n",
    "                                                    , 'poten_card1_nunique_D5', 'poten_card1_nunique_D11','poten_card1_nunique_D6', 'poten_card1_nunique_D3','poten_card1_nunique_D7','poten_card1_nunique_D12','poten_card1_nunique_D8','poten_card1_nunique_D4','poten_card1_nunique_D14'\n",
    "                                                    , 'id_13', 'id_31', 'id_13_count_full', 'id_31_count_full','ProductCD', 'card3', 'card4', 'card5', 'card6', 'M1', 'M2', 'M3',\n",
    "       'M4', 'M5', 'M7', 'M8', 'M9', 'P_emaildomain_bin',\n",
    "       'P_emaildomain_suffix', 'R_emaildomain_bin',\n",
    "       'R_emaildomain_suffix', 'account_make_date',\n",
    "       'account_make_date_D3', 'account_make_date_D4',\n",
    "       'account_make_date_D7', 'account_make_date_D8',\n",
    "       'account_make_date_D11', 'account_make_date_D12',\n",
    "       'account_make_date_D14', 'dayofweek', 'hour', 'card1_addr1',\n",
    "       'card1_ProductCD', 'count_x', 'count_y', 'D15', \"card1_TransactionAmt_mean\",\n",
    "        'card1_addr1hourstd','card1_addr1hourmedian','uid_hour_std','uid2_hour_std','card1_ProductCD_hour_std','card1_addr2_hour_std',\n",
    "        'card1_TransactionAmt_nunique','card2_TransactionAmt_nunique','card3_TransactionAmt_nunique','card5_TransactionAmt_nunique','uid_TransactionAmt_nunique',\n",
    "        'uid_hour_nunique','uid2_hour_nunique','card1_addr2_hour_nunique','card1_ProductCD_hour_nunique','account_make_date_D1','card1_year_month_mean','uid2_D4_mean','uid2_dayofweek_std','DT_M','Transactionhourcount','account_make_date_D1_card1','account_make_date_D2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 491,\n",
    "          'min_child_weight': 0.03454472573214212,\n",
    "          'feature_fraction': 0.3797454081646243,\n",
    "          'bagging_fraction': 0.4181193142567742,\n",
    "          'min_data_in_leaf': 106,\n",
    "          'objective': 'binary',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.006883242363721497,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'auc',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.3899927210061127,\n",
    "          'reg_lambda': 0.6485237330340494,\n",
    "          'random_state': 47,\n",
    "           # GPU 사용 \n",
    "        #   'device': 'gpu',  # CPU를 사용할 경우 'cpu'\n",
    "        #   'gpu_platform_id': 0,  # GPU 플랫폼 ID\n",
    "        #   'gpu_device_id': 0,   # GPU 디바이스 ID\n",
    "        #   'tree_learner': 'gpu'  # GPU 사용을 위한 tree learner 설정\n",
    "\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's auc: 0.983153\tvalid_1's auc: 0.900163\n",
      "[1000]\ttraining's auc: 0.996639\tvalid_1's auc: 0.910807\n",
      "[1500]\ttraining's auc: 0.99931\tvalid_1's auc: 0.912243\n",
      "Early stopping, best iteration is:\n",
      "[1428]\ttraining's auc: 0.999151\tvalid_1's auc: 0.912372\n",
      "Training on fold 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's auc: 0.982431\tvalid_1's auc: 0.933349\n",
      "[1000]\ttraining's auc: 0.996774\tvalid_1's auc: 0.942004\n",
      "Early stopping, best iteration is:\n",
      "[1187]\ttraining's auc: 0.998299\tvalid_1's auc: 0.942592\n",
      "Training on fold 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's auc: 0.980965\tvalid_1's auc: 0.93188\n",
      "[1000]\ttraining's auc: 0.996314\tvalid_1's auc: 0.944439\n",
      "[1500]\ttraining's auc: 0.999233\tvalid_1's auc: 0.946852\n",
      "Early stopping, best iteration is:\n",
      "[1596]\ttraining's auc: 0.999412\tvalid_1's auc: 0.947065\n",
      "Training on fold 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's auc: 0.981557\tvalid_1's auc: 0.931432\n",
      "[1000]\ttraining's auc: 0.996213\tvalid_1's auc: 0.938718\n",
      "[1500]\ttraining's auc: 0.999177\tvalid_1's auc: 0.9393\n",
      "Early stopping, best iteration is:\n",
      "[1407]\ttraining's auc: 0.998938\tvalid_1's auc: 0.939568\n",
      "Training on fold 5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's auc: 0.981049\tvalid_1's auc: 0.945852\n",
      "[1000]\ttraining's auc: 0.996073\tvalid_1's auc: 0.95378\n",
      "Early stopping, best iteration is:\n",
      "[1315]\ttraining's auc: 0.998517\tvalid_1's auc: 0.954425\n",
      "Training on fold 6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's auc: 0.981072\tvalid_1's auc: 0.941082\n",
      "[1000]\ttraining's auc: 0.996039\tvalid_1's auc: 0.953123\n",
      "[1500]\ttraining's auc: 0.999115\tvalid_1's auc: 0.954703\n",
      "Early stopping, best iteration is:\n",
      "[1788]\ttraining's auc: 0.999609\tvalid_1's auc: 0.955059\n",
      "Mean AUC :  0.9418469328560973\n"
     ]
    }
   ],
   "source": [
    "NFOLD = 6\n",
    "folds = GroupKFold(n_splits=NFOLD)\n",
    "\n",
    "X = train_df[features]\n",
    "y = train_df[\"isFraud\"]\n",
    "test = test_df[features]\n",
    "\n",
    "split_groups = train_df[\"DT_M\"] # 월 단위를 그룹으로 선정\n",
    "\n",
    "aucs = list() # validation auc 점수를 저장\n",
    "preds = np.zeros(len(test))\n",
    "\n",
    "for fold, (trn_idx, test_idx) in enumerate(folds.split(X, y, groups=split_groups)):\n",
    "    print(\"Training on fold {}\".format(fold + 1))\n",
    "\n",
    "    trn_data = lgb.Dataset(X.iloc[trn_idx], label=y.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(X.iloc[test_idx], label=y.iloc[test_idx])\n",
    "    \n",
    "    # 콜백 함수 설정\n",
    "    callbacks = [\n",
    "        log_evaluation(period=500),\n",
    "        early_stopping(stopping_rounds=100)\n",
    "    ]\n",
    "    clf = lgb.train(\n",
    "        params,\n",
    "        trn_data,\n",
    "        10000,\n",
    "        valid_sets=[trn_data, val_data],\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    preds += clf.predict(test) / NFOLD\n",
    "    aucs.append(clf.best_score[\"valid_1\"][\"auc\"])\n",
    "\n",
    "print(\"Mean AUC : \", np.mean(aucs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cpu 사용 학습 : 56분 14초\n",
    "    - Mean AUC : 0.9418469328560973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/model_lightgbm_cpu.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'model/model_lightgbm_cpu.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
