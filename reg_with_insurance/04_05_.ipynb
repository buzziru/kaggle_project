{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 952 ms, sys: 622 ms, total: 1.57 s\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import PowerTransformer, OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import optuna\n",
    "from xgboost import XGBRegressor, callback\n",
    "from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=2024\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.7 s, sys: 2.02 s, total: 12.8 s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def load_data():    \n",
    "    train = pd.read_csv('data/train.csv')\n",
    "    test = pd.read_csv('data/test.csv')    \n",
    "    all_df = pd.concat([train, test], sort=False).reset_index(drop=True)\n",
    "    return train, test, all_df\n",
    "\n",
    "def fill_nan_values(df):\n",
    "    num_cols = [col for col in df.select_dtypes(exclude='object').columns if col != 'Premium Amount']\n",
    "    cat_cols = df.select_dtypes(include='object').columns\n",
    "    for col in num_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].fillna('missing')\n",
    "    return df\n",
    "    \n",
    "def skewed(df, all_df):\n",
    "    pt = PowerTransformer(method='yeo-johnson')\n",
    "    pt.fit(df[['Annual Income']])\n",
    "    all_df['transformed_Annual_Income'] = pt.transform(all_df[['Annual Income']])\n",
    "    # all_df['log_Annual_Income'] = np.log1p(all_df['Annual Income'])\n",
    "    return all_df\n",
    "    \n",
    "def date(df):\n",
    "    df['Policy Start Date'] = pd.to_datetime(df['Policy Start Date'])\n",
    "    df['Year'] = df['Policy Start Date'].dt.year\n",
    "    df['Day'] = df['Policy Start Date'].dt.day\n",
    "    df['Month'] = df['Policy Start Date'].dt.month\n",
    "    df['Month_name'] = df['Policy Start Date'].dt.month_name()\n",
    "    df['Day_of_week'] = df['Policy Start Date'].dt.day_name()\n",
    "    df['Week'] = df['Policy Start Date'].dt.isocalendar().week\n",
    "    df['Year_sin'] = np.sin(2 * np.pi * df['Year'])\n",
    "    df['Year_cos'] = np.cos(2 * np.pi * df['Year'])\n",
    "    min_year = df['Year'].min()\n",
    "    max_year = df['Year'].max()\n",
    "    df['Year_sin'] = np.sin(2 * np.pi * (df['Year'] - min_year) / (max_year - min_year))\n",
    "    df['Year_cos'] = np.cos(2 * np.pi * (df['Year'] - min_year) / (max_year - min_year))\n",
    "    df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12) \n",
    "    df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)\n",
    "    df['Day_sin'] = np.sin(2 * np.pi * df['Day'] / 31)  \n",
    "    df['Day_cos'] = np.cos(2 * np.pi * df['Day'] / 31)\n",
    "    df['Group']=(df['Year']-2020)*48+df['Month']*4+df['Day']//7    \n",
    "    df.drop('Policy Start Date', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_nan_cols(df):\n",
    "    nan_cols = ['Marital Status', 'Customer Feedback', 'Health Score', 'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration']\n",
    "    for col in nan_cols:\n",
    "        col_name = col + '_NA'\n",
    "        df[col_name] = df[col].isnull().astype(int)\n",
    "    return df\n",
    "\n",
    "def get_encoding(df):\n",
    "    def encode_ordinal(df):\n",
    "        educ = {\"High School\":0, \"Bachelor's\":1, \"Master's\":2, \"PhD\":3}\n",
    "        policy = {'Basic':0, 'Comprehensive':1, 'Premium':2}\n",
    "        exerc = {'Rarely':0, 'Daily':1, 'Weekly':2, 'Monthly': 3}\n",
    "        # feedback = {'Poor':0, 'Average':1, 'Good':2}\n",
    "\n",
    "        df['Education Level'] = df['Education Level'].map(educ)\n",
    "        df['Policy Type'] = df['Policy Type'].map(policy)\n",
    "        df['Exercise Frequency'] = df['Exercise Frequency'].map(exerc)\n",
    "        # df['Customer Feedback'] = df['Customer Feedback'].map(feedback)\n",
    "        df['Gender'] = df['Gender'].map({'Male':0, 'Female':1})\n",
    "        df['Smoking Status'] = df['Smoking Status'].map({'Yes':1, 'No':0})\n",
    "        return df\n",
    "    \n",
    "    def target_encoder(df):\n",
    "        train = df[~df['Premium Amount'].isnull()]\n",
    "        test = df[df['Premium Amount'].isnull()]\n",
    "        encoder = TargetEncoder()\n",
    "        categorical_cols = ['Marital Status', 'Customer Feedback']\n",
    "        train[categorical_cols] = encoder.fit_transform(train[categorical_cols], train['Premium Amount'])\n",
    "        test[categorical_cols] = encoder.transform(test[categorical_cols])\n",
    "        df = pd.concat([train, test], sort=False).reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def one_hot_dummies(df, categorical):\n",
    "        oh = pd.get_dummies(df[categorical])\n",
    "        df = df.drop(categorical, axis=1)\n",
    "        return pd.concat([df, oh], axis=1)\n",
    "        return df\n",
    "\n",
    "    df = encode_ordinal(df)\n",
    "    df = target_encoder(df)\n",
    "\n",
    "    categorical_features = df.select_dtypes(include='object').columns\n",
    "    df = one_hot_dummies(df, categorical_features)\n",
    "    return df\n",
    "\n",
    "def add_new_features(df):\n",
    "    df['Income_Dependents Ratio'] = df['Annual Income'] / (df['Number of Dependents'].fillna(0) + 1)\n",
    "    df['Income_per_Dependent'] = df['Annual Income'] / (df['Number of Dependents'] + 1)\n",
    "    df['CreditScore_InsuranceDuration'] = df['Credit Score'] * df['Insurance Duration']\n",
    "    df['Health_Risk_Score'] = df['Smoking Status'].apply(lambda x: 1 if x == 'Smoker' else 0) + \\\n",
    "                                df['Exercise Frequency'].apply(lambda x: 1 if x == 'Low' else (0.5 if x == 'Medium' else 0)) + \\\n",
    "                                (100 - df['Health Score']) / 20\n",
    "    df['Credit_Health_Score'] = df['Credit Score'] * df['Health Score']\n",
    "    df['Health_Age_Interaction'] = df['Health Score'] * df['Age']\n",
    "\n",
    "    df['contract_length'] = pd.cut(\n",
    "        df[\"Insurance Duration\"].fillna(99),  \n",
    "        bins=[-float('inf'), 1, 3, float('inf')],  \n",
    "        labels=[0, 1, 2]  \n",
    "    ).astype(int)\n",
    "\n",
    "    df['Age_Income'] = df['Age'] * df['Annual Income']\n",
    "\n",
    "    # df[\"Annual_Income_Health_Score_Ratio\"] = df[\"Health Score\"] / df[\"Annual Income\"]\n",
    "    # df[\"Annual_Income_Age_Ratio\"] = df[\"Annual Income\"] / df[\"Age\"]\n",
    "    # df[\"Credit_Age\"] = df[\"Credit Score\"] / df[\"Age\"]\n",
    "    # df[\"Vehicle_Age_Insurance_Duration\"] = df[\"Vehicle Age\"] / df[\"Insurance Duration\"]\n",
    "    return df\n",
    "\n",
    "def prep():\n",
    "    train, test, all_df = load_data()\n",
    "\n",
    "    all_df = skewed(train, all_df)\n",
    "    all_df = date(all_df)\n",
    "    all_df = get_nan_cols(all_df)\n",
    "    # all_df = fill_nan_values(all_df)\n",
    "    all_df = get_encoding(all_df)\n",
    "    all_df = add_new_features(all_df)\n",
    "\n",
    "    del all_df['Annual Income']\n",
    "    \n",
    "    train = all_df[~all_df['Premium Amount'].isnull()]\n",
    "    test = all_df[all_df['Premium Amount'].isnull()]\n",
    "    train.drop('id', axis=1, inplace=True)\n",
    "    test.drop(['id', 'Premium Amount'], axis=1, inplace=True)\n",
    "    return train, test, all_df\n",
    "\n",
    "def prep_nan():\n",
    "    train, test, all_df = load_data()\n",
    "\n",
    "    all_df = skewed(train, all_df)\n",
    "    all_df = date(all_df)\n",
    "    all_df = get_nan_cols(all_df)\n",
    "    all_df = fill_nan_values(all_df)\n",
    "    all_df = get_encoding(all_df)\n",
    "    all_df = add_new_features(all_df)\n",
    "\n",
    "    del all_df['Annual Income']\n",
    "    \n",
    "    train = all_df[~all_df['Premium Amount'].isnull()]\n",
    "    test = all_df[all_df['Premium Amount'].isnull()]\n",
    "    train.drop('id', axis=1, inplace=True)\n",
    "    test.drop(['id', 'Premium Amount'], axis=1, inplace=True)\n",
    "    return train, test, all_df\n",
    "\n",
    "train, test, all_df = prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nan, test_nan, all_df_nan = prep_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>Policy Type</th>\n",
       "      <th>Previous Claims</th>\n",
       "      <th>Vehicle Age</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Insurance Duration</th>\n",
       "      <th>Customer Feedback</th>\n",
       "      <th>Smoking Status</th>\n",
       "      <th>Exercise Frequency</th>\n",
       "      <th>Premium Amount</th>\n",
       "      <th>transformed_Annual_Income</th>\n",
       "      <th>Year</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Year_sin</th>\n",
       "      <th>Year_cos</th>\n",
       "      <th>Month_sin</th>\n",
       "      <th>Month_cos</th>\n",
       "      <th>Day_sin</th>\n",
       "      <th>Day_cos</th>\n",
       "      <th>Group</th>\n",
       "      <th>Marital Status_NA</th>\n",
       "      <th>Customer Feedback_NA</th>\n",
       "      <th>Health Score_NA</th>\n",
       "      <th>Previous Claims_NA</th>\n",
       "      <th>Vehicle Age_NA</th>\n",
       "      <th>Credit Score_NA</th>\n",
       "      <th>Insurance Duration_NA</th>\n",
       "      <th>Occupation_Employed</th>\n",
       "      <th>Occupation_Self-Employed</th>\n",
       "      <th>Occupation_Unemployed</th>\n",
       "      <th>Location_Rural</th>\n",
       "      <th>Location_Suburban</th>\n",
       "      <th>Location_Urban</th>\n",
       "      <th>Property Type_Apartment</th>\n",
       "      <th>Property Type_Condo</th>\n",
       "      <th>Property Type_House</th>\n",
       "      <th>Month_name_April</th>\n",
       "      <th>Month_name_August</th>\n",
       "      <th>Month_name_December</th>\n",
       "      <th>Month_name_February</th>\n",
       "      <th>Month_name_January</th>\n",
       "      <th>Month_name_July</th>\n",
       "      <th>Month_name_June</th>\n",
       "      <th>Month_name_March</th>\n",
       "      <th>Month_name_May</th>\n",
       "      <th>Month_name_November</th>\n",
       "      <th>Month_name_October</th>\n",
       "      <th>Month_name_September</th>\n",
       "      <th>Day_of_week_Friday</th>\n",
       "      <th>Day_of_week_Monday</th>\n",
       "      <th>Day_of_week_Saturday</th>\n",
       "      <th>Day_of_week_Sunday</th>\n",
       "      <th>Day_of_week_Thursday</th>\n",
       "      <th>Day_of_week_Tuesday</th>\n",
       "      <th>Day_of_week_Wednesday</th>\n",
       "      <th>Income_Dependents Ratio</th>\n",
       "      <th>Income_per_Dependent</th>\n",
       "      <th>CreditScore_InsuranceDuration</th>\n",
       "      <th>Health_Risk_Score</th>\n",
       "      <th>Credit_Health_Score</th>\n",
       "      <th>Health_Age_Interaction</th>\n",
       "      <th>contract_length</th>\n",
       "      <th>Age_Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1099.844389</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.598761</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1098.892745</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2869.0</td>\n",
       "      <td>-0.596487</td>\n",
       "      <td>2023</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>-9.510565e-01</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.998717</td>\n",
       "      <td>-0.050649</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5024.5</td>\n",
       "      <td>5024.5</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>3.870062</td>\n",
       "      <td>8406.738970</td>\n",
       "      <td>429.376453</td>\n",
       "      <td>2</td>\n",
       "      <td>190931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1100.625116</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>15.569731</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1094.350977</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1483.0</td>\n",
       "      <td>0.336563</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>-9.510565e-01</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>-0.758758</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7919.5</td>\n",
       "      <td>7919.5</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>4.221513</td>\n",
       "      <td>10805.393307</td>\n",
       "      <td>607.219509</td>\n",
       "      <td>1</td>\n",
       "      <td>1235442.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1100.625116</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.177549</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1096.284299</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.140781</td>\n",
       "      <td>2023</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>-9.510565e-01</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.979530</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6400.5</td>\n",
       "      <td>6400.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.641123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1085.083634</td>\n",
       "      <td>1</td>\n",
       "      <td>588846.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1099.844389</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.938144</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1098.892745</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>765.0</td>\n",
       "      <td>2.088459</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>-0.758758</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>47285.0</td>\n",
       "      <td>47285.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>4.453093</td>\n",
       "      <td>4014.298906</td>\n",
       "      <td>229.701027</td>\n",
       "      <td>0</td>\n",
       "      <td>2978955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1101.735535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.376094</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1098.892745</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>0.555622</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>5.877853e-01</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.979530</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>19825.5</td>\n",
       "      <td>19825.5</td>\n",
       "      <td>2392.0</td>\n",
       "      <td>3.981195</td>\n",
       "      <td>12184.903989</td>\n",
       "      <td>427.897966</td>\n",
       "      <td>2</td>\n",
       "      <td>832671.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender  Marital Status  Number of Dependents  Education Level  \\\n",
       "0  19.0       1     1099.844389                   1.0                1   \n",
       "1  39.0       1     1100.625116                   3.0                2   \n",
       "2  23.0       0     1100.625116                   3.0                0   \n",
       "3  21.0       0     1099.844389                   2.0                1   \n",
       "4  21.0       0     1101.735535                   1.0                1   \n",
       "\n",
       "   Health Score  Policy Type  Previous Claims  Vehicle Age  Credit Score  \\\n",
       "0     22.598761            2              2.0         17.0         372.0   \n",
       "1     15.569731            1              1.0         12.0         694.0   \n",
       "2     47.177549            2              1.0         14.0           NaN   \n",
       "3     10.938144            0              1.0          0.0         367.0   \n",
       "4     20.376094            2              0.0          8.0         598.0   \n",
       "\n",
       "   Insurance Duration  Customer Feedback  Smoking Status  Exercise Frequency  \\\n",
       "0                 5.0        1098.892745               0                   2   \n",
       "1                 2.0        1094.350977               1                   3   \n",
       "2                 3.0        1096.284299               1                   2   \n",
       "3                 1.0        1098.892745               1                   1   \n",
       "4                 4.0        1098.892745               1                   2   \n",
       "\n",
       "   Premium Amount  transformed_Annual_Income  Year  Day  Month  Week  \\\n",
       "0          2869.0                  -0.596487  2023   23     12    51   \n",
       "1          1483.0                   0.336563  2023   12      6    24   \n",
       "2           567.0                   0.140781  2023   30      9    39   \n",
       "3           765.0                   2.088459  2024   12      6    24   \n",
       "4          2022.0                   0.555622  2021    1     12    48   \n",
       "\n",
       "       Year_sin  Year_cos     Month_sin     Month_cos   Day_sin   Day_cos  \\\n",
       "0 -9.510565e-01  0.309017 -2.449294e-16  1.000000e+00 -0.998717 -0.050649   \n",
       "1 -9.510565e-01  0.309017  1.224647e-16 -1.000000e+00  0.651372 -0.758758   \n",
       "2 -9.510565e-01  0.309017 -1.000000e+00 -1.836970e-16 -0.201299  0.979530   \n",
       "3 -2.449294e-16  1.000000  1.224647e-16 -1.000000e+00  0.651372 -0.758758   \n",
       "4  5.877853e-01 -0.809017 -2.449294e-16  1.000000e+00  0.201299  0.979530   \n",
       "\n",
       "   Group  Marital Status_NA  Customer Feedback_NA  Health Score_NA  \\\n",
       "0    195                  0                     0                0   \n",
       "1    169                  0                     0                0   \n",
       "2    184                  0                     0                0   \n",
       "3    217                  0                     0                0   \n",
       "4     96                  0                     0                0   \n",
       "\n",
       "   Previous Claims_NA  Vehicle Age_NA  Credit Score_NA  Insurance Duration_NA  \\\n",
       "0                   0               0                0                      0   \n",
       "1                   0               0                0                      0   \n",
       "2                   0               0                1                      0   \n",
       "3                   0               0                0                      0   \n",
       "4                   0               0                0                      0   \n",
       "\n",
       "   Occupation_Employed  Occupation_Self-Employed  Occupation_Unemployed  \\\n",
       "0                False                      True                  False   \n",
       "1                False                     False                  False   \n",
       "2                False                      True                  False   \n",
       "3                False                     False                  False   \n",
       "4                False                      True                  False   \n",
       "\n",
       "   Location_Rural  Location_Suburban  Location_Urban  Property Type_Apartment  \\\n",
       "0           False              False            True                    False   \n",
       "1            True              False           False                    False   \n",
       "2           False               True           False                    False   \n",
       "3            True              False           False                     True   \n",
       "4            True              False           False                    False   \n",
       "\n",
       "   Property Type_Condo  Property Type_House  Month_name_April  \\\n",
       "0                False                 True             False   \n",
       "1                False                 True             False   \n",
       "2                False                 True             False   \n",
       "3                False                False             False   \n",
       "4                False                 True             False   \n",
       "\n",
       "   Month_name_August  Month_name_December  Month_name_February  \\\n",
       "0              False                 True                False   \n",
       "1              False                False                False   \n",
       "2              False                False                False   \n",
       "3              False                False                False   \n",
       "4              False                 True                False   \n",
       "\n",
       "   Month_name_January  Month_name_July  Month_name_June  Month_name_March  \\\n",
       "0               False            False            False             False   \n",
       "1               False            False             True             False   \n",
       "2               False            False            False             False   \n",
       "3               False            False             True             False   \n",
       "4               False            False            False             False   \n",
       "\n",
       "   Month_name_May  Month_name_November  Month_name_October  \\\n",
       "0           False                False               False   \n",
       "1           False                False               False   \n",
       "2           False                False               False   \n",
       "3           False                False               False   \n",
       "4           False                False               False   \n",
       "\n",
       "   Month_name_September  Day_of_week_Friday  Day_of_week_Monday  \\\n",
       "0                 False               False               False   \n",
       "1                 False               False                True   \n",
       "2                  True               False               False   \n",
       "3                 False               False               False   \n",
       "4                 False               False               False   \n",
       "\n",
       "   Day_of_week_Saturday  Day_of_week_Sunday  Day_of_week_Thursday  \\\n",
       "0                  True               False                 False   \n",
       "1                 False               False                 False   \n",
       "2                  True               False                 False   \n",
       "3                 False               False                 False   \n",
       "4                 False               False                 False   \n",
       "\n",
       "   Day_of_week_Tuesday  Day_of_week_Wednesday  Income_Dependents Ratio  \\\n",
       "0                False                  False                   5024.5   \n",
       "1                False                  False                   7919.5   \n",
       "2                False                  False                   6400.5   \n",
       "3                False                   True                  47285.0   \n",
       "4                False                   True                  19825.5   \n",
       "\n",
       "   Income_per_Dependent  CreditScore_InsuranceDuration  Health_Risk_Score  \\\n",
       "0                5024.5                         1860.0           3.870062   \n",
       "1                7919.5                         1388.0           4.221513   \n",
       "2                6400.5                            NaN           2.641123   \n",
       "3               47285.0                          367.0           4.453093   \n",
       "4               19825.5                         2392.0           3.981195   \n",
       "\n",
       "   Credit_Health_Score  Health_Age_Interaction  contract_length  Age_Income  \n",
       "0          8406.738970              429.376453                2    190931.0  \n",
       "1         10805.393307              607.219509                1   1235442.0  \n",
       "2                  NaN             1085.083634                1    588846.0  \n",
       "3          4014.298906              229.701027                0   2978955.0  \n",
       "4         12184.903989              427.897966                2    832671.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200000, 70), (800000, 69), (1200000, 71), (800000, 70))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, train_nan.shape, test_nan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pred, OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 149 ms, sys: 74 ms, total: 223 ms\n",
      "Wall time: 771 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = np.load('./data/pred_oof_data.npz')\n",
    "\n",
    "lgbm_OOF = data['lgbm_OOF']\n",
    "xgb_OOF = data['xgb_OOF']\n",
    "cat_OOF = data['cat_OOF']\n",
    "et_OOF = data['et_OOF']\n",
    "\n",
    "lgbm_preds = data['lgbm_preds']\n",
    "xgb_preds = data['xgb_preds']\n",
    "cat_preds = data['cat_preds']\n",
    "et_preds = data['et_preds']\n",
    "\n",
    "OOF_std = data['OOF_std']\n",
    "OOF_mean = data['OOF_mean']\n",
    "OOF_min = data['OOF_min']\n",
    "OOF_max = data['OOF_max']\n",
    "pred_std = data['pred_std']\n",
    "pred_mean = data['pred_mean']\n",
    "pred_min = data['pred_min']\n",
    "pred_max = data['pred_max']\n",
    "\n",
    "stacked_train = np.column_stack((lgbm_OOF, xgb_OOF, cat_OOF, et_OOF, train['transformed_Annual_Income'], train['Credit Score'], OOF_mean, OOF_min, OOF_max))\n",
    "stacked_test = np.column_stack((lgbm_preds, xgb_preds, cat_preds, et_preds, test['transformed_Annual_Income'], test['Credit Score'], pred_mean, pred_min, pred_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Premium Amount']\n",
    "y_log = np.log1p(y_train)\n",
    "y_log_nan = np.log1p(train_nan['Premium Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 23:30:16,270] A new study created in memory with name: no-name-dd6c3557-4723-418a-972c-1a630d7b4734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.0461\tvalid_0's l2: 1.09433\n",
      "[200]\tvalid_0's rmse: 1.046\tvalid_0's l2: 1.09411\n",
      "[300]\tvalid_0's rmse: 1.04594\tvalid_0's l2: 1.09398\n",
      "[400]\tvalid_0's rmse: 1.04592\tvalid_0's l2: 1.09395\n",
      "Early stopping, best iteration is:\n",
      "[380]\tvalid_0's rmse: 1.04591\tvalid_0's l2: 1.09394\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.0452\tvalid_0's l2: 1.09245\n",
      "[200]\tvalid_0's rmse: 1.04516\tvalid_0's l2: 1.09236\n",
      "[300]\tvalid_0's rmse: 1.04512\tvalid_0's l2: 1.09228\n",
      "[400]\tvalid_0's rmse: 1.04512\tvalid_0's l2: 1.09227\n",
      "Early stopping, best iteration is:\n",
      "[316]\tvalid_0's rmse: 1.04511\tvalid_0's l2: 1.09225\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04622\tvalid_0's l2: 1.09458\n",
      "[200]\tvalid_0's rmse: 1.04616\tvalid_0's l2: 1.09445\n",
      "[300]\tvalid_0's rmse: 1.04612\tvalid_0's l2: 1.09437\n",
      "[400]\tvalid_0's rmse: 1.04612\tvalid_0's l2: 1.09437\n",
      "Early stopping, best iteration is:\n",
      "[358]\tvalid_0's rmse: 1.04611\tvalid_0's l2: 1.09434\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04397\tvalid_0's l2: 1.08987\n",
      "[200]\tvalid_0's rmse: 1.04391\tvalid_0's l2: 1.08974\n",
      "[300]\tvalid_0's rmse: 1.04384\tvalid_0's l2: 1.08961\n",
      "[400]\tvalid_0's rmse: 1.0438\tvalid_0's l2: 1.08953\n",
      "[500]\tvalid_0's rmse: 1.0438\tvalid_0's l2: 1.08953\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[424]\tvalid_0's rmse: 1.0438\tvalid_0's l2: 1.08952\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04566\tvalid_0's l2: 1.0934\n",
      "[200]\tvalid_0's rmse: 1.04554\tvalid_0's l2: 1.09316\n",
      "[300]\tvalid_0's rmse: 1.04551\tvalid_0's l2: 1.09308\n",
      "[400]\tvalid_0's rmse: 1.04548\tvalid_0's l2: 1.09303\n",
      "[500]\tvalid_0's rmse: 1.04545\tvalid_0's l2: 1.09296\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.04545\tvalid_0's l2: 1.09296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 23:30:59,314] Trial 0 finished with value: 1.0452745888499515 and parameters: {'num_leaves': 21, 'max_depth': 6, 'learning_rate': 0.03321866147099672, 'lambda_l1': 7.993292420985183, 'lambda_l2': 1.2340279606636548, 'min_child_samples': 11, 'colsample_bytree': 0.50871254182523, 'subsample': 0.6299264218662403}. Best is trial 0 with value: 1.0452745888499515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04703\tvalid_0's l2: 1.09627\n",
      "[200]\tvalid_0's rmse: 1.04605\tvalid_0's l2: 1.09422\n",
      "[300]\tvalid_0's rmse: 1.046\tvalid_0's l2: 1.09412\n",
      "[400]\tvalid_0's rmse: 1.04596\tvalid_0's l2: 1.09403\n",
      "[500]\tvalid_0's rmse: 1.04595\tvalid_0's l2: 1.09401\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[470]\tvalid_0's rmse: 1.04595\tvalid_0's l2: 1.094\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04601\tvalid_0's l2: 1.09413\n",
      "[200]\tvalid_0's rmse: 1.04516\tvalid_0's l2: 1.09236\n",
      "[300]\tvalid_0's rmse: 1.04515\tvalid_0's l2: 1.09233\n",
      "[400]\tvalid_0's rmse: 1.04512\tvalid_0's l2: 1.09227\n",
      "[500]\tvalid_0's rmse: 1.04509\tvalid_0's l2: 1.09222\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.04509\tvalid_0's l2: 1.09222\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.047\tvalid_0's l2: 1.0962\n",
      "[200]\tvalid_0's rmse: 1.04615\tvalid_0's l2: 1.09443\n",
      "[300]\tvalid_0's rmse: 1.04613\tvalid_0's l2: 1.0944\n",
      "[400]\tvalid_0's rmse: 1.04612\tvalid_0's l2: 1.09437\n",
      "[500]\tvalid_0's rmse: 1.04612\tvalid_0's l2: 1.09436\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[410]\tvalid_0's rmse: 1.04611\tvalid_0's l2: 1.09434\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04488\tvalid_0's l2: 1.09176\n",
      "[200]\tvalid_0's rmse: 1.04389\tvalid_0's l2: 1.08971\n",
      "[300]\tvalid_0's rmse: 1.04389\tvalid_0's l2: 1.0897\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's rmse: 1.04387\tvalid_0's l2: 1.08967\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.0466\tvalid_0's l2: 1.09538\n",
      "[200]\tvalid_0's rmse: 1.04559\tvalid_0's l2: 1.09327\n",
      "[300]\tvalid_0's rmse: 1.04554\tvalid_0's l2: 1.09316\n",
      "[400]\tvalid_0's rmse: 1.04551\tvalid_0's l2: 1.09309\n",
      "[500]\tvalid_0's rmse: 1.04547\tvalid_0's l2: 1.09301\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[497]\tvalid_0's rmse: 1.04547\tvalid_0's l2: 1.09301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 23:31:45,977] Trial 1 finished with value: 1.0452985395470424 and parameters: {'num_leaves': 23, 'max_depth': 5, 'learning_rate': 0.02028740718282379, 'lambda_l1': 9.849549260809972, 'lambda_l2': 2.2486639612006325, 'min_child_samples': 12, 'colsample_bytree': 0.5272737450810651, 'subsample': 0.5275106764780151}. Best is trial 0 with value: 1.0452745888499515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04632\tvalid_0's l2: 1.09478\n",
      "[200]\tvalid_0's rmse: 1.04603\tvalid_0's l2: 1.09417\n",
      "[300]\tvalid_0's rmse: 1.04597\tvalid_0's l2: 1.09406\n",
      "[400]\tvalid_0's rmse: 1.04594\tvalid_0's l2: 1.094\n",
      "Early stopping, best iteration is:\n",
      "[376]\tvalid_0's rmse: 1.04594\tvalid_0's l2: 1.09399\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04539\tvalid_0's l2: 1.09284\n",
      "[200]\tvalid_0's rmse: 1.04516\tvalid_0's l2: 1.09237\n",
      "[300]\tvalid_0's rmse: 1.04513\tvalid_0's l2: 1.09229\n",
      "[400]\tvalid_0's rmse: 1.0451\tvalid_0's l2: 1.09224\n",
      "[500]\tvalid_0's rmse: 1.0451\tvalid_0's l2: 1.09223\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[435]\tvalid_0's rmse: 1.0451\tvalid_0's l2: 1.09223\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04637\tvalid_0's l2: 1.09488\n",
      "[200]\tvalid_0's rmse: 1.04616\tvalid_0's l2: 1.09446\n",
      "[300]\tvalid_0's rmse: 1.04614\tvalid_0's l2: 1.09441\n",
      "[400]\tvalid_0's rmse: 1.04613\tvalid_0's l2: 1.09439\n",
      "[500]\tvalid_0's rmse: 1.04612\tvalid_0's l2: 1.09436\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[497]\tvalid_0's rmse: 1.04612\tvalid_0's l2: 1.09436\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04414\tvalid_0's l2: 1.09024\n",
      "[200]\tvalid_0's rmse: 1.04388\tvalid_0's l2: 1.08969\n",
      "[300]\tvalid_0's rmse: 1.04386\tvalid_0's l2: 1.08964\n",
      "[400]\tvalid_0's rmse: 1.04382\tvalid_0's l2: 1.08956\n",
      "[500]\tvalid_0's rmse: 1.0438\tvalid_0's l2: 1.08953\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.0438\tvalid_0's l2: 1.08953\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04587\tvalid_0's l2: 1.09383\n",
      "[200]\tvalid_0's rmse: 1.04555\tvalid_0's l2: 1.09317\n",
      "[300]\tvalid_0's rmse: 1.0455\tvalid_0's l2: 1.09306\n",
      "[400]\tvalid_0's rmse: 1.04545\tvalid_0's l2: 1.09297\n",
      "[500]\tvalid_0's rmse: 1.04543\tvalid_0's l2: 1.09292\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\tvalid_0's rmse: 1.04543\tvalid_0's l2: 1.09292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 23:32:30,183] Trial 2 finished with value: 1.0452764922001276 and parameters: {'num_leaves': 20, 'max_depth': 5, 'learning_rate': 0.026981022415762914, 'lambda_l1': 6.456145700990209, 'lambda_l2': 1.9177793420835691, 'min_child_samples': 11, 'colsample_bytree': 0.5438216972802827, 'subsample': 0.5549542764940538}. Best is trial 0 with value: 1.0452745888499515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.0466\tvalid_0's l2: 1.09537\n",
      "[200]\tvalid_0's rmse: 1.04602\tvalid_0's l2: 1.09415\n",
      "[300]\tvalid_0's rmse: 1.046\tvalid_0's l2: 1.09411\n",
      "[400]\tvalid_0's rmse: 1.04594\tvalid_0's l2: 1.09399\n",
      "[500]\tvalid_0's rmse: 1.04591\tvalid_0's l2: 1.09393\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[485]\tvalid_0's rmse: 1.04591\tvalid_0's l2: 1.09393\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04562\tvalid_0's l2: 1.09333\n",
      "[200]\tvalid_0's rmse: 1.04515\tvalid_0's l2: 1.09233\n",
      "[300]\tvalid_0's rmse: 1.04514\tvalid_0's l2: 1.09231\n",
      "[400]\tvalid_0's rmse: 1.04511\tvalid_0's l2: 1.09226\n",
      "[500]\tvalid_0's rmse: 1.0451\tvalid_0's l2: 1.09223\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[462]\tvalid_0's rmse: 1.0451\tvalid_0's l2: 1.09223\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04662\tvalid_0's l2: 1.09542\n",
      "[200]\tvalid_0's rmse: 1.04616\tvalid_0's l2: 1.09444\n",
      "[300]\tvalid_0's rmse: 1.04615\tvalid_0's l2: 1.09443\n",
      "[400]\tvalid_0's rmse: 1.04613\tvalid_0's l2: 1.09439\n",
      "[500]\tvalid_0's rmse: 1.04613\tvalid_0's l2: 1.09439\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[466]\tvalid_0's rmse: 1.04612\tvalid_0's l2: 1.09438\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04448\tvalid_0's l2: 1.09093\n",
      "[200]\tvalid_0's rmse: 1.0439\tvalid_0's l2: 1.08973\n",
      "[300]\tvalid_0's rmse: 1.04391\tvalid_0's l2: 1.08974\n",
      "[400]\tvalid_0's rmse: 1.04384\tvalid_0's l2: 1.0896\n",
      "[500]\tvalid_0's rmse: 1.04383\tvalid_0's l2: 1.08957\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.04383\tvalid_0's l2: 1.08957\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04617\tvalid_0's l2: 1.09447\n",
      "[200]\tvalid_0's rmse: 1.04556\tvalid_0's l2: 1.0932\n",
      "[300]\tvalid_0's rmse: 1.04554\tvalid_0's l2: 1.09315\n",
      "[400]\tvalid_0's rmse: 1.0455\tvalid_0's l2: 1.09307\n",
      "[500]\tvalid_0's rmse: 1.04547\tvalid_0's l2: 1.09301\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's rmse: 1.04547\tvalid_0's l2: 1.09301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 23:33:17,390] Trial 3 finished with value: 1.0452860789574578 and parameters: {'num_leaves': 22, 'max_depth': 6, 'learning_rate': 0.022968772883218625, 'lambda_l1': 7.571172192068058, 'lambda_l2': 1.8886218532930636, 'min_child_samples': 10, 'colsample_bytree': 0.5911317277852157, 'subsample': 0.5255786185530937}. Best is trial 0 with value: 1.0452745888499515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04604\tvalid_0's l2: 1.09421\n",
      "[200]\tvalid_0's rmse: 1.04597\tvalid_0's l2: 1.09406\n",
      "[300]\tvalid_0's rmse: 1.04592\tvalid_0's l2: 1.09395\n",
      "[400]\tvalid_0's rmse: 1.04593\tvalid_0's l2: 1.09398\n",
      "Early stopping, best iteration is:\n",
      "[321]\tvalid_0's rmse: 1.04592\tvalid_0's l2: 1.09394\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04518\tvalid_0's l2: 1.0924\n",
      "[200]\tvalid_0's rmse: 1.04513\tvalid_0's l2: 1.09231\n",
      "[300]\tvalid_0's rmse: 1.04511\tvalid_0's l2: 1.09226\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's rmse: 1.04511\tvalid_0's l2: 1.09225\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04621\tvalid_0's l2: 1.09455\n",
      "[200]\tvalid_0's rmse: 1.04616\tvalid_0's l2: 1.09444\n",
      "[300]\tvalid_0's rmse: 1.04614\tvalid_0's l2: 1.09441\n",
      "[400]\tvalid_0's rmse: 1.04616\tvalid_0's l2: 1.09445\n",
      "Early stopping, best iteration is:\n",
      "[305]\tvalid_0's rmse: 1.04613\tvalid_0's l2: 1.0944\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04392\tvalid_0's l2: 1.08978\n",
      "[200]\tvalid_0's rmse: 1.04388\tvalid_0's l2: 1.08968\n",
      "[300]\tvalid_0's rmse: 1.04385\tvalid_0's l2: 1.08962\n",
      "[400]\tvalid_0's rmse: 1.04382\tvalid_0's l2: 1.08957\n",
      "[500]\tvalid_0's rmse: 1.0438\tvalid_0's l2: 1.08952\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[494]\tvalid_0's rmse: 1.0438\tvalid_0's l2: 1.08952\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04564\tvalid_0's l2: 1.09336\n",
      "[200]\tvalid_0's rmse: 1.04557\tvalid_0's l2: 1.09321\n",
      "[300]\tvalid_0's rmse: 1.04553\tvalid_0's l2: 1.09313\n",
      "[400]\tvalid_0's rmse: 1.04551\tvalid_0's l2: 1.09308\n",
      "[500]\tvalid_0's rmse: 1.0455\tvalid_0's l2: 1.09307\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[418]\tvalid_0's rmse: 1.0455\tvalid_0's l2: 1.09307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 23:33:54,950] Trial 4 finished with value: 1.045292216781268 and parameters: {'num_leaves': 18, 'max_depth': 6, 'learning_rate': 0.039058377844131076, 'lambda_l1': 9.041986740582306, 'lambda_l2': 1.456920653760056, 'min_child_samples': 11, 'colsample_bytree': 0.6026349539768235, 'subsample': 0.5660228740609402}. Best is trial 0 with value: 1.0452745888499515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04706\tvalid_0's l2: 1.09634\n",
      "[200]\tvalid_0's rmse: 1.04609\tvalid_0's l2: 1.09431\n",
      "[300]\tvalid_0's rmse: 1.04603\tvalid_0's l2: 1.09418\n",
      "[400]\tvalid_0's rmse: 1.04599\tvalid_0's l2: 1.09409\n",
      "[500]\tvalid_0's rmse: 1.04596\tvalid_0's l2: 1.09404\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\tvalid_0's rmse: 1.04596\tvalid_0's l2: 1.09404\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04605\tvalid_0's l2: 1.09422\n",
      "[200]\tvalid_0's rmse: 1.04521\tvalid_0's l2: 1.09247\n",
      "[300]\tvalid_0's rmse: 1.04518\tvalid_0's l2: 1.09241\n",
      "[400]\tvalid_0's rmse: 1.04516\tvalid_0's l2: 1.09236\n",
      "[500]\tvalid_0's rmse: 1.04515\tvalid_0's l2: 1.09233\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[489]\tvalid_0's rmse: 1.04514\tvalid_0's l2: 1.09233\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.047\tvalid_0's l2: 1.09621\n",
      "[200]\tvalid_0's rmse: 1.04621\tvalid_0's l2: 1.09456\n",
      "[300]\tvalid_0's rmse: 1.04619\tvalid_0's l2: 1.09452\n",
      "Early stopping, best iteration is:\n",
      "[263]\tvalid_0's rmse: 1.04619\tvalid_0's l2: 1.09451\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04489\tvalid_0's l2: 1.0918\n",
      "[200]\tvalid_0's rmse: 1.04393\tvalid_0's l2: 1.0898\n",
      "[300]\tvalid_0's rmse: 1.0439\tvalid_0's l2: 1.08973\n",
      "[400]\tvalid_0's rmse: 1.04388\tvalid_0's l2: 1.08969\n",
      "[500]\tvalid_0's rmse: 1.04386\tvalid_0's l2: 1.08965\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.04386\tvalid_0's l2: 1.08965\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04661\tvalid_0's l2: 1.09539\n",
      "[200]\tvalid_0's rmse: 1.04562\tvalid_0's l2: 1.09332\n",
      "[300]\tvalid_0's rmse: 1.04557\tvalid_0's l2: 1.09321\n",
      "[400]\tvalid_0's rmse: 1.04554\tvalid_0's l2: 1.09316\n",
      "[500]\tvalid_0's rmse: 1.04551\tvalid_0's l2: 1.0931\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.04551\tvalid_0's l2: 1.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 23:34:36,625] Trial 5 finished with value: 1.0453337691680535 and parameters: {'num_leaves': 19, 'max_depth': 4, 'learning_rate': 0.02048245323798968, 'lambda_l1': 9.546602010393912, 'lambda_l2': 1.3881699724000254, 'min_child_samples': 17, 'colsample_bytree': 0.5467566614134116, 'subsample': 0.5780102031766716}. Best is trial 0 with value: 1.0452745888499515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04622\tvalid_0's l2: 1.09458\n",
      "[200]\tvalid_0's rmse: 1.04611\tvalid_0's l2: 1.09434\n",
      "[300]\tvalid_0's rmse: 1.04605\tvalid_0's l2: 1.09422\n",
      "[400]\tvalid_0's rmse: 1.04602\tvalid_0's l2: 1.09416\n",
      "[500]\tvalid_0's rmse: 1.04599\tvalid_0's l2: 1.0941\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[497]\tvalid_0's rmse: 1.04599\tvalid_0's l2: 1.0941\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04531\tvalid_0's l2: 1.09268\n",
      "[200]\tvalid_0's rmse: 1.04523\tvalid_0's l2: 1.09252\n",
      "[300]\tvalid_0's rmse: 1.04519\tvalid_0's l2: 1.09243\n",
      "[400]\tvalid_0's rmse: 1.04518\tvalid_0's l2: 1.0924\n",
      "Early stopping, best iteration is:\n",
      "[370]\tvalid_0's rmse: 1.04518\tvalid_0's l2: 1.09239\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04632\tvalid_0's l2: 1.09478\n",
      "[200]\tvalid_0's rmse: 1.04626\tvalid_0's l2: 1.09465\n",
      "[300]\tvalid_0's rmse: 1.04621\tvalid_0's l2: 1.09456\n",
      "[400]\tvalid_0's rmse: 1.04618\tvalid_0's l2: 1.0945\n",
      "[500]\tvalid_0's rmse: 1.04616\tvalid_0's l2: 1.09445\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's rmse: 1.04616\tvalid_0's l2: 1.09445\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04404\tvalid_0's l2: 1.09002\n",
      "[200]\tvalid_0's rmse: 1.04395\tvalid_0's l2: 1.08983\n",
      "[300]\tvalid_0's rmse: 1.04392\tvalid_0's l2: 1.08977\n",
      "[400]\tvalid_0's rmse: 1.04389\tvalid_0's l2: 1.0897\n",
      "[500]\tvalid_0's rmse: 1.04387\tvalid_0's l2: 1.08967\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[489]\tvalid_0's rmse: 1.04387\tvalid_0's l2: 1.08967\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04573\tvalid_0's l2: 1.09354\n",
      "[200]\tvalid_0's rmse: 1.04561\tvalid_0's l2: 1.09331\n",
      "[300]\tvalid_0's rmse: 1.04557\tvalid_0's l2: 1.09321\n",
      "[400]\tvalid_0's rmse: 1.04554\tvalid_0's l2: 1.09316\n",
      "[500]\tvalid_0's rmse: 1.04553\tvalid_0's l2: 1.09314\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[462]\tvalid_0's rmse: 1.04553\tvalid_0's l2: 1.09313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 23:35:15,199] Trial 6 finished with value: 1.0453466980268948 and parameters: {'num_leaves': 22, 'max_depth': 3, 'learning_rate': 0.0391655339707926, 'lambda_l1': 8.875664116805574, 'lambda_l2': 2.4092484123462836, 'min_child_samples': 19, 'colsample_bytree': 0.5896849968216628, 'subsample': 0.6382811352534675}. Best is trial 0 with value: 1.0452745888499515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04716\tvalid_0's l2: 1.09654\n",
      "[200]\tvalid_0's rmse: 1.04619\tvalid_0's l2: 1.09452\n",
      "[300]\tvalid_0's rmse: 1.04612\tvalid_0's l2: 1.09437\n",
      "[400]\tvalid_0's rmse: 1.04607\tvalid_0's l2: 1.09427\n",
      "[500]\tvalid_0's rmse: 1.04604\tvalid_0's l2: 1.09421\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[497]\tvalid_0's rmse: 1.04604\tvalid_0's l2: 1.0942\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04617\tvalid_0's l2: 1.09446\n",
      "[200]\tvalid_0's rmse: 1.04529\tvalid_0's l2: 1.09262\n",
      "[300]\tvalid_0's rmse: 1.04524\tvalid_0's l2: 1.09253\n",
      "[400]\tvalid_0's rmse: 1.04522\tvalid_0's l2: 1.09248\n",
      "[500]\tvalid_0's rmse: 1.04519\tvalid_0's l2: 1.09242\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.04519\tvalid_0's l2: 1.09242\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04716\tvalid_0's l2: 1.09654\n",
      "[200]\tvalid_0's rmse: 1.04631\tvalid_0's l2: 1.09477\n",
      "[300]\tvalid_0's rmse: 1.04627\tvalid_0's l2: 1.09469\n",
      "[400]\tvalid_0's rmse: 1.04625\tvalid_0's l2: 1.09465\n",
      "[500]\tvalid_0's rmse: 1.04623\tvalid_0's l2: 1.0946\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.04623\tvalid_0's l2: 1.0946\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04505\tvalid_0's l2: 1.09213\n",
      "[200]\tvalid_0's rmse: 1.04404\tvalid_0's l2: 1.09002\n",
      "[300]\tvalid_0's rmse: 1.04399\tvalid_0's l2: 1.08991\n",
      "[400]\tvalid_0's rmse: 1.04396\tvalid_0's l2: 1.08985\n",
      "[500]\tvalid_0's rmse: 1.04394\tvalid_0's l2: 1.0898\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[496]\tvalid_0's rmse: 1.04393\tvalid_0's l2: 1.0898\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04676\tvalid_0's l2: 1.09572\n",
      "[200]\tvalid_0's rmse: 1.04573\tvalid_0's l2: 1.09355\n",
      "[300]\tvalid_0's rmse: 1.04565\tvalid_0's l2: 1.09338\n",
      "[400]\tvalid_0's rmse: 1.04561\tvalid_0's l2: 1.09331\n",
      "[500]\tvalid_0's rmse: 1.04559\tvalid_0's l2: 1.09325\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[497]\tvalid_0's rmse: 1.04559\tvalid_0's l2: 1.09325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 23:35:53,046] Trial 7 finished with value: 1.0453966349044426 and parameters: {'num_leaves': 18, 'max_depth': 3, 'learning_rate': 0.020636914565776935, 'lambda_l1': 6.626651653816322, 'lambda_l2': 1.583015934534223, 'min_child_samples': 12, 'colsample_bytree': 0.6243106263727894, 'subsample': 0.5535129990040384}. Best is trial 0 with value: 1.0452745888499515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04675\tvalid_0's l2: 1.09569\n",
      "[200]\tvalid_0's rmse: 1.04606\tvalid_0's l2: 1.09425\n",
      "[300]\tvalid_0's rmse: 1.04603\tvalid_0's l2: 1.09418\n",
      "[400]\tvalid_0's rmse: 1.04597\tvalid_0's l2: 1.09406\n",
      "[500]\tvalid_0's rmse: 1.04596\tvalid_0's l2: 1.09404\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[452]\tvalid_0's rmse: 1.04596\tvalid_0's l2: 1.09403\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04574\tvalid_0's l2: 1.09356\n",
      "[200]\tvalid_0's rmse: 1.04516\tvalid_0's l2: 1.09236\n",
      "[300]\tvalid_0's rmse: 1.04516\tvalid_0's l2: 1.09236\n",
      "[400]\tvalid_0's rmse: 1.04514\tvalid_0's l2: 1.09232\n",
      "[500]\tvalid_0's rmse: 1.04512\tvalid_0's l2: 1.09228\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.04512\tvalid_0's l2: 1.09228\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04674\tvalid_0's l2: 1.09567\n",
      "[200]\tvalid_0's rmse: 1.04617\tvalid_0's l2: 1.09447\n",
      "[300]\tvalid_0's rmse: 1.04616\tvalid_0's l2: 1.09445\n",
      "Early stopping, best iteration is:\n",
      "[244]\tvalid_0's rmse: 1.04615\tvalid_0's l2: 1.09444\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04458\tvalid_0's l2: 1.09115\n",
      "[200]\tvalid_0's rmse: 1.04389\tvalid_0's l2: 1.0897\n",
      "[300]\tvalid_0's rmse: 1.04388\tvalid_0's l2: 1.08969\n",
      "[400]\tvalid_0's rmse: 1.04386\tvalid_0's l2: 1.08964\n",
      "[500]\tvalid_0's rmse: 1.04383\tvalid_0's l2: 1.08958\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[458]\tvalid_0's rmse: 1.04383\tvalid_0's l2: 1.08957\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04631\tvalid_0's l2: 1.09476\n",
      "[200]\tvalid_0's rmse: 1.04558\tvalid_0's l2: 1.09323\n",
      "[300]\tvalid_0's rmse: 1.04555\tvalid_0's l2: 1.09317\n",
      "[400]\tvalid_0's rmse: 1.04551\tvalid_0's l2: 1.0931\n",
      "[500]\tvalid_0's rmse: 1.0455\tvalid_0's l2: 1.09306\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[488]\tvalid_0's rmse: 1.04549\tvalid_0's l2: 1.09306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 23:36:38,115] Trial 8 finished with value: 1.045311885857687 and parameters: {'num_leaves': 20, 'max_depth': 5, 'learning_rate': 0.02205222497654264, 'lambda_l1': 9.010984903770199, 'lambda_l2': 1.1118259655196563, 'min_child_samples': 20, 'colsample_bytree': 0.6158367153944986, 'subsample': 0.5298073522301259}. Best is trial 0 with value: 1.0452745888499515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04613\tvalid_0's l2: 1.09439\n",
      "[200]\tvalid_0's rmse: 1.04601\tvalid_0's l2: 1.09414\n",
      "[300]\tvalid_0's rmse: 1.04598\tvalid_0's l2: 1.09407\n",
      "[400]\tvalid_0's rmse: 1.04595\tvalid_0's l2: 1.094\n",
      "[500]\tvalid_0's rmse: 1.04593\tvalid_0's l2: 1.09398\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[469]\tvalid_0's rmse: 1.04593\tvalid_0's l2: 1.09396\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04523\tvalid_0's l2: 1.09251\n",
      "[200]\tvalid_0's rmse: 1.04515\tvalid_0's l2: 1.09233\n",
      "[300]\tvalid_0's rmse: 1.0451\tvalid_0's l2: 1.09224\n",
      "[400]\tvalid_0's rmse: 1.0451\tvalid_0's l2: 1.09223\n",
      "Early stopping, best iteration is:\n",
      "[368]\tvalid_0's rmse: 1.04509\tvalid_0's l2: 1.09221\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04625\tvalid_0's l2: 1.09464\n",
      "[200]\tvalid_0's rmse: 1.04618\tvalid_0's l2: 1.09449\n",
      "[300]\tvalid_0's rmse: 1.04615\tvalid_0's l2: 1.09444\n",
      "[400]\tvalid_0's rmse: 1.04613\tvalid_0's l2: 1.09438\n",
      "[500]\tvalid_0's rmse: 1.04612\tvalid_0's l2: 1.09436\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[492]\tvalid_0's rmse: 1.04611\tvalid_0's l2: 1.09435\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04399\tvalid_0's l2: 1.08991\n",
      "[200]\tvalid_0's rmse: 1.0439\tvalid_0's l2: 1.08974\n",
      "[300]\tvalid_0's rmse: 1.04385\tvalid_0's l2: 1.08963\n",
      "[400]\tvalid_0's rmse: 1.04382\tvalid_0's l2: 1.08956\n",
      "[500]\tvalid_0's rmse: 1.04379\tvalid_0's l2: 1.08951\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.04379\tvalid_0's l2: 1.08951\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04567\tvalid_0's l2: 1.09342\n",
      "[200]\tvalid_0's rmse: 1.04555\tvalid_0's l2: 1.09317\n",
      "[300]\tvalid_0's rmse: 1.04552\tvalid_0's l2: 1.09311\n",
      "[400]\tvalid_0's rmse: 1.04548\tvalid_0's l2: 1.09304\n",
      "[500]\tvalid_0's rmse: 1.04546\tvalid_0's l2: 1.09298\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.04546\tvalid_0's l2: 1.09298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 23:37:22,119] Trial 9 finished with value: 1.0452766060209029 and parameters: {'num_leaves': 18, 'max_depth': 6, 'learning_rate': 0.032644893703530485, 'lambda_l1': 8.645035840204937, 'lambda_l2': 2.1569055200289187, 'min_child_samples': 10, 'colsample_bytree': 0.5537698592816409, 'subsample': 0.5173803589287694}. Best is trial 0 with value: 1.0452745888499515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 34s, sys: 2.64 s, total: 26min 36s\n",
      "Wall time: 7min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': 500,\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 18, 26),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.04, log=True),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 5, 10.0),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1.0, 2.5),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 20),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.65),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 0.65),\n",
    "        'random_state': 42,\n",
    "        'verbose': -1,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    lgbm_meta = LGBMRegressor(**params)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(stacked_train):\n",
    "        x_train, x_val = stacked_train[train_idx], stacked_train[val_idx]\n",
    "        y_train, y_val = y_log[train_idx], y_log[val_idx]\n",
    "\n",
    "        lgbm_meta.fit(\n",
    "            x_train, y_train,\n",
    "            eval_set=[(x_val, y_val)],\n",
    "            eval_metric='rmse',\n",
    "            callbacks=[\n",
    "                early_stopping(100),\n",
    "                log_evaluation(100)  \n",
    "            ]\n",
    "        )\n",
    "        preds = lgbm_meta.predict(x_val)\n",
    "        rmse = root_mean_squared_error(y_val, preds)\n",
    "        scores.append(rmse)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'num_leaves': 21, 'max_depth': 6, 'learning_rate': 0.03321866147099672, 'lambda_l1': 7.993292420985183, 'lambda_l2': 1.2340279606636548, 'min_child_samples': 11, 'colsample_bytree': 0.50871254182523, 'subsample': 0.6299264218662403}\n",
      "Best score: 1.0452745888499515\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Best score: {study.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> train_nan1 : \n",
    "- Best params: {'num_leaves': 17, 'max_depth': 4, 'learning_rate': 0.03826462461969002}\n",
    "- Best score: 1.045365246163749\n",
    "> train_nan2 : \n",
    "- Best params: {'num_leaves': 13, 'max_depth': 4, 'learning_rate': 0.07395933395415777}\n",
    "- Best score: 1.0453620758551936\n",
    "> train1\n",
    "- Best params: {'num_leaves': 19, 'max_depth': 5, 'learning_rate': 0.08644134558897314}\n",
    "- Best score: 1.045370006761391\n",
    "> train2\n",
    "- Best params: {'num_leaves': 13, 'max_depth': 5, 'learning_rate': 0.06460819035343711}\n",
    "- Best score: 1.0453501377537826\n",
    "> train3(optuna.sampler.TPESampler(seed=42))\n",
    "- Best params: {'num_leaves': 23, 'max_depth': 4, 'learning_rate': 0.05671589285948462}\n",
    "- Best score: 1.0453243380539543\n",
    "> train4(optuna.sampler.TPESampler(seed=42)) + addition of hyper params\n",
    "- Best params: {'num_leaves': 22, 'max_depth': 5, 'learning_rate': 0.030611852048834733, 'lambda_l1': 7.072114131472227, 'lambda_l2': 1.452824663751602, 'min_child_samples': 14, 'colsample_bytree': 0.5671589285948462, 'subsample': 0.5677802257385179}\n",
    "- Best score: 1.0452741712447353\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.7 s, sys: 60.4 ms, total: 55.7 s\n",
      "Wall time: 28 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# best_params = {\n",
    "#     'num_leaves': 13, \n",
    "#     'max_depth': 4, \n",
    "#     'learning_rate': 0.07395933395415777\n",
    "#     'random_state': 42,\n",
    "#     'verbose': -1,\n",
    "#     'n_jobs': -1\n",
    "# }\n",
    "\n",
    "# meta_model = LGBMRegressor(\n",
    "#     **best_params, \n",
    "#     n_estimators=1000, \n",
    "#     callbacks=[\n",
    "#         early_stopping(100),\n",
    "#         log_evaluation(100)  \n",
    "#             ],\n",
    "#     random_state=42,\n",
    "#     )\n",
    "# meta_model.fit(stacked_train, y_log)\n",
    "# meta_preds_log = meta_model.predict(stacked_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04619\tvalid_0's l2: 1.09451\n",
      "[200]\tvalid_0's rmse: 1.04603\tvalid_0's l2: 1.09417\n",
      "[300]\tvalid_0's rmse: 1.04596\tvalid_0's l2: 1.09404\n",
      "[400]\tvalid_0's rmse: 1.04594\tvalid_0's l2: 1.094\n",
      "[500]\tvalid_0's rmse: 1.04594\tvalid_0's l2: 1.09399\n",
      "Early stopping, best iteration is:\n",
      "[438]\tvalid_0's rmse: 1.04593\tvalid_0's l2: 1.09398\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04527\tvalid_0's l2: 1.09259\n",
      "[200]\tvalid_0's rmse: 1.04518\tvalid_0's l2: 1.09239\n",
      "[300]\tvalid_0's rmse: 1.04515\tvalid_0's l2: 1.09233\n",
      "[400]\tvalid_0's rmse: 1.04512\tvalid_0's l2: 1.09228\n",
      "[500]\tvalid_0's rmse: 1.04512\tvalid_0's l2: 1.09227\n",
      "[600]\tvalid_0's rmse: 1.0451\tvalid_0's l2: 1.09224\n",
      "[700]\tvalid_0's rmse: 1.04509\tvalid_0's l2: 1.09222\n",
      "Early stopping, best iteration is:\n",
      "[676]\tvalid_0's rmse: 1.04509\tvalid_0's l2: 1.09221\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04625\tvalid_0's l2: 1.09464\n",
      "[200]\tvalid_0's rmse: 1.04614\tvalid_0's l2: 1.0944\n",
      "[300]\tvalid_0's rmse: 1.04612\tvalid_0's l2: 1.09436\n",
      "[400]\tvalid_0's rmse: 1.04611\tvalid_0's l2: 1.09434\n",
      "[500]\tvalid_0's rmse: 1.04611\tvalid_0's l2: 1.09434\n",
      "Early stopping, best iteration is:\n",
      "[408]\tvalid_0's rmse: 1.0461\tvalid_0's l2: 1.09433\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.044\tvalid_0's l2: 1.08994\n",
      "[200]\tvalid_0's rmse: 1.04387\tvalid_0's l2: 1.08967\n",
      "[300]\tvalid_0's rmse: 1.04382\tvalid_0's l2: 1.08956\n",
      "[400]\tvalid_0's rmse: 1.0438\tvalid_0's l2: 1.08951\n",
      "[500]\tvalid_0's rmse: 1.04379\tvalid_0's l2: 1.0895\n",
      "[600]\tvalid_0's rmse: 1.0438\tvalid_0's l2: 1.08952\n",
      "Early stopping, best iteration is:\n",
      "[542]\tvalid_0's rmse: 1.04379\tvalid_0's l2: 1.08949\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04572\tvalid_0's l2: 1.09353\n",
      "[200]\tvalid_0's rmse: 1.04554\tvalid_0's l2: 1.09315\n",
      "[300]\tvalid_0's rmse: 1.04549\tvalid_0's l2: 1.09305\n",
      "[400]\tvalid_0's rmse: 1.04544\tvalid_0's l2: 1.09294\n",
      "[500]\tvalid_0's rmse: 1.04542\tvalid_0's l2: 1.09291\n",
      "[600]\tvalid_0's rmse: 1.04541\tvalid_0's l2: 1.09289\n",
      "Early stopping, best iteration is:\n",
      "[589]\tvalid_0's rmse: 1.04541\tvalid_0's l2: 1.09288\n",
      "CPU times: user 5min 2s, sys: 285 ms, total: 5min 3s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'num_leaves': 22,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.030611852048834733,\n",
    "    'lambda_l1': 7.072114131472227,\n",
    "    'lambda_l2': 1.452824663751602,\n",
    "    'min_child_samples': 14,\n",
    "    'colsample_bytree': 0.5671589285948462,\n",
    "    'subsample': 0.5677802257385179,\n",
    "    'random_state': 42,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "meta_models_lgb = []\n",
    "meta_lgbm_OOF = np.zeros(len(stacked_train))\n",
    "meta_lgbm_preds = np.zeros(len(stacked_test))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, val_idx in kf.split(stacked_train):\n",
    "    x_train, x_val = stacked_train[train_idx], stacked_train[val_idx]\n",
    "    y_train, y_val = y_log[train_idx], y_log[val_idx]\n",
    "\n",
    "    model = LGBMRegressor(**best_params)\n",
    "    model.fit(\n",
    "        x_train, y_train, \n",
    "        eval_set=[(x_val, y_val)],\n",
    "        eval_metric='rmse',\n",
    "        callbacks=[\n",
    "            early_stopping(100),\n",
    "            log_evaluation(100)\n",
    "        ])\n",
    "\n",
    "    meta_lgbm_OOF[val_idx] += model.predict(x_val)\n",
    "    meta_lgbm_preds += model.predict(stacked_test) / kf.n_splits\n",
    "    meta_models_lgb.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0452650462992732"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_squared_error(meta_lgbm_OOF, y_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_data = {'OOF': meta_lgbm_OOF, 'Predictions': meta_lgbm_preds}\n",
    "np.save('./data/meta_lgbm_results2.npy', stacked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_loaded = np.load('./data/meta_lgbm_results2.npy', allow_pickle=True).item()\n",
    "meta_oof = meta_loaded['OOF']\n",
    "meta_pred = meta_loaded['Predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0452650462992732"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_squared_error(meta_oof, y_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Public Score : 1.04470(406/2244) / 18.09%\n",
    "2. Public Score : 1.04446(358/2253) / 15.89%\n",
    "2. Public Score : 1.04439(355/2268) / 15.65%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \n",
    "-  , pca, kmeans  lgbm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pred'] = meta_oof\n",
    "test['pred'] = meta_pred\n",
    "\n",
    "train_og = train_nan.drop(['Premium Amount'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(train_og)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(scaled_data)\n",
    "\n",
    "explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by PCA Components')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.65 s, sys: 5.14 s, total: 13.8 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(train_og)\n",
    "test_scaled = scaler.transform(test_nan)\n",
    "\n",
    "pca = PCA(n_components=45)\n",
    "pca_features = pca.fit_transform(scaled_data)\n",
    "test_pca = pca.transform(test_scaled)\n",
    "\n",
    "x_extended = np.hstack((train_og, pca_features))\n",
    "test_extended = np.hstack((test_nan, test_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_columns = train_og.columns.tolist()\n",
    "# pca_columns = [f'PCA_{i+1}' for i in range(pca_features.shape[1])]\n",
    "# extended_columns = original_columns + pca_columns\n",
    "# x_extended_df = pd.DataFrame(x_extended, columns=extended_columns)\n",
    "# x_extended_df = x_extended_df.astype(float)\n",
    "# test_extended_df = pd.DataFrame(test_extended, columns=extended_columns)\n",
    "# test_extended_df = test_extended_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "folds_train = KFold(n_splits=5, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 09:30:34,335] A new study created in memory with name: no-name-a72f4a81-7545-41c7-9f18-e9a7b24a4549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.08046\tvalid_0's l2: 1.16739\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.08047\tvalid_0's l2: 1.16742\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.08013\tvalid_0's l2: 1.16668\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.07702\tvalid_0's l2: 1.15997\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.07533\tvalid_0's l2: 1.15634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 09:35:21,301] Trial 0 finished with value: 1.0786818719605065 and parameters: {'num_leaves': 114, 'learning_rate': 0.012511985806183077, 'feature_fraction': 0.8376303920077013, 'bagging_fraction': 0.6131425691240594, 'bagging_freq': 10, 'min_data_in_leaf': 63, 'max_depth': 9, 'lambda_l1': 4.358801047050283, 'lambda_l2': 7.363690821247121, 'min_gain_to_split': 0.0037931832979212184}. Best is trial 0 with value: 1.0786818719605065.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.08394\tvalid_0's l2: 1.17493\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.08402\tvalid_0's l2: 1.17511\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.08395\tvalid_0's l2: 1.17494\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.08064\tvalid_0's l2: 1.16778\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.07877\tvalid_0's l2: 1.16375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 09:38:41,896] Trial 1 finished with value: 1.0822641694693425 and parameters: {'num_leaves': 90, 'learning_rate': 0.01810485336084989, 'feature_fraction': 0.9204897078016253, 'bagging_fraction': 0.8885332725924568, 'bagging_freq': 12, 'min_data_in_leaf': 79, 'max_depth': 5, 'lambda_l1': 3.4507083263853913, 'lambda_l2': 8.011575179745895, 'min_gain_to_split': 0.0049430663698076535}. Best is trial 0 with value: 1.0786818719605065.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.0955\tvalid_0's l2: 1.20012\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.09574\tvalid_0's l2: 1.20065\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.09574\tvalid_0's l2: 1.20064\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.09253\tvalid_0's l2: 1.19362\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.09063\tvalid_0's l2: 1.18948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 09:44:07,182] Trial 2 finished with value: 1.0940280762722532 and parameters: {'num_leaves': 100, 'learning_rate': 0.00019347571557360864, 'feature_fraction': 0.9921819484473355, 'bagging_fraction': 0.6755301860304033, 'bagging_freq': 10, 'min_data_in_leaf': 84, 'max_depth': 10, 'lambda_l1': 4.088074396800832, 'lambda_l2': 7.062935181133918, 'min_gain_to_split': 0.003526603800807989}. Best is trial 0 with value: 1.0786818719605065.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.07982\tvalid_0's l2: 1.16602\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.07976\tvalid_0's l2: 1.16587\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.07964\tvalid_0's l2: 1.16561\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.07649\tvalid_0's l2: 1.15883\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.07477\tvalid_0's l2: 1.15512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 09:49:59,079] Trial 3 finished with value: 1.078093253082113 and parameters: {'num_leaves': 101, 'learning_rate': 0.016626638693686285, 'feature_fraction': 0.8477973664871459, 'bagging_fraction': 0.7313165113949591, 'bagging_freq': 13, 'min_data_in_leaf': 69, 'max_depth': 9, 'lambda_l1': 4.51790731354718, 'lambda_l2': 7.17869177028363, 'min_gain_to_split': 0.002903075070384332}. Best is trial 3 with value: 1.078093253082113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.09629\tvalid_0's l2: 1.20185\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.09654\tvalid_0's l2: 1.2024\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.09654\tvalid_0's l2: 1.20239\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.09333\tvalid_0's l2: 1.19536\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.09144\tvalid_0's l2: 1.19125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 09:54:19,650] Trial 4 finished with value: 1.0948272545869933 and parameters: {'num_leaves': 107, 'learning_rate': 0.00015598795791976034, 'feature_fraction': 0.9192865373841993, 'bagging_fraction': 0.851197116693249, 'bagging_freq': 13, 'min_data_in_leaf': 66, 'max_depth': 6, 'lambda_l1': 4.790763688922551, 'lambda_l2': 6.644539073581293, 'min_gain_to_split': 0.005468929371865161}. Best is trial 3 with value: 1.078093253082113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 20min 3s, sys: 13 s, total: 1h 20min 16s\n",
      "Wall time: 23min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': 500,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 90, 130),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.8, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 0.9),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 9, 13),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 60, 91),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 12),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 3, 5),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 5.8, 9.1),\n",
    "        'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0.002, 0.006),\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    model = LGBMRegressor(**params)\n",
    "    scores = []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for train_idx, val_idx in kf.split(pca_features):\n",
    "        x_train, x_val = pca_features[train_idx], pca_features[val_idx]\n",
    "        y_train, y_val = y_log[train_idx], y_log[val_idx]\n",
    "\n",
    "        model.fit(\n",
    "            x_train, y_train, \n",
    "            eval_set=[(x_val, y_val)],\n",
    "            eval_metric='rmse',\n",
    "            callbacks=[\n",
    "                early_stopping(50),\n",
    "                # log_evaluation(10)\n",
    "            ])\n",
    "        preds = model.predict(x_val)\n",
    "        score = np.sqrt(mean_squared_error(y_val,preds))\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED)\n",
    ")\n",
    "study.optimize(objective, n_trials=5)\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'num_leaves': 101,\n",
       "  'learning_rate': 0.016626638693686285,\n",
       "  'feature_fraction': 0.8477973664871459,\n",
       "  'bagging_fraction': 0.7313165113949591,\n",
       "  'bagging_freq': 13,\n",
       "  'min_data_in_leaf': 69,\n",
       "  'max_depth': 9,\n",
       "  'lambda_l1': 4.51790731354718,\n",
       "  'lambda_l2': 7.17869177028363,\n",
       "  'min_gain_to_split': 0.002903075070384332},\n",
       " 1.078093253082113)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_params, study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'num_leaves': 101,\n",
       "  'learning_rate': 0.016626638693686285,\n",
       "  'feature_fraction': 0.8477973664871459,\n",
       "  'bagging_fraction': 0.7313165113949591,\n",
       "  'bagging_freq': 13,\n",
       "  'min_data_in_leaf': 69,\n",
       "  'max_depth': 9,\n",
       "  'lambda_l1': 4.51790731354718,\n",
       "  'lambda_l2': 7.17869177028363,\n",
       "  'min_gain_to_split': 0.002903075070384332},\n",
       " 1.0469236379660614)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, study.best_value # org + pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[303]\tvalid_0's rmse: 1.04825\tvalid_0's l2: 1.09882\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[425]\tvalid_0's rmse: 1.04913\tvalid_0's l2: 1.10068\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[325]\tvalid_0's rmse: 1.04917\tvalid_0's l2: 1.10075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[299]\tvalid_0's rmse: 1.04404\tvalid_0's l2: 1.09001\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[287]\tvalid_0's rmse: 1.04301\tvalid_0's l2: 1.08786\n",
      "CPU times: user 20min 34s, sys: 7.35 s, total: 20min 41s\n",
      "Wall time: 6min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_params = {\n",
    " 'n_estimators': 1000,\n",
    " 'boosting_type': 'gbdt',\n",
    " 'num_leaves': 101,\n",
    " 'learning_rate': 0.016626638693686285,\n",
    " 'feature_fraction': 0.8477973664871459,\n",
    " 'bagging_fraction': 0.7313165113949591,\n",
    " 'bagging_freq': 13,\n",
    " 'min_data_in_leaf': 69,\n",
    " 'max_depth': 9,\n",
    " 'lambda_l1': 4.51790731354718,\n",
    " 'lambda_l2': 7.17869177028363,\n",
    " 'min_gain_to_split': 0.002903075070384332,\n",
    " 'verbose': -1,\n",
    " 'n_jobs': -1\n",
    "}\n",
    "\n",
    "models_lgb_pca = []\n",
    "lgbm_OOF_pca = np.zeros(len(x_extended))\n",
    "lgbm_preds_pca = np.zeros(len(test_extended))\n",
    "\n",
    "for train_idx, val_idx in folds_train.split(x_extended):\n",
    "    x_train, x_val = x_extended[train_idx], x_extended[val_idx]\n",
    "    y_train, y_val = y_log[train_idx], y_log[val_idx]\n",
    "\n",
    "    model = LGBMRegressor(**best_params)\n",
    "    model.fit(\n",
    "        x_train, y_train, \n",
    "        eval_set=[(x_val, y_val)],\n",
    "        eval_metric='rmse',\n",
    "        callbacks=[\n",
    "            early_stopping(100),\n",
    "            # log_evaluation(50)\n",
    "        ])\n",
    "\n",
    "    lgbm_OOF_pca[val_idx] += model.predict(x_val)\n",
    "    lgbm_preds_pca += model.predict(test_extended) / folds_train.n_splits\n",
    "    models_lgb_pca.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0467198643519278"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_squared_error(lgbm_OOF_pca50, y_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " PCA    ,       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.183015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11475\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score 6.594502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[649]\tvalid_0's rmse: 1.07995\tvalid_0's l2: 1.16629\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(n_estimators=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(n_estimators=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(n_estimators=1000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(pca_features, y_log_nan, test_size=0.2, random_state=SEED)\n",
    "model = LGBMRegressor(n_estimators=1000, learning_rate=0.1)\n",
    "model.fit(x_train, y_train, \n",
    "    eval_set=[(x_val, y_val)], \n",
    "    eval_metric='rmse',\n",
    "    callbacks=[\n",
    "            early_stopping(100),\n",
    "            # log_evaluation(50)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200000, 19)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(model, threshold='mean', prefit=True)  #     \n",
    "selected_features = selector.transform(pca_features)  #   \n",
    "selected_test = selector.transform(test_pca)  #   \n",
    "\n",
    "print(selected_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.3 s, sys: 3.5 s, total: 7.8 s\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x_extended_selected = np.hstack((train.drop(['Premium Amount'], axis=1), selected_features))\n",
    "test_extended_selected = np.hstack((test, selected_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 10:49:14,669] A new study created in memory with name: no-name-6a76faba-ed36-425d-8b10-6b28c5e8def7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[320]\tvalid_0's rmse: 1.04658\tvalid_0's l2: 1.09533\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[319]\tvalid_0's rmse: 1.04739\tvalid_0's l2: 1.09702\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[356]\tvalid_0's rmse: 1.04752\tvalid_0's l2: 1.09729\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[310]\tvalid_0's rmse: 1.04343\tvalid_0's l2: 1.08874\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[289]\tvalid_0's rmse: 1.04246\tvalid_0's l2: 1.08673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 10:52:51,677] Trial 0 finished with value: 1.0454769336435932 and parameters: {'num_leaves': 114, 'learning_rate': 0.012511985806183077, 'feature_fraction': 0.8376303920077013, 'bagging_fraction': 0.6131425691240594, 'bagging_freq': 10, 'min_data_in_leaf': 63, 'max_depth': 9, 'lambda_l1': 4.358801047050283, 'lambda_l2': 7.363690821247121, 'min_gain_to_split': 0.0037931832979212184}. Best is trial 0 with value: 1.0454769336435932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's rmse: 1.0464\tvalid_0's l2: 1.09496\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's rmse: 1.04724\tvalid_0's l2: 1.09671\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's rmse: 1.0473\tvalid_0's l2: 1.09683\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's rmse: 1.0434\tvalid_0's l2: 1.08869\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's rmse: 1.04243\tvalid_0's l2: 1.08665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 10:55:20,850] Trial 1 finished with value: 1.0453541412907976 and parameters: {'num_leaves': 90, 'learning_rate': 0.01810485336084989, 'feature_fraction': 0.9204897078016253, 'bagging_fraction': 0.8885332725924568, 'bagging_freq': 12, 'min_data_in_leaf': 79, 'max_depth': 5, 'lambda_l1': 3.4507083263853913, 'lambda_l2': 8.011575179745895, 'min_gain_to_split': 0.0049430663698076535}. Best is trial 1 with value: 1.0453541412907976.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.08852\tvalid_0's l2: 1.18488\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.08889\tvalid_0's l2: 1.18568\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.08885\tvalid_0's l2: 1.1856\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.0856\tvalid_0's l2: 1.17852\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.08377\tvalid_0's l2: 1.17455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 11:01:04,392] Trial 2 finished with value: 1.087125704967244 and parameters: {'num_leaves': 100, 'learning_rate': 0.00019347571557360864, 'feature_fraction': 0.9921819484473355, 'bagging_fraction': 0.6755301860304033, 'bagging_freq': 10, 'min_data_in_leaf': 84, 'max_depth': 10, 'lambda_l1': 4.088074396800832, 'lambda_l2': 7.062935181133918, 'min_gain_to_split': 0.003526603800807989}. Best is trial 1 with value: 1.0453541412907976.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's rmse: 1.04663\tvalid_0's l2: 1.09542\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's rmse: 1.04735\tvalid_0's l2: 1.09695\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's rmse: 1.0475\tvalid_0's l2: 1.09725\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's rmse: 1.0435\tvalid_0's l2: 1.08889\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's rmse: 1.0425\tvalid_0's l2: 1.08681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 11:05:08,257] Trial 3 finished with value: 1.0454928569610815 and parameters: {'num_leaves': 101, 'learning_rate': 0.016626638693686285, 'feature_fraction': 0.8477973664871459, 'bagging_fraction': 0.7313165113949591, 'bagging_freq': 13, 'min_data_in_leaf': 69, 'max_depth': 9, 'lambda_l1': 4.51790731354718, 'lambda_l2': 7.17869177028363, 'min_gain_to_split': 0.002903075070384332}. Best is trial 1 with value: 1.0453541412907976.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.09015\tvalid_0's l2: 1.18842\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.0905\tvalid_0's l2: 1.18918\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.09046\tvalid_0's l2: 1.18911\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.08722\tvalid_0's l2: 1.18204\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.08538\tvalid_0's l2: 1.17806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 11:11:32,781] Trial 4 finished with value: 1.0887409950129308 and parameters: {'num_leaves': 107, 'learning_rate': 0.00015598795791976034, 'feature_fraction': 0.9192865373841993, 'bagging_fraction': 0.851197116693249, 'bagging_freq': 13, 'min_data_in_leaf': 66, 'max_depth': 6, 'lambda_l1': 4.790763688922551, 'lambda_l2': 6.644539073581293, 'min_gain_to_split': 0.005468929371865161}. Best is trial 1 with value: 1.0453541412907976.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 10min 13s, sys: 24.3 s, total: 1h 10min 37s\n",
      "Wall time: 22min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': 500,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 90, 130),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.8, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 0.9),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 9, 13),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 60, 91),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 12),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 3, 5),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 5.8, 9.1),\n",
    "        'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0.002, 0.006),\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    model = LGBMRegressor(**params)\n",
    "    scores = []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for train_idx, val_idx in kf.split(x_extended_selected):\n",
    "        x_train, x_val = x_extended_selected[train_idx], x_extended_selected[val_idx]\n",
    "        y_train, y_val = y_log_nan[train_idx], y_log_nan[val_idx]\n",
    "\n",
    "        model.fit(\n",
    "            x_train, y_train, \n",
    "            eval_set=[(x_val, y_val)],\n",
    "            eval_metric='rmse',\n",
    "            callbacks=[\n",
    "                early_stopping(50),\n",
    "                # log_evaluation(10)\n",
    "            ])\n",
    "        preds = model.predict(x_val)\n",
    "        score = np.sqrt(mean_squared_error(y_val,preds))\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED)\n",
    ")\n",
    "study.optimize(objective, n_trials=5)\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'num_leaves': 90,\n",
       "  'learning_rate': 0.01810485336084989,\n",
       "  'feature_fraction': 0.9204897078016253,\n",
       "  'bagging_fraction': 0.8885332725924568,\n",
       "  'bagging_freq': 12,\n",
       "  'min_data_in_leaf': 79,\n",
       "  'max_depth': 5,\n",
       "  'lambda_l1': 3.4507083263853913,\n",
       "  'lambda_l2': 8.011575179745895,\n",
       "  'min_gain_to_split': 0.0049430663698076535},\n",
       " 1.0453541412907976)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's rmse: 1.0464\tvalid_0's l2: 1.09496\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's rmse: 1.04724\tvalid_0's l2: 1.09671\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's rmse: 1.0473\tvalid_0's l2: 1.09683\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's rmse: 1.0434\tvalid_0's l2: 1.08869\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's rmse: 1.04243\tvalid_0's l2: 1.08665\n",
      "CPU times: user 14min 19s, sys: 6.84 s, total: 14min 26s\n",
      "Wall time: 5min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_params = {\n",
    " 'n_estimators': 1000,\n",
    " 'boosting_type': 'gbdt',\n",
    " 'num_leaves': 90,\n",
    " 'learning_rate': 0.01810485336084989,\n",
    " 'feature_fraction': 0.9204897078016253,\n",
    " 'bagging_fraction': 0.8885332725924568,\n",
    " 'bagging_freq': 12,\n",
    " 'min_data_in_leaf': 79,\n",
    " 'max_depth': 5,\n",
    " 'lambda_l1': 3.4507083263853913,\n",
    " 'lambda_l2': 8.011575179745895,\n",
    " 'min_gain_to_split': 0.0049430663698076535,\n",
    " 'verbose': -1,\n",
    " 'n_jobs': -1\n",
    "}\n",
    "\n",
    "models_lgb_pca = []\n",
    "lgbm_OOF_pca = np.zeros(len(x_extended_selected))\n",
    "lgbm_preds_pca = np.zeros(len(test_extended_selected))\n",
    "\n",
    "for train_idx, val_idx in folds_train.split(x_extended_selected):\n",
    "    x_train, x_val = x_extended_selected[train_idx], x_extended_selected[val_idx]\n",
    "    y_train, y_val = y_log[train_idx], y_log[val_idx]\n",
    "\n",
    "    model = LGBMRegressor(**best_params)\n",
    "    model.fit(\n",
    "        x_train, y_train, \n",
    "        eval_set=[(x_val, y_val)],\n",
    "        eval_metric='rmse',\n",
    "        callbacks=[\n",
    "            early_stopping(100),\n",
    "            # log_evaluation(50)\n",
    "        ])\n",
    "\n",
    "    lgbm_OOF_pca[val_idx] += model.predict(x_val)\n",
    "    lgbm_preds_pca += model.predict(test_extended_selected) / folds_train.n_splits\n",
    "    models_lgb_pca.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0453561329117549"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_squared_error(lgbm_OOF_pca, y_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pred'] = meta_oof\n",
    "test['pred'] = meta_pred\n",
    "\n",
    "train['pred_mean'] = OOF_mean \n",
    "train['pred_min'] = OOF_min \n",
    "train['pred_max'] = OOF_max \n",
    "\n",
    "test['pred_mean'] = pred_mean \n",
    "test['pred_min'] = pred_min \n",
    "test['pred_max'] = pred_max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.drop('Premium Amount', axis=1)\n",
    "y = train['Premium Amount']\n",
    "\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 13:15:28,806] A new study created in memory with name: no-name-738312f4-a0da-4dfb-8f03-c649dde5631b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's rmse: 1.04604\tvalid_0's l2: 1.09421\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid_0's rmse: 1.04504\tvalid_0's l2: 1.09211\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's rmse: 1.04619\tvalid_0's l2: 1.09451\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's rmse: 1.0438\tvalid_0's l2: 1.08952\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's rmse: 1.04538\tvalid_0's l2: 1.09282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 13:18:02,004] Trial 0 finished with value: 1.0452911362325086 and parameters: {'num_leaves': 38, 'learning_rate': 0.02155557652018214, 'feature_fraction': 0.8763412744053908, 'bagging_fraction': 0.808761712749373, 'bagging_freq': 16, 'min_data_in_leaf': 62, 'max_depth': 5, 'lambda_l1': 3.8588010470502834, 'lambda_l2': 7.77938339920219, 'min_gain_to_split': 0.008344887473440914}. Best is trial 0 with value: 1.0452911362325086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's rmse: 1.04599\tvalid_0's l2: 1.0941\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[276]\tvalid_0's rmse: 1.04508\tvalid_0's l2: 1.09218\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's rmse: 1.0462\tvalid_0's l2: 1.09453\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[279]\tvalid_0's rmse: 1.04374\tvalid_0's l2: 1.08939\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[283]\tvalid_0's rmse: 1.04541\tvalid_0's l2: 1.09289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 13:20:17,255] Trial 1 finished with value: 1.0452834381133358 and parameters: {'num_leaves': 20, 'learning_rate': 0.022860233546174735, 'feature_fraction': 0.9343427954611377, 'bagging_fraction': 0.9923555150616379, 'bagging_freq': 19, 'min_data_in_leaf': 76, 'max_depth': 3, 'lambda_l1': 2.9507083263853913, 'lambda_l2': 8.309470601610277, 'min_gain_to_split': 0.009207299777355741}. Best is trial 1 with value: 1.0452834381133358.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[464]\tvalid_0's rmse: 1.046\tvalid_0's l2: 1.09411\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[411]\tvalid_0's rmse: 1.04507\tvalid_0's l2: 1.09217\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[483]\tvalid_0's rmse: 1.04624\tvalid_0's l2: 1.09462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[419]\tvalid_0's rmse: 1.04381\tvalid_0's l2: 1.08954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[485]\tvalid_0's rmse: 1.04538\tvalid_0's l2: 1.09282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 13:23:54,077] Trial 2 finished with value: 1.0452994960244837 and parameters: {'num_leaves': 27, 'learning_rate': 0.011106703859405143, 'feature_fraction': 0.9845273639131349, 'bagging_fraction': 0.8503534573536022, 'bagging_freq': 16, 'min_data_in_leaf': 81, 'max_depth': 6, 'lambda_l1': 3.588074396800832, 'lambda_l2': 7.533310602745933, 'min_gain_to_split': 0.008144952850605992}. Best is trial 1 with value: 1.0452834381133358.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's rmse: 1.04599\tvalid_0's l2: 1.0941\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's rmse: 1.04504\tvalid_0's l2: 1.0921\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's rmse: 1.04623\tvalid_0's l2: 1.09459\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's rmse: 1.04379\tvalid_0's l2: 1.0895\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's rmse: 1.04539\tvalid_0's l2: 1.09284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 13:26:12,877] Trial 3 finished with value: 1.0452873330135102 and parameters: {'num_leaves': 28, 'learning_rate': 0.022552654674491787, 'feature_fraction': 0.883458156541002, 'bagging_fraction': 0.8875443409299728, 'bagging_freq': 21, 'min_data_in_leaf': 68, 'max_depth': 6, 'lambda_l1': 4.01790731354718, 'lambda_l2': 7.62802053932297, 'min_gain_to_split': 0.007677306302788249}. Best is trial 1 with value: 1.0452834381133358.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[492]\tvalid_0's rmse: 1.04601\tvalid_0's l2: 1.09413\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[495]\tvalid_0's rmse: 1.0451\tvalid_0's l2: 1.09222\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[440]\tvalid_0's rmse: 1.0462\tvalid_0's l2: 1.09453\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[483]\tvalid_0's rmse: 1.04375\tvalid_0's l2: 1.08942\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.04544\tvalid_0's l2: 1.09295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 13:29:28,853] Trial 4 finished with value: 1.0452992397762013 and parameters: {'num_leaves': 33, 'learning_rate': 0.010732707285467727, 'feature_fraction': 0.9335005761689396, 'bagging_fraction': 0.967464744462166, 'bagging_freq': 21, 'min_data_in_leaf': 65, 'max_depth': 3, 'lambda_l1': 4.290763688922551, 'lambda_l2': 7.190986514748331, 'min_gain_to_split': 0.00960169702889887}. Best is trial 1 with value: 1.0452834381133358.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44min 34s, sys: 13.4 s, total: 44min 48s\n",
      "Wall time: 14min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': 500,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.03, log=True),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.85, 0.99),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.8, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 15, 21),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 60, 87),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 7),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 2.5, 4.5),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 6.5, 9.2),\n",
    "        'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0.007, 0.01),\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    model = LGBMRegressor(**params)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in folds.split(x):\n",
    "        x_train, x_val = x.iloc[train_idx], x.iloc[val_idx]\n",
    "        y_train, y_val = y_log.iloc[train_idx], y_log.iloc[val_idx]\n",
    "\n",
    "        model.fit(\n",
    "            x_train, y_train, \n",
    "            eval_set=[(x_val, y_val)],\n",
    "            eval_metric='rmse',\n",
    "            callbacks=[\n",
    "                early_stopping(50),\n",
    "                # log_evaluation(10)\n",
    "            ])\n",
    "        preds = model.predict(x_val)\n",
    "        score = np.sqrt(mean_squared_log_error(np.expm1(y_val), np.expm1(preds)))\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED)\n",
    ")\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'num_leaves': 20,\n",
       "  'learning_rate': 0.022860233546174735,\n",
       "  'feature_fraction': 0.9343427954611377,\n",
       "  'bagging_fraction': 0.9923555150616379,\n",
       "  'bagging_freq': 19,\n",
       "  'min_data_in_leaf': 76,\n",
       "  'max_depth': 3,\n",
       "  'lambda_l1': 2.9507083263853913,\n",
       "  'lambda_l2': 8.309470601610277,\n",
       "  'min_gain_to_split': 0.009207299777355741},\n",
       " 1.0452834381133358)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ({'num_leaves': 90,\n",
    "#   'learning_rate': 0.01810485336084989,\n",
    "#   'feature_fraction': 0.9204897078016253,\n",
    "#   'bagging_fraction': 0.8885332725924568,\n",
    "#   'bagging_freq': 12,\n",
    "#   'min_data_in_leaf': 79,\n",
    "#   'max_depth': 5,\n",
    "#   'lambda_l1': 3.4507083263853913,\n",
    "#   'lambda_l2': 8.011575179745895,\n",
    "#   'min_gain_to_split': 0.0049430663698076535},\n",
    "#  1.045273450566226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's rmse: 1.04599\tvalid_0's l2: 1.0941\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[276]\tvalid_0's rmse: 1.04508\tvalid_0's l2: 1.09218\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's rmse: 1.0462\tvalid_0's l2: 1.09453\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[279]\tvalid_0's rmse: 1.04374\tvalid_0's l2: 1.08939\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[422]\tvalid_0's rmse: 1.04541\tvalid_0's l2: 1.09288\n",
      "CPU times: user 9min 49s, sys: 3.83 s, total: 9min 53s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_params = {\n",
    "'n_estimators': 1000,\n",
    "'boosting_type': 'gbdt',\n",
    "'num_leaves': 20,\n",
    "'learning_rate': 0.022860233546174735,\n",
    "'feature_fraction': 0.9343427954611377,\n",
    "'bagging_fraction': 0.9923555150616379,\n",
    "'bagging_freq': 19,\n",
    "'min_data_in_leaf': 76,\n",
    "'max_depth': 3,\n",
    "'lambda_l1': 2.9507083263853913,\n",
    "'lambda_l2': 8.309470601610277,\n",
    "'min_gain_to_split': 0.009207299777355741,\n",
    "'verbose': -1,\n",
    "'n_jobs': -1\n",
    "}\n",
    "\n",
    "models_lgb = []\n",
    "lgbm_OOF = np.zeros(len(x))\n",
    "lgbm_preds = np.zeros(len(test))\n",
    "\n",
    "for train_idx, val_idx in folds.split(x):\n",
    "    x_train, x_val = x.iloc[train_idx], x.iloc[val_idx]\n",
    "    y_train, y_val = y_log.iloc[train_idx], y_log.iloc[val_idx]\n",
    "\n",
    "    model = LGBMRegressor(**best_params)\n",
    "    model.fit(\n",
    "        x_train, y_train, \n",
    "        eval_set=[(x_val, y_val)],\n",
    "        eval_metric='rmse',\n",
    "        callbacks=[\n",
    "            early_stopping(100),\n",
    "            # log_evaluation(50)\n",
    "        ])\n",
    "\n",
    "    lgbm_OOF[val_idx] += model.predict(x_val)\n",
    "    lgbm_preds += model.predict(test) / folds.n_splits\n",
    "    models_lgb.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 1.045283213407708\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation RMSE:\", np.sqrt(mean_squared_error(y_log, lgbm_OOF)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (OOF)\n",
    "1. (LGBM) - 1.046063550028496\n",
    "2.   - 1.0452650462992732"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Premium Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200000</td>\n",
       "      <td>1102.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200001</td>\n",
       "      <td>1102.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1200002</td>\n",
       "      <td>1102.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200003</td>\n",
       "      <td>1102.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200004</td>\n",
       "      <td>1102.545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Premium Amount\n",
       "0  1200000        1102.545\n",
       "1  1200001        1102.545\n",
       "2  1200002        1102.545\n",
       "3  1200003        1102.545\n",
       "4  1200004        1102.545"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_preds = np.expm1(meta_lgbm_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Premium Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200000</td>\n",
       "      <td>783.842769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200001</td>\n",
       "      <td>787.437395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1200002</td>\n",
       "      <td>803.820039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200003</td>\n",
       "      <td>806.575528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200004</td>\n",
       "      <td>752.637634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Premium Amount\n",
       "0  1200000      783.842769\n",
       "1  1200001      787.437395\n",
       "2  1200002      803.820039\n",
       "3  1200003      806.575528\n",
       "4  1200004      752.637634"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['Premium Amount'] = meta_preds\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 19.8M/19.8M [00:00<00:00, 39.2MB/s]\n",
      "Successfully submitted to Regression with an Insurance Dataset"
     ]
    }
   ],
   "source": [
    "submission.to_csv('./data/04_05.csv', index=False)\n",
    "!kaggle competitions submit -c playground-series-s4e12 -f \"./data/04_05.csv\" -m \"04_05_stacking_04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  : 1\n",
      "  : 4\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from datetime import datetime\n",
    "\n",
    "# Kaggle API \n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "#   \n",
    "competition = 'playground-series-s4e12'\n",
    "\n",
    "#   \n",
    "submissions = api.competition_submissions(competition)\n",
    "\n",
    "#   (UTC )\n",
    "today = datetime.utcnow().date()\n",
    "\n",
    "#        \n",
    "today_submissions = [\n",
    "    sub for sub in submissions \n",
    "    if sub.date.date() == today  #   date() \n",
    "]\n",
    "\n",
    "#  \n",
    "used_submissions = len(today_submissions)\n",
    "remaining_submissions = 5 - used_submissions\n",
    "\n",
    "print(f\"  : {used_submissions}\")\n",
    "print(f\"  : {remaining_submissions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
