{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.08 ms, sys: 385 Âµs, total: 6.47 ms\n",
      "Wall time: 5.62 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import PowerTransformer, OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import optuna\n",
    "from xgboost import XGBRegressor, callback\n",
    "from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=2024\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 2 s, total: 12.3 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def load_data():    \n",
    "    train = pd.read_csv('data/train.csv')\n",
    "    test = pd.read_csv('data/test.csv')    \n",
    "    all_df = pd.concat([train, test], sort=False).reset_index(drop=True)\n",
    "    return train, test, all_df\n",
    "\n",
    "def fill_nan_values(df):\n",
    "    num_cols = [col for col in df.select_dtypes(exclude='object').columns if col != 'Premium Amount']\n",
    "    cat_cols = df.select_dtypes(include='object').columns\n",
    "    for col in num_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].fillna('missing')\n",
    "    return df\n",
    "    \n",
    "def skewed(df, all_df):\n",
    "    pt = PowerTransformer(method='yeo-johnson')\n",
    "    pt.fit(df[['Annual Income']])\n",
    "    all_df['transformed_Annual_Income'] = pt.transform(all_df[['Annual Income']])\n",
    "    # all_df['log_Annual_Income'] = np.log1p(all_df['Annual Income'])\n",
    "    return all_df\n",
    "    \n",
    "def date(df):\n",
    "    df['Policy Start Date'] = pd.to_datetime(df['Policy Start Date'])\n",
    "    df['Year'] = df['Policy Start Date'].dt.year\n",
    "    df['Day'] = df['Policy Start Date'].dt.day\n",
    "    df['Month'] = df['Policy Start Date'].dt.month\n",
    "    df['Month_name'] = df['Policy Start Date'].dt.month_name()\n",
    "    df['Day_of_week'] = df['Policy Start Date'].dt.day_name()\n",
    "    df['Week'] = df['Policy Start Date'].dt.isocalendar().week\n",
    "    df['Year_sin'] = np.sin(2 * np.pi * df['Year'])\n",
    "    df['Year_cos'] = np.cos(2 * np.pi * df['Year'])\n",
    "    min_year = df['Year'].min()\n",
    "    max_year = df['Year'].max()\n",
    "    df['Year_sin'] = np.sin(2 * np.pi * (df['Year'] - min_year) / (max_year - min_year))\n",
    "    df['Year_cos'] = np.cos(2 * np.pi * (df['Year'] - min_year) / (max_year - min_year))\n",
    "    df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12) \n",
    "    df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)\n",
    "    df['Day_sin'] = np.sin(2 * np.pi * df['Day'] / 31)  \n",
    "    df['Day_cos'] = np.cos(2 * np.pi * df['Day'] / 31)\n",
    "    df['Group']=(df['Year']-2020)*48+df['Month']*4+df['Day']//7    \n",
    "    df.drop('Policy Start Date', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_nan_cols(df):\n",
    "    nan_cols = ['Marital Status', 'Customer Feedback', 'Health Score', 'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration']\n",
    "    for col in nan_cols:\n",
    "        col_name = col + '_NA'\n",
    "        df[col_name] = df[col].isnull().astype(int)\n",
    "    return df\n",
    "\n",
    "def get_encoding(df):\n",
    "    def encode_ordinal(df):\n",
    "        educ = {\"High School\":0, \"Bachelor's\":1, \"Master's\":2, \"PhD\":3}\n",
    "        policy = {'Basic':0, 'Comprehensive':1, 'Premium':2}\n",
    "        exerc = {'Rarely':0, 'Daily':1, 'Weekly':2, 'Monthly': 3}\n",
    "        # feedback = {'Poor':0, 'Average':1, 'Good':2}\n",
    "\n",
    "        df['Education Level'] = df['Education Level'].map(educ)\n",
    "        df['Policy Type'] = df['Policy Type'].map(policy)\n",
    "        df['Exercise Frequency'] = df['Exercise Frequency'].map(exerc)\n",
    "        # df['Customer Feedback'] = df['Customer Feedback'].map(feedback)\n",
    "        df['Gender'] = df['Gender'].map({'Male':0, 'Female':1})\n",
    "        df['Smoking Status'] = df['Smoking Status'].map({'Yes':1, 'No':0})\n",
    "        return df\n",
    "    \n",
    "    def target_encoder(df):\n",
    "        train = df[~df['Premium Amount'].isnull()]\n",
    "        test = df[df['Premium Amount'].isnull()]\n",
    "        encoder = TargetEncoder()\n",
    "        categorical_cols = ['Marital Status', 'Customer Feedback']\n",
    "        train[categorical_cols] = encoder.fit_transform(train[categorical_cols], train['Premium Amount'])\n",
    "        test[categorical_cols] = encoder.transform(test[categorical_cols])\n",
    "        df = pd.concat([train, test], sort=False).reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def one_hot_dummies(df, categorical):\n",
    "        oh = pd.get_dummies(df[categorical])\n",
    "        df = df.drop(categorical, axis=1)\n",
    "        return pd.concat([df, oh], axis=1)\n",
    "        return df\n",
    "\n",
    "    df = encode_ordinal(df)\n",
    "    df = target_encoder(df)\n",
    "\n",
    "    categorical_features = df.select_dtypes(include='object').columns\n",
    "    df = one_hot_dummies(df, categorical_features)\n",
    "    return df\n",
    "\n",
    "def add_new_features(df):\n",
    "    df['Income_Dependents Ratio'] = df['Annual Income'] / (df['Number of Dependents'].fillna(0) + 1)\n",
    "    df['Income_per_Dependent'] = df['Annual Income'] / (df['Number of Dependents'] + 1)\n",
    "    df['CreditScore_InsuranceDuration'] = df['Credit Score'] * df['Insurance Duration']\n",
    "    df['Health_Risk_Score'] = df['Smoking Status'].apply(lambda x: 1 if x == 'Smoker' else 0) + \\\n",
    "                                df['Exercise Frequency'].apply(lambda x: 1 if x == 'Low' else (0.5 if x == 'Medium' else 0)) + \\\n",
    "                                (100 - df['Health Score']) / 20\n",
    "    df['Credit_Health_Score'] = df['Credit Score'] * df['Health Score']\n",
    "    df['Health_Age_Interaction'] = df['Health Score'] * df['Age']\n",
    "\n",
    "    df['contract_length'] = pd.cut(\n",
    "        df[\"Insurance Duration\"].fillna(99),  \n",
    "        bins=[-float('inf'), 1, 3, float('inf')],  \n",
    "        labels=[0, 1, 2]  \n",
    "    ).astype(int)\n",
    "\n",
    "    df['Age_Income'] = df['Age'] * df['Annual Income']\n",
    "\n",
    "    # df[\"Annual_Income_Health_Score_Ratio\"] = df[\"Health Score\"] / df[\"Annual Income\"]\n",
    "    # df[\"Annual_Income_Age_Ratio\"] = df[\"Annual Income\"] / df[\"Age\"]\n",
    "    # df[\"Credit_Age\"] = df[\"Credit Score\"] / df[\"Age\"]\n",
    "    # df[\"Vehicle_Age_Insurance_Duration\"] = df[\"Vehicle Age\"] / df[\"Insurance Duration\"]\n",
    "    return df\n",
    "\n",
    "def prep():\n",
    "    train, test, all_df = load_data()\n",
    "\n",
    "    all_df = skewed(train, all_df)\n",
    "    all_df = date(all_df)\n",
    "    all_df = get_nan_cols(all_df)\n",
    "    # all_df = fill_nan_values(all_df)\n",
    "    all_df = get_encoding(all_df)\n",
    "    all_df = add_new_features(all_df)\n",
    "\n",
    "    del all_df['Annual Income']\n",
    "    \n",
    "    train = all_df[~all_df['Premium Amount'].isnull()]\n",
    "    test = all_df[all_df['Premium Amount'].isnull()]\n",
    "    train.drop('id', axis=1, inplace=True)\n",
    "    test.drop(['id', 'Premium Amount'], axis=1, inplace=True)\n",
    "    return train, test, all_df\n",
    "\n",
    "def prep_nan():\n",
    "    train, test, all_df = load_data()\n",
    "\n",
    "    all_df = skewed(train, all_df)\n",
    "    all_df = date(all_df)\n",
    "    all_df = get_nan_cols(all_df)\n",
    "    all_df = fill_nan_values(all_df)\n",
    "    all_df = get_encoding(all_df)\n",
    "    all_df = add_new_features(all_df)\n",
    "\n",
    "    del all_df['Annual Income']\n",
    "    \n",
    "    train = all_df[~all_df['Premium Amount'].isnull()]\n",
    "    test = all_df[all_df['Premium Amount'].isnull()]\n",
    "    train.drop('id', axis=1, inplace=True)\n",
    "    test.drop(['id', 'Premium Amount'], axis=1, inplace=True)\n",
    "    return train, test, all_df\n",
    "\n",
    "train, test, all_df = prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nan, test_nan, all_df_nan = prep_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>Policy Type</th>\n",
       "      <th>Previous Claims</th>\n",
       "      <th>Vehicle Age</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Insurance Duration</th>\n",
       "      <th>Customer Feedback</th>\n",
       "      <th>Smoking Status</th>\n",
       "      <th>Exercise Frequency</th>\n",
       "      <th>Premium Amount</th>\n",
       "      <th>transformed_Annual_Income</th>\n",
       "      <th>Year</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Year_sin</th>\n",
       "      <th>Year_cos</th>\n",
       "      <th>Month_sin</th>\n",
       "      <th>Month_cos</th>\n",
       "      <th>Day_sin</th>\n",
       "      <th>Day_cos</th>\n",
       "      <th>Group</th>\n",
       "      <th>Marital Status_NA</th>\n",
       "      <th>Customer Feedback_NA</th>\n",
       "      <th>Health Score_NA</th>\n",
       "      <th>Previous Claims_NA</th>\n",
       "      <th>Vehicle Age_NA</th>\n",
       "      <th>Credit Score_NA</th>\n",
       "      <th>Insurance Duration_NA</th>\n",
       "      <th>Occupation_Employed</th>\n",
       "      <th>Occupation_Self-Employed</th>\n",
       "      <th>Occupation_Unemployed</th>\n",
       "      <th>Location_Rural</th>\n",
       "      <th>Location_Suburban</th>\n",
       "      <th>Location_Urban</th>\n",
       "      <th>Property Type_Apartment</th>\n",
       "      <th>Property Type_Condo</th>\n",
       "      <th>Property Type_House</th>\n",
       "      <th>Month_name_April</th>\n",
       "      <th>Month_name_August</th>\n",
       "      <th>Month_name_December</th>\n",
       "      <th>Month_name_February</th>\n",
       "      <th>Month_name_January</th>\n",
       "      <th>Month_name_July</th>\n",
       "      <th>Month_name_June</th>\n",
       "      <th>Month_name_March</th>\n",
       "      <th>Month_name_May</th>\n",
       "      <th>Month_name_November</th>\n",
       "      <th>Month_name_October</th>\n",
       "      <th>Month_name_September</th>\n",
       "      <th>Day_of_week_Friday</th>\n",
       "      <th>Day_of_week_Monday</th>\n",
       "      <th>Day_of_week_Saturday</th>\n",
       "      <th>Day_of_week_Sunday</th>\n",
       "      <th>Day_of_week_Thursday</th>\n",
       "      <th>Day_of_week_Tuesday</th>\n",
       "      <th>Day_of_week_Wednesday</th>\n",
       "      <th>Income_Dependents Ratio</th>\n",
       "      <th>Income_per_Dependent</th>\n",
       "      <th>CreditScore_InsuranceDuration</th>\n",
       "      <th>Health_Risk_Score</th>\n",
       "      <th>Credit_Health_Score</th>\n",
       "      <th>Health_Age_Interaction</th>\n",
       "      <th>contract_length</th>\n",
       "      <th>Age_Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1099.844389</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.598761</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1098.892745</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2869.0</td>\n",
       "      <td>-0.596487</td>\n",
       "      <td>2023</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>-9.510565e-01</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.998717</td>\n",
       "      <td>-0.050649</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5024.5</td>\n",
       "      <td>5024.5</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>3.870062</td>\n",
       "      <td>8406.738970</td>\n",
       "      <td>429.376453</td>\n",
       "      <td>2</td>\n",
       "      <td>190931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1100.625116</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>15.569731</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1094.350977</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1483.0</td>\n",
       "      <td>0.336563</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>-9.510565e-01</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>-0.758758</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7919.5</td>\n",
       "      <td>7919.5</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>4.221513</td>\n",
       "      <td>10805.393307</td>\n",
       "      <td>607.219509</td>\n",
       "      <td>1</td>\n",
       "      <td>1235442.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1100.625116</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.177549</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1096.284299</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.140781</td>\n",
       "      <td>2023</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>-9.510565e-01</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.979530</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6400.5</td>\n",
       "      <td>6400.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.641123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1085.083634</td>\n",
       "      <td>1</td>\n",
       "      <td>588846.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1099.844389</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.938144</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1098.892745</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>765.0</td>\n",
       "      <td>2.088459</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>-0.758758</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>47285.0</td>\n",
       "      <td>47285.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>4.453093</td>\n",
       "      <td>4014.298906</td>\n",
       "      <td>229.701027</td>\n",
       "      <td>0</td>\n",
       "      <td>2978955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1101.735535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.376094</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1098.892745</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>0.555622</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>5.877853e-01</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.979530</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>19825.5</td>\n",
       "      <td>19825.5</td>\n",
       "      <td>2392.0</td>\n",
       "      <td>3.981195</td>\n",
       "      <td>12184.903989</td>\n",
       "      <td>427.897966</td>\n",
       "      <td>2</td>\n",
       "      <td>832671.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender  Marital Status  Number of Dependents  Education Level  \\\n",
       "0  19.0       1     1099.844389                   1.0                1   \n",
       "1  39.0       1     1100.625116                   3.0                2   \n",
       "2  23.0       0     1100.625116                   3.0                0   \n",
       "3  21.0       0     1099.844389                   2.0                1   \n",
       "4  21.0       0     1101.735535                   1.0                1   \n",
       "\n",
       "   Health Score  Policy Type  Previous Claims  Vehicle Age  Credit Score  \\\n",
       "0     22.598761            2              2.0         17.0         372.0   \n",
       "1     15.569731            1              1.0         12.0         694.0   \n",
       "2     47.177549            2              1.0         14.0           NaN   \n",
       "3     10.938144            0              1.0          0.0         367.0   \n",
       "4     20.376094            2              0.0          8.0         598.0   \n",
       "\n",
       "   Insurance Duration  Customer Feedback  Smoking Status  Exercise Frequency  \\\n",
       "0                 5.0        1098.892745               0                   2   \n",
       "1                 2.0        1094.350977               1                   3   \n",
       "2                 3.0        1096.284299               1                   2   \n",
       "3                 1.0        1098.892745               1                   1   \n",
       "4                 4.0        1098.892745               1                   2   \n",
       "\n",
       "   Premium Amount  transformed_Annual_Income  Year  Day  Month  Week  \\\n",
       "0          2869.0                  -0.596487  2023   23     12    51   \n",
       "1          1483.0                   0.336563  2023   12      6    24   \n",
       "2           567.0                   0.140781  2023   30      9    39   \n",
       "3           765.0                   2.088459  2024   12      6    24   \n",
       "4          2022.0                   0.555622  2021    1     12    48   \n",
       "\n",
       "       Year_sin  Year_cos     Month_sin     Month_cos   Day_sin   Day_cos  \\\n",
       "0 -9.510565e-01  0.309017 -2.449294e-16  1.000000e+00 -0.998717 -0.050649   \n",
       "1 -9.510565e-01  0.309017  1.224647e-16 -1.000000e+00  0.651372 -0.758758   \n",
       "2 -9.510565e-01  0.309017 -1.000000e+00 -1.836970e-16 -0.201299  0.979530   \n",
       "3 -2.449294e-16  1.000000  1.224647e-16 -1.000000e+00  0.651372 -0.758758   \n",
       "4  5.877853e-01 -0.809017 -2.449294e-16  1.000000e+00  0.201299  0.979530   \n",
       "\n",
       "   Group  Marital Status_NA  Customer Feedback_NA  Health Score_NA  \\\n",
       "0    195                  0                     0                0   \n",
       "1    169                  0                     0                0   \n",
       "2    184                  0                     0                0   \n",
       "3    217                  0                     0                0   \n",
       "4     96                  0                     0                0   \n",
       "\n",
       "   Previous Claims_NA  Vehicle Age_NA  Credit Score_NA  Insurance Duration_NA  \\\n",
       "0                   0               0                0                      0   \n",
       "1                   0               0                0                      0   \n",
       "2                   0               0                1                      0   \n",
       "3                   0               0                0                      0   \n",
       "4                   0               0                0                      0   \n",
       "\n",
       "   Occupation_Employed  Occupation_Self-Employed  Occupation_Unemployed  \\\n",
       "0                False                      True                  False   \n",
       "1                False                     False                  False   \n",
       "2                False                      True                  False   \n",
       "3                False                     False                  False   \n",
       "4                False                      True                  False   \n",
       "\n",
       "   Location_Rural  Location_Suburban  Location_Urban  Property Type_Apartment  \\\n",
       "0           False              False            True                    False   \n",
       "1            True              False           False                    False   \n",
       "2           False               True           False                    False   \n",
       "3            True              False           False                     True   \n",
       "4            True              False           False                    False   \n",
       "\n",
       "   Property Type_Condo  Property Type_House  Month_name_April  \\\n",
       "0                False                 True             False   \n",
       "1                False                 True             False   \n",
       "2                False                 True             False   \n",
       "3                False                False             False   \n",
       "4                False                 True             False   \n",
       "\n",
       "   Month_name_August  Month_name_December  Month_name_February  \\\n",
       "0              False                 True                False   \n",
       "1              False                False                False   \n",
       "2              False                False                False   \n",
       "3              False                False                False   \n",
       "4              False                 True                False   \n",
       "\n",
       "   Month_name_January  Month_name_July  Month_name_June  Month_name_March  \\\n",
       "0               False            False            False             False   \n",
       "1               False            False             True             False   \n",
       "2               False            False            False             False   \n",
       "3               False            False             True             False   \n",
       "4               False            False            False             False   \n",
       "\n",
       "   Month_name_May  Month_name_November  Month_name_October  \\\n",
       "0           False                False               False   \n",
       "1           False                False               False   \n",
       "2           False                False               False   \n",
       "3           False                False               False   \n",
       "4           False                False               False   \n",
       "\n",
       "   Month_name_September  Day_of_week_Friday  Day_of_week_Monday  \\\n",
       "0                 False               False               False   \n",
       "1                 False               False                True   \n",
       "2                  True               False               False   \n",
       "3                 False               False               False   \n",
       "4                 False               False               False   \n",
       "\n",
       "   Day_of_week_Saturday  Day_of_week_Sunday  Day_of_week_Thursday  \\\n",
       "0                  True               False                 False   \n",
       "1                 False               False                 False   \n",
       "2                  True               False                 False   \n",
       "3                 False               False                 False   \n",
       "4                 False               False                 False   \n",
       "\n",
       "   Day_of_week_Tuesday  Day_of_week_Wednesday  Income_Dependents Ratio  \\\n",
       "0                False                  False                   5024.5   \n",
       "1                False                  False                   7919.5   \n",
       "2                False                  False                   6400.5   \n",
       "3                False                   True                  47285.0   \n",
       "4                False                   True                  19825.5   \n",
       "\n",
       "   Income_per_Dependent  CreditScore_InsuranceDuration  Health_Risk_Score  \\\n",
       "0                5024.5                         1860.0           3.870062   \n",
       "1                7919.5                         1388.0           4.221513   \n",
       "2                6400.5                            NaN           2.641123   \n",
       "3               47285.0                          367.0           4.453093   \n",
       "4               19825.5                         2392.0           3.981195   \n",
       "\n",
       "   Credit_Health_Score  Health_Age_Interaction  contract_length  Age_Income  \n",
       "0          8406.738970              429.376453                2    190931.0  \n",
       "1         10805.393307              607.219509                1   1235442.0  \n",
       "2                  NaN             1085.083634                1    588846.0  \n",
       "3          4014.298906              229.701027                0   2978955.0  \n",
       "4         12184.903989              427.897966                2    832671.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200000, 70), (800000, 69), (1200000, 71), (800000, 70))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, train_nan.shape, test_nan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Premium Amount']\n",
    "y_log = np.log1p(y_train)\n",
    "y_log_nan = np.log1p(train_nan['Premium Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(train_nan.drop('Premium Amount', axis=1))\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(scaled_data)\n",
    "\n",
    "explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by PCA Components')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 12.2 s, total: 24.4 s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train_nan.drop('Premium Amount', axis=1))\n",
    "test_scaled = scaler.transform(test_nan)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "train_pca = pca.fit_transform(scaled_data)\n",
    "test_pca = pca.transform(test_scaled)\n",
    "\n",
    "train_extended = np.hstack((train.drop('Premium Amount', axis=1), train_pca))\n",
    "test_extended = np.hstack((test, test_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.168818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11475\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score 6.594502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[425]\tvalid_0's rmse: 1.07972\tvalid_0's l2: 1.1658\n",
      "CPU times: user 52.1 s, sys: 173 ms, total: 52.3 s\n",
      "Wall time: 27 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(n_estimators=1000, random_state=2024)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(n_estimators=1000, random_state=2024)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(n_estimators=1000, random_state=2024)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_pca, y_log_nan, test_size=0.2, random_state=SEED)\n",
    "model = LGBMRegressor(n_estimators=1000, learning_rate=0.1, random_state=SEED)\n",
    "model.fit(x_train, y_train, \n",
    "    eval_set=[(x_val, y_val)], \n",
    "    eval_metric='rmse',\n",
    "    callbacks=[early_stopping(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200000, 19)\n",
      "CPU times: user 370 ms, sys: 48.3 ms, total: 418 ms\n",
      "Wall time: 419 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "selector = SelectFromModel(model, threshold='mean', prefit=True)  # íê·  ì´ì ì¤ìë ê¸°ì¤ì¼ë¡ ì í\n",
    "selected_train = selector.transform(train_pca)\n",
    "selected_test = selector.transform(test_pca)\n",
    "\n",
    "print(selected_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.96 s, sys: 2.41 s, total: 5.36 s\n",
      "Wall time: 5.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_extended_selected = np.hstack((train.drop(['Premium Amount'], axis=1), selected_train))\n",
    "test_extended_selected = np.hstack((test, selected_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 105 ms, sys: 15.9 ms, total: 121 ms\n",
      "Wall time: 120 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = np.load('./data/pred_oof_data.npz')\n",
    "\n",
    "lgbm_OOF = data['lgbm_OOF']\n",
    "xgb_OOF = data['xgb_OOF']\n",
    "cat_OOF = data['cat_OOF']\n",
    "et_OOF = data['et_OOF']\n",
    "\n",
    "lgbm_preds = data['lgbm_preds']\n",
    "xgb_preds = data['xgb_preds']\n",
    "cat_preds = data['cat_preds']\n",
    "et_preds = data['et_preds']\n",
    "\n",
    "OOF_std = data['OOF_std']\n",
    "OOF_mean = data['OOF_mean']\n",
    "OOF_min = data['OOF_min']\n",
    "OOF_max = data['OOF_max']\n",
    "pred_std = data['pred_std']\n",
    "pred_mean = data['pred_mean']\n",
    "pred_min = data['pred_min']\n",
    "pred_max = data['pred_max']\n",
    "\n",
    "train['income_credit'] = train['transformed_Annual_Income'] * train['Credit Score']\n",
    "test['income_credit'] = test['transformed_Annual_Income'] * test['Credit Score']\n",
    "\n",
    "stacked_train = np.column_stack((lgbm_OOF, xgb_OOF, cat_OOF, et_OOF, train['transformed_Annual_Income'], train['Credit Score']))\n",
    "stacked_test = np.column_stack((lgbm_preds, xgb_preds, cat_preds, et_preds, test['transformed_Annual_Income'], test['Credit Score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 15:19:11,766] A new study created in memory with name: no-name-cdba6469-270e-493f-ae29-b08c7a298b41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[400]\tvalid_0's rmse: 1.04593\tvalid_0's l2: 1.09398\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\tvalid_0's rmse: 1.04501\tvalid_0's l2: 1.09205\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[477]\tvalid_0's rmse: 1.04605\tvalid_0's l2: 1.09423\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[435]\tvalid_0's rmse: 1.04387\tvalid_0's l2: 1.08967\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[372]\tvalid_0's rmse: 1.04549\tvalid_0's l2: 1.09305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 15:20:43,164] Trial 0 finished with value: 1.045272363402227 and parameters: {'num_leaves': 21, 'max_depth': 6, 'learning_rate': 0.03321866147099672, 'lambda_l1': 7.993292420985183, 'lambda_l2': 1.2340279606636548, 'min_child_samples': 11, 'colsample_bytree': 0.50871254182523, 'subsample': 0.6299264218662403}. Best is trial 0 with value: 1.045272363402227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.04598\tvalid_0's l2: 1.09408\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.04506\tvalid_0's l2: 1.09215\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\tvalid_0's rmse: 1.04607\tvalid_0's l2: 1.09427\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[497]\tvalid_0's rmse: 1.04389\tvalid_0's l2: 1.0897\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\tvalid_0's rmse: 1.04548\tvalid_0's l2: 1.09302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 15:22:10,208] Trial 1 finished with value: 1.0452963001141673 and parameters: {'num_leaves': 23, 'max_depth': 5, 'learning_rate': 0.02028740718282379, 'lambda_l1': 9.849549260809972, 'lambda_l2': 2.2486639612006325, 'min_child_samples': 12, 'colsample_bytree': 0.5272737450810651, 'subsample': 0.5275106764780151}. Best is trial 0 with value: 1.045272363402227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 1.04594\tvalid_0's l2: 1.09399\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[497]\tvalid_0's rmse: 1.04506\tvalid_0's l2: 1.09215\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[449]\tvalid_0's rmse: 1.04604\tvalid_0's l2: 1.09419\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[466]\tvalid_0's rmse: 1.04384\tvalid_0's l2: 1.08961\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[497]\tvalid_0's rmse: 1.04548\tvalid_0's l2: 1.09303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 15:23:25,012] Trial 2 finished with value: 1.0452715106884043 and parameters: {'num_leaves': 20, 'max_depth': 5, 'learning_rate': 0.026981022415762914, 'lambda_l1': 6.456145700990209, 'lambda_l2': 1.9177793420835691, 'min_child_samples': 11, 'colsample_bytree': 0.5438216972802827, 'subsample': 0.5549542764940538}. Best is trial 2 with value: 1.0452715106884043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[489]\tvalid_0's rmse: 1.04597\tvalid_0's l2: 1.09406\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[495]\tvalid_0's rmse: 1.04506\tvalid_0's l2: 1.09216\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[474]\tvalid_0's rmse: 1.04605\tvalid_0's l2: 1.09421\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[472]\tvalid_0's rmse: 1.04386\tvalid_0's l2: 1.08964\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[452]\tvalid_0's rmse: 1.04549\tvalid_0's l2: 1.09304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 15:24:36,013] Trial 3 finished with value: 1.04528545146442 and parameters: {'num_leaves': 22, 'max_depth': 6, 'learning_rate': 0.022968772883218625, 'lambda_l1': 7.571172192068058, 'lambda_l2': 1.8886218532930636, 'min_child_samples': 10, 'colsample_bytree': 0.5911317277852157, 'subsample': 0.5255786185530937}. Best is trial 2 with value: 1.0452715106884043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[383]\tvalid_0's rmse: 1.04595\tvalid_0's l2: 1.09401\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[438]\tvalid_0's rmse: 1.04506\tvalid_0's l2: 1.09215\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[397]\tvalid_0's rmse: 1.04606\tvalid_0's l2: 1.09425\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[351]\tvalid_0's rmse: 1.04383\tvalid_0's l2: 1.08958\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[491]\tvalid_0's rmse: 1.04546\tvalid_0's l2: 1.093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 15:25:59,645] Trial 4 finished with value: 1.0452732938879863 and parameters: {'num_leaves': 18, 'max_depth': 6, 'learning_rate': 0.039058377844131076, 'lambda_l1': 9.041986740582306, 'lambda_l2': 1.456920653760056, 'min_child_samples': 11, 'colsample_bytree': 0.6026349539768235, 'subsample': 0.5660228740609402}. Best is trial 2 with value: 1.0452715106884043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 57s, sys: 2.77 s, total: 22min\n",
      "Wall time: 6min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': 500,\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 18, 26),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.04, log=True),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 5, 10.0),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1.0, 2.5),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 20),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.65),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 0.65),\n",
    "        'random_state': 42,\n",
    "        'verbose': -1,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    lgbm_meta = LGBMRegressor(**params)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(stacked_train):\n",
    "        x_train, x_val = stacked_train[train_idx], stacked_train[val_idx]\n",
    "        y_train, y_val = y_log[train_idx], y_log[val_idx]\n",
    "\n",
    "        lgbm_meta.fit(\n",
    "            x_train, y_train,\n",
    "            eval_set=[(x_val, y_val)],\n",
    "            eval_metric='rmse',\n",
    "            callbacks=[early_stopping(100)]\n",
    "        )\n",
    "        preds = lgbm_meta.predict(x_val)\n",
    "        rmse = root_mean_squared_error(y_val, preds)\n",
    "        scores.append(rmse)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Best score: {study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + income_credit\n",
    "# Best params: {'num_leaves': 20, 'max_depth': 5, 'learning_rate': 0.026981022415762914, 'lambda_l1': 6.456145700990209, 'lambda_l2': 1.9177793420835691, 'min_child_samples': 11, 'colsample_bytree': 0.5438216972802827, 'subsample': 0.5549542764940538}\n",
    "# Best score: 1.0452715106884043\n",
    "\n",
    "# - max of oof\n",
    "# Best params: {'num_leaves': 20, 'max_depth': 5, 'learning_rate': 0.026981022415762914, 'lambda_l1': 6.456145700990209, 'lambda_l2': 1.9177793420835691, 'min_child_samples': 11, 'colsample_bytree': 0.5438216972802827, 'subsample': 0.5549542764940538}\n",
    "# Best score: 1.04524143977958\n",
    "\n",
    "# - min of oof\n",
    "# Best params: {'num_leaves': 18, 'max_depth': 6, 'learning_rate': 0.039058377844131076, 'lambda_l1': 9.041986740582306, 'lambda_l2': 1.456920653760056, 'min_child_samples': 11, 'colsample_bytree': 0.6026349539768235, 'subsample': 0.5660228740609402}\n",
    "# Best score: 1.0452550621692729\n",
    "\n",
    "# - mean of oof\n",
    "# Best params: {'num_leaves': 18, 'max_depth': 6, 'learning_rate': 0.039058377844131076, 'lambda_l1': 9.041986740582306, 'lambda_l2': 1.456920653760056, 'min_child_samples': 11, 'colsample_bytree': 0.6026349539768235, 'subsample': 0.5660228740609402}\n",
    "# Best score: 1.0452737270613282\n",
    "\n",
    "# + previous claims\n",
    "# Best params: {'num_leaves': 20, 'max_depth': 5, 'learning_rate': 0.026981022415762914, 'lambda_l1': 6.456145700990209, 'lambda_l2': 1.9177793420835691, 'min_child_samples': 11, 'colsample_bytree': 0.5438216972802827, 'subsample': 0.5549542764940538}\n",
    "# Best score: 1.0452803088301272\n",
    "\n",
    "# 2 pca\n",
    "# Best params: {'num_leaves': 18, 'max_depth': 6, 'learning_rate': 0.039058377844131076, 'lambda_l1': 9.041986740582306, 'lambda_l2': 1.456920653760056, 'min_child_samples': 11, 'colsample_bytree': 0.6026349539768235, 'subsample': 0.5660228740609402}\n",
    "# Best score: 1.0453225785114277\n",
    "\n",
    "# selected pca\n",
    "# Best params: {'num_leaves': 23, 'max_depth': 5, 'learning_rate': 0.02028740718282379, 'lambda_l1': 9.849549260809972, 'lambda_l2': 2.2486639612006325, 'min_child_samples': 12, 'colsample_bytree': 0.5272737450810651, 'subsample': 0.5275106764780151}\n",
    "# Best score: 1.0453800836022906\n",
    "\n",
    "# No PCA, No std\n",
    "# Best score: 1.0452741712447353 (No PCA, No std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04639\tvalid_0's l2: 1.09492\n",
      "[200]\tvalid_0's rmse: 1.04605\tvalid_0's l2: 1.09422\n",
      "[300]\tvalid_0's rmse: 1.04599\tvalid_0's l2: 1.0941\n",
      "[400]\tvalid_0's rmse: 1.04594\tvalid_0's l2: 1.09399\n",
      "[500]\tvalid_0's rmse: 1.0459\tvalid_0's l2: 1.09391\n",
      "[600]\tvalid_0's rmse: 1.04589\tvalid_0's l2: 1.09389\n",
      "[700]\tvalid_0's rmse: 1.04589\tvalid_0's l2: 1.09389\n",
      "Early stopping, best iteration is:\n",
      "[652]\tvalid_0's rmse: 1.04589\tvalid_0's l2: 1.09388\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04545\tvalid_0's l2: 1.09296\n",
      "[200]\tvalid_0's rmse: 1.04516\tvalid_0's l2: 1.09236\n",
      "[300]\tvalid_0's rmse: 1.04512\tvalid_0's l2: 1.09227\n",
      "[400]\tvalid_0's rmse: 1.04507\tvalid_0's l2: 1.09217\n",
      "[500]\tvalid_0's rmse: 1.04506\tvalid_0's l2: 1.09215\n",
      "[600]\tvalid_0's rmse: 1.04506\tvalid_0's l2: 1.09216\n",
      "Early stopping, best iteration is:\n",
      "[536]\tvalid_0's rmse: 1.04505\tvalid_0's l2: 1.09214\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.0464\tvalid_0's l2: 1.09495\n",
      "[200]\tvalid_0's rmse: 1.04613\tvalid_0's l2: 1.09439\n",
      "[300]\tvalid_0's rmse: 1.0461\tvalid_0's l2: 1.09432\n",
      "[400]\tvalid_0's rmse: 1.04607\tvalid_0's l2: 1.09426\n",
      "[500]\tvalid_0's rmse: 1.04605\tvalid_0's l2: 1.09421\n",
      "[600]\tvalid_0's rmse: 1.04604\tvalid_0's l2: 1.0942\n",
      "[700]\tvalid_0's rmse: 1.04603\tvalid_0's l2: 1.09418\n",
      "[800]\tvalid_0's rmse: 1.04602\tvalid_0's l2: 1.09415\n",
      "Early stopping, best iteration is:\n",
      "[770]\tvalid_0's rmse: 1.04601\tvalid_0's l2: 1.09414\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04421\tvalid_0's l2: 1.09037\n",
      "[200]\tvalid_0's rmse: 1.0439\tvalid_0's l2: 1.08973\n",
      "[300]\tvalid_0's rmse: 1.04386\tvalid_0's l2: 1.08965\n",
      "[400]\tvalid_0's rmse: 1.0438\tvalid_0's l2: 1.08952\n",
      "[500]\tvalid_0's rmse: 1.04379\tvalid_0's l2: 1.08951\n",
      "[600]\tvalid_0's rmse: 1.04377\tvalid_0's l2: 1.08946\n",
      "[700]\tvalid_0's rmse: 1.04377\tvalid_0's l2: 1.08946\n",
      "[800]\tvalid_0's rmse: 1.04376\tvalid_0's l2: 1.08943\n",
      "[900]\tvalid_0's rmse: 1.04375\tvalid_0's l2: 1.08942\n",
      "[1000]\tvalid_0's rmse: 1.04375\tvalid_0's l2: 1.08941\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 1.04375\tvalid_0's l2: 1.08941\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.04593\tvalid_0's l2: 1.09396\n",
      "[200]\tvalid_0's rmse: 1.04558\tvalid_0's l2: 1.09323\n",
      "[300]\tvalid_0's rmse: 1.04551\tvalid_0's l2: 1.09309\n",
      "[400]\tvalid_0's rmse: 1.04544\tvalid_0's l2: 1.09295\n",
      "[500]\tvalid_0's rmse: 1.04541\tvalid_0's l2: 1.09287\n",
      "[600]\tvalid_0's rmse: 1.04537\tvalid_0's l2: 1.09281\n",
      "[700]\tvalid_0's rmse: 1.04537\tvalid_0's l2: 1.09279\n",
      "Early stopping, best iteration is:\n",
      "[678]\tvalid_0's rmse: 1.04536\tvalid_0's l2: 1.09279\n",
      "CPU times: user 9min 23s, sys: 1.25 s, total: 9min 24s\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'num_leaves': 20,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.026981022415762914,\n",
    "    'lambda_l1': 6.456145700990209,\n",
    "    'lambda_l2': 1.9177793420835691,\n",
    "    'min_child_samples': 11,\n",
    "    'colsample_bytree': 0.543821697280282,\n",
    "    'subsample': 0.5549542764940538,\n",
    "    'random_state': 42,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "meta_models_lgb = []\n",
    "meta_lgbm_OOF = np.zeros(len(stacked_train))\n",
    "meta_lgbm_preds = np.zeros(len(stacked_test))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, val_idx in kf.split(stacked_train):\n",
    "    x_train, x_val = stacked_train[train_idx], stacked_train[val_idx]\n",
    "    y_train, y_val = y_log[train_idx], y_log[val_idx]\n",
    "\n",
    "    model = LGBMRegressor(**best_params)\n",
    "    model.fit(\n",
    "        x_train, y_train, \n",
    "        eval_set=[(x_val, y_val)],\n",
    "        eval_metric='rmse',\n",
    "        callbacks=[\n",
    "            early_stopping(100),\n",
    "            log_evaluation(100)\n",
    "        ])\n",
    "\n",
    "    meta_lgbm_OOF[val_idx] += model.predict(x_val)\n",
    "    meta_lgbm_preds += model.predict(stacked_test) / kf.n_splits\n",
    "    meta_models_lgb.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0452133511066504"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_squared_error(meta_lgbm_OOF, y_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_data = {'OOF': meta_lgbm_OOF, 'Predictions': meta_lgbm_preds}\n",
    "np.save('./data/meta_lgbm_results4.npy', stacked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_loaded = np.load('./data/meta_lgbm_results4.npy', allow_pickle=True).item()\n",
    "meta_oof = meta_loaded['OOF']\n",
    "meta_pred = meta_loaded['Predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0452133511066504"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_squared_error(meta_oof, y_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Public Score : 1.04470(406/2244) / 18.09%\n",
    "2. Public Score : 1.04446(358/2253) / 15.89%\n",
    "3. Public Score : 1.04439(355/2268) / 15.65%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_train = np.column_stack((lgbm_OOF, xgb_OOF, cat_OOF, et_OOF, train_nan['transformed_Annual_Income'], train_nan['Credit Score']))\n",
    "stacked_test = np.column_stack((lgbm_preds, xgb_preds, cat_preds, et_preds, test_nan['transformed_Annual_Income'], test_nan['Credit Score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 15:37:17,115] A new study created in memory with name: no-name-5dece794-348e-4a7e-8aa4-f350862a0060\n",
      "[I 2024-12-31 15:37:17,620] Trial 0 finished with value: -1.0457131768159864 and parameters: {'alpha': 0.017233288831716688}. Best is trial 0 with value: -1.0457131768159864.\n",
      "[I 2024-12-31 15:37:18,208] Trial 1 finished with value: -1.0457131723424589 and parameters: {'alpha': 1.3751068413926437}. Best is trial 1 with value: -1.0457131723424589.\n",
      "[I 2024-12-31 15:37:18,740] Trial 2 finished with value: -1.0457131760070313 and parameters: {'alpha': 0.2608158369431769}. Best is trial 1 with value: -1.0457131723424589.\n",
      "[I 2024-12-31 15:37:19,242] Trial 3 finished with value: -1.045713176558523 and parameters: {'alpha': 0.09466503798478172}. Best is trial 1 with value: -1.0457131723424589.\n",
      "[I 2024-12-31 15:37:19,752] Trial 4 finished with value: -1.0457131768624333 and parameters: {'alpha': 0.0032735743714072487}. Best is trial 1 with value: -1.0457131723424589.\n",
      "[I 2024-12-31 15:37:20,338] Trial 5 finished with value: -1.0457131768624355 and parameters: {'alpha': 0.0032729742670534194}. Best is trial 1 with value: -1.0457131723424589.\n",
      "[I 2024-12-31 15:37:20,909] Trial 6 finished with value: -1.0457131768681518 and parameters: {'alpha': 0.0015550191654264875}. Best is trial 1 with value: -1.0457131723424589.\n",
      "[I 2024-12-31 15:37:21,430] Trial 7 finished with value: -1.0457131744791226 and parameters: {'alpha': 0.7232250142857393}. Best is trial 1 with value: -1.0457131723424589.\n",
      "[I 2024-12-31 15:37:22,066] Trial 8 finished with value: -1.0457131765525942 and parameters: {'alpha': 0.09644921218755022}. Best is trial 1 with value: -1.0457131723424589.\n",
      "[I 2024-12-31 15:37:22,599] Trial 9 finished with value: -1.0457131761508296 and parameters: {'alpha': 0.21745470981373619}. Best is trial 1 with value: -1.0457131723424589.\n",
      "[I 2024-12-31 15:37:23,284] Trial 10 finished with value: -1.0457131712482295 and parameters: {'alpha': 1.7113619142286258}. Best is trial 10 with value: -1.0457131712482295.\n",
      "[I 2024-12-31 15:37:23,836] Trial 11 finished with value: -1.0457131729123896 and parameters: {'alpha': 1.200619640751131}. Best is trial 10 with value: -1.0457131712482295.\n",
      "[I 2024-12-31 15:37:24,531] Trial 12 finished with value: -1.0457131716535542 and parameters: {'alpha': 1.5866132785281857}. Best is trial 10 with value: -1.0457131712482295.\n",
      "[I 2024-12-31 15:37:25,211] Trial 13 finished with value: -1.0457131753725977 and parameters: {'alpha': 0.45244761836187064}. Best is trial 10 with value: -1.0457131712482295.\n",
      "[I 2024-12-31 15:37:25,761] Trial 14 finished with value: -1.0457131707423886 and parameters: {'alpha': 1.8673674674346594}. Best is trial 14 with value: -1.0457131707423886.\n",
      "[I 2024-12-31 15:37:26,272] Trial 15 finished with value: -1.0457131768279093 and parameters: {'alpha': 0.0136495105221561}. Best is trial 14 with value: -1.0457131707423886.\n",
      "[I 2024-12-31 15:37:26,848] Trial 16 finished with value: -1.0457131752428528 and parameters: {'alpha': 0.4917025597066839}. Best is trial 14 with value: -1.0457131707423886.\n",
      "[I 2024-12-31 15:37:27,456] Trial 17 finished with value: -1.0457131766712784 and parameters: {'alpha': 0.06074339621054667}. Best is trial 14 with value: -1.0457131707423886.\n",
      "[I 2024-12-31 15:37:28,034] Trial 18 finished with value: -1.045713176001859 and parameters: {'alpha': 0.2623759749912418}. Best is trial 14 with value: -1.0457131707423886.\n",
      "[I 2024-12-31 15:37:28,574] Trial 19 finished with value: -1.0457131704238019 and parameters: {'alpha': 1.9658057898287142}. Best is trial 19 with value: -1.0457131704238019.\n",
      "[I 2024-12-31 15:37:29,083] Trial 20 finished with value: -1.045713176776502 and parameters: {'alpha': 0.02910256395183978}. Best is trial 19 with value: -1.0457131704238019.\n",
      "[I 2024-12-31 15:37:29,629] Trial 21 finished with value: -1.0457131714056507 and parameters: {'alpha': 1.6628846360446994}. Best is trial 19 with value: -1.0457131704238019.\n",
      "[I 2024-12-31 15:37:30,240] Trial 22 finished with value: -1.0457131744943546 and parameters: {'alpha': 0.7185998347918221}. Best is trial 19 with value: -1.0457131704238019.\n",
      "[I 2024-12-31 15:37:30,825] Trial 23 finished with value: -1.0457131706973886 and parameters: {'alpha': 1.8812631586060724}. Best is trial 19 with value: -1.0457131704238019.\n",
      "[I 2024-12-31 15:37:31,392] Trial 24 finished with value: -1.0457131740701806 and parameters: {'alpha': 0.8475139873279738}. Best is trial 19 with value: -1.0457131704238019.\n",
      "[I 2024-12-31 15:37:31,985] Trial 25 finished with value: -1.0457131755678333 and parameters: {'alpha': 0.39341996684744557}. Best is trial 19 with value: -1.0457131704238019.\n",
      "[I 2024-12-31 15:37:32,547] Trial 26 finished with value: -1.045713176424781 and parameters: {'alpha': 0.13492183674270117}. Best is trial 19 with value: -1.0457131704238019.\n",
      "[I 2024-12-31 15:37:33,081] Trial 27 finished with value: -1.0457131703519815 and parameters: {'alpha': 1.9880169610274376}. Best is trial 27 with value: -1.0457131703519815.\n",
      "[I 2024-12-31 15:37:33,571] Trial 28 finished with value: -1.0457131739617058 and parameters: {'alpha': 0.8805201461304338}. Best is trial 27 with value: -1.0457131703519815.\n",
      "[I 2024-12-31 15:37:34,183] Trial 29 finished with value: -1.0457131768100059 and parameters: {'alpha': 0.01903093359028286}. Best is trial 27 with value: -1.0457131703519815.\n",
      "[I 2024-12-31 15:37:34,738] Trial 30 finished with value: -1.0457131752238844 and parameters: {'alpha': 0.49744339909265994}. Best is trial 27 with value: -1.0457131703519815.\n",
      "[I 2024-12-31 15:37:35,338] Trial 31 finished with value: -1.0457131703736398 and parameters: {'alpha': 1.9813181759300438}. Best is trial 27 with value: -1.0457131703519815.\n",
      "[I 2024-12-31 15:37:35,986] Trial 32 finished with value: -1.0457131734003764 and parameters: {'alpha': 1.0515713837048843}. Best is trial 27 with value: -1.0457131703519815.\n",
      "[I 2024-12-31 15:37:36,550] Trial 33 finished with value: -1.0457131735217442 and parameters: {'alpha': 1.014551637164143}. Best is trial 27 with value: -1.0457131703519815.\n",
      "[I 2024-12-31 15:37:37,106] Trial 34 finished with value: -1.0457131705814455 and parameters: {'alpha': 1.917078649419156}. Best is trial 27 with value: -1.0457131703519815.\n",
      "[I 2024-12-31 15:37:37,733] Trial 35 finished with value: -1.0457131758556595 and parameters: {'alpha': 0.30649000635240353}. Best is trial 27 with value: -1.0457131703519815.\n",
      "[I 2024-12-31 15:37:38,294] Trial 36 finished with value: -1.045713174850849 and parameters: {'alpha': 0.6104405368816971}. Best is trial 27 with value: -1.0457131703519815.\n",
      "[I 2024-12-31 15:37:38,845] Trial 37 finished with value: -1.0457131763160532 and parameters: {'alpha': 0.1676662953939695}. Best is trial 27 with value: -1.0457131703519815.\n",
      "[I 2024-12-31 15:37:39,376] Trial 38 finished with value: -1.0457131768502212 and parameters: {'alpha': 0.006943754532109919}. Best is trial 27 with value: -1.0457131703519815.\n",
      "[I 2024-12-31 15:37:39,949] Trial 39 finished with value: -1.0457131728091436 and parameters: {'alpha': 1.232196008103256}. Best is trial 27 with value: -1.0457131703519815.\n",
      "[I 2024-12-31 15:37:40,465] Trial 40 finished with value: -1.045713170344499 and parameters: {'alpha': 1.990331362835953}. Best is trial 40 with value: -1.045713170344499.\n",
      "[I 2024-12-31 15:37:41,075] Trial 41 finished with value: -1.0457131728646387 and parameters: {'alpha': 1.2152217842479827}. Best is trial 40 with value: -1.045713170344499.\n",
      "[I 2024-12-31 15:37:41,672] Trial 42 finished with value: -1.0457131744628694 and parameters: {'alpha': 0.7281605790341723}. Best is trial 40 with value: -1.045713170344499.\n",
      "[I 2024-12-31 15:37:42,249] Trial 43 finished with value: -1.0457131703652591 and parameters: {'alpha': 1.9839101957233705}. Best is trial 40 with value: -1.045713170344499.\n",
      "[I 2024-12-31 15:37:42,784] Trial 44 finished with value: -1.0457131731452796 and parameters: {'alpha': 1.129446581642454}. Best is trial 40 with value: -1.045713170344499.\n",
      "[I 2024-12-31 15:37:43,274] Trial 45 finished with value: -1.0457131703423448 and parameters: {'alpha': 1.9909977540337367}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:43,764] Trial 46 finished with value: -1.0457131722997435 and parameters: {'alpha': 1.388202209504086}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:44,365] Trial 47 finished with value: -1.0457131757456821 and parameters: {'alpha': 0.33969273780472864}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:44,915] Trial 48 finished with value: -1.0457131749693684 and parameters: {'alpha': 0.5745194836708828}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:45,447] Trial 49 finished with value: -1.0457131723992132 and parameters: {'alpha': 1.3577112461118575}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:45,994] Trial 50 finished with value: -1.0457131740218994 and parameters: {'alpha': 0.8622027483445811}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:46,512] Trial 51 finished with value: -1.045713170640711 and parameters: {'alpha': 1.8987687763008203}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:47,027] Trial 52 finished with value: -1.0457131768675596 and parameters: {'alpha': 0.0017329955348196599}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:47,490] Trial 53 finished with value: -1.0457131704394103 and parameters: {'alpha': 1.960979780588883}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:48,004] Trial 54 finished with value: -1.0457131731912237 and parameters: {'alpha': 1.1154143837089494}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:48,531] Trial 55 finished with value: -1.0457131720788297 and parameters: {'alpha': 1.4559686613426917}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:49,110] Trial 56 finished with value: -1.0457131747172053 and parameters: {'alpha': 0.6509678522844533}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:49,656] Trial 57 finished with value: -1.0457131767137604 and parameters: {'alpha': 0.04796729370175901}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:50,277] Trial 58 finished with value: -1.045713172007426 and parameters: {'alpha': 1.4778864637197948}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:50,848] Trial 59 finished with value: -1.0457131740569798 and parameters: {'alpha': 0.8515298301969273}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:51,457] Trial 60 finished with value: -1.0457131715355577 and parameters: {'alpha': 1.6229061707040335}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:52,050] Trial 61 finished with value: -1.0457131706872436 and parameters: {'alpha': 1.8843962144618271}. Best is trial 45 with value: -1.0457131703423448.\n",
      "[I 2024-12-31 15:37:52,631] Trial 62 finished with value: -1.045713170328384 and parameters: {'alpha': 1.9953163283000404}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:37:53,138] Trial 63 finished with value: -1.0457131720518305 and parameters: {'alpha': 1.4642554294520966}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:37:53,687] Trial 64 finished with value: -1.0457131736980738 and parameters: {'alpha': 0.9608025374621519}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:37:54,240] Trial 65 finished with value: -1.0457131726113136 and parameters: {'alpha': 1.2927402977494291}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:37:54,744] Trial 66 finished with value: -1.0457131743882633 and parameters: {'alpha': 0.7508203419896003}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:37:55,362] Trial 67 finished with value: -1.0457131753966595 and parameters: {'alpha': 0.4451701156367786}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:37:56,044] Trial 68 finished with value: -1.0457131734984961 and parameters: {'alpha': 1.021641209747982}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:37:56,638] Trial 69 finished with value: -1.0457131716782802 and parameters: {'alpha': 1.5790107065286023}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:37:57,156] Trial 70 finished with value: -1.0457131704165241 and parameters: {'alpha': 1.9680562274923334}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:37:57,697] Trial 71 finished with value: -1.0457131706322103 and parameters: {'alpha': 1.9013947509746434}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:37:58,214] Trial 72 finished with value: -1.0457131718054327 and parameters: {'alpha': 1.5399275890446342}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:37:58,765] Trial 73 finished with value: -1.0457131730076825 and parameters: {'alpha': 1.1714885059910904}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:37:59,262] Trial 74 finished with value: -1.0457131704547256 and parameters: {'alpha': 1.9562446857346265}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:37:59,811] Trial 75 finished with value: -1.0457131738725054 and parameters: {'alpha': 0.9076733197593927}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:00,486] Trial 76 finished with value: -1.0457131768475563 and parameters: {'alpha': 0.0077445651023685886}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:01,020] Trial 77 finished with value: -1.045713176521432 and parameters: {'alpha': 0.1058272175485415}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:01,586] Trial 78 finished with value: -1.0457131727287605 and parameters: {'alpha': 1.2567901514269795}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:02,166] Trial 79 finished with value: -1.0457131750916833 and parameters: {'alpha': 0.5374677175115732}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:02,759] Trial 80 finished with value: -1.0457131717227637 and parameters: {'alpha': 1.5653352148490007}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:03,334] Trial 81 finished with value: -1.0457131703381506 and parameters: {'alpha': 1.9922951352663107}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:03,884] Trial 82 finished with value: -1.0457131703288345 and parameters: {'alpha': 1.9951768462535764}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:04,400] Trial 83 finished with value: -1.0457131733897995 and parameters: {'alpha': 1.0547985062603538}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:04,923] Trial 84 finished with value: -1.0457131715400412 and parameters: {'alpha': 1.6215268473511255}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:05,440] Trial 85 finished with value: -1.0457131744052925 and parameters: {'alpha': 0.745647462141603}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:05,944] Trial 86 finished with value: -1.0457131726386855 and parameters: {'alpha': 1.2843601093295145}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:06,499] Trial 87 finished with value: -1.045713171273989 and parameters: {'alpha': 1.703427011804793}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:07,076] Trial 88 finished with value: -1.045713170421757 and parameters: {'alpha': 1.9664381911984627}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:07,636] Trial 89 finished with value: -1.045713173410388 and parameters: {'alpha': 1.048516924610979}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:08,227] Trial 90 finished with value: -1.0457131727363629 and parameters: {'alpha': 1.2544637762865807}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:08,766] Trial 91 finished with value: -1.045713170362956 and parameters: {'alpha': 1.9846224990595283}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:09,319] Trial 92 finished with value: -1.0457131722114772 and parameters: {'alpha': 1.4152703171230026}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:09,936] Trial 93 finished with value: -1.0457131715622068 and parameters: {'alpha': 1.614707881000007}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:10,562] Trial 94 finished with value: -1.0457131711955205 and parameters: {'alpha': 1.727601101554327}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:11,155] Trial 95 finished with value: -1.0457131724738193 and parameters: {'alpha': 1.3348507178350393}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:11,665] Trial 96 finished with value: -1.0457131703361182 and parameters: {'alpha': 1.992923778806976}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:12,185] Trial 97 finished with value: -1.0457131739686918 and parameters: {'alpha': 0.8783939463584911}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:12,759] Trial 98 finished with value: -1.0457131767687113 and parameters: {'alpha': 0.031444669640127355}. Best is trial 62 with value: -1.045713170328384.\n",
      "[I 2024-12-31 15:38:13,379] Trial 99 finished with value: -1.0457131746970285 and parameters: {'alpha': 0.6570885412332516}. Best is trial 62 with value: -1.045713170328384.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-1, 3, log=True)\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "\n",
    "    score = cross_val_score(ridge, stacked_train, y_log_nan, cv=5, scoring='neg_root_mean_squared_error')\n",
    "    return score.mean()\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.045713170328384, {'alpha': 1.9953163283000404})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value, study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = 1.9953163283000404\n",
    "\n",
    "meta_models_rid = []\n",
    "meta_rid_OOF = np.zeros(len(stacked_train))\n",
    "meta_rid_preds = np.zeros(len(stacked_test))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, val_idx in kf.split(stacked_train):\n",
    "    x_train, x_val = stacked_train[train_idx], stacked_train[val_idx]\n",
    "    y_train, y_val = y_log_nan[train_idx], y_log_nan[val_idx]\n",
    "\n",
    "    meta_model = Ridge(alpha=best_alpha)\n",
    "    meta_model.fit(x_train, y_train)\n",
    "\n",
    "    meta_rid_OOF[val_idx] += meta_model.predict(x_val)\n",
    "    meta_rid_preds += meta_model.predict(stacked_test) / kf.n_splits\n",
    "    meta_models_rid.append(meta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0457157512245219"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_squared_error(meta_rid_OOF, y_log_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 16:14:24,009] A new study created in memory with name: no-name-52369bce-13c2-4d1d-aff6-ac2c260bb3c5\n",
      "[I 2024-12-31 16:14:24,022] Trial 0 finished with value: 1.0452503546659975 and parameters: {'w1': 0.6295863361351248}. Best is trial 0 with value: 1.0452503546659975.\n",
      "[I 2024-12-31 16:14:24,032] Trial 1 finished with value: 1.0453462350085845 and parameters: {'w1': 0.4246309606331323}. Best is trial 0 with value: 1.0452503546659975.\n",
      "[I 2024-12-31 16:14:24,040] Trial 2 finished with value: 1.0452398526936597 and parameters: {'w1': 0.6628750015592575}. Best is trial 2 with value: 1.0452398526936597.\n",
      "[I 2024-12-31 16:14:24,048] Trial 3 finished with value: 1.0454249824639277 and parameters: {'w1': 0.30772061520210947}. Best is trial 2 with value: 1.0452398526936597.\n",
      "[I 2024-12-31 16:14:24,055] Trial 4 finished with value: 1.045425824630064 and parameters: {'w1': 0.30659624839682786}. Best is trial 2 with value: 1.0452398526936597.\n",
      "[I 2024-12-31 16:14:24,063] Trial 5 finished with value: 1.0452723299044537 and parameters: {'w1': 0.5708772083149051}. Best is trial 2 with value: 1.0452398526936597.\n",
      "[I 2024-12-31 16:14:24,070] Trial 6 finished with value: 1.0455711946584052 and parameters: {'w1': 0.13716741611026206}. Best is trial 2 with value: 1.0452398526936597.\n",
      "[I 2024-12-31 16:14:24,081] Trial 7 finished with value: 1.0453469348728663 and parameters: {'w1': 0.42346371876073974}. Best is trial 2 with value: 1.0452398526936597.\n",
      "[I 2024-12-31 16:14:24,089] Trial 8 finished with value: 1.04547917213165 and parameters: {'w1': 0.2393010547664145}. Best is trial 2 with value: 1.0452398526936597.\n",
      "[I 2024-12-31 16:14:24,097] Trial 9 finished with value: 1.0452435782895146 and parameters: {'w1': 0.6505419473968521}. Best is trial 2 with value: 1.0452398526936597.\n",
      "[I 2024-12-31 16:14:24,112] Trial 10 finished with value: 1.0452109706603447 and parameters: {'w1': 0.9809229441939328}. Best is trial 10 with value: 1.0452109706603447.\n",
      "[I 2024-12-31 16:14:24,132] Trial 11 finished with value: 1.0452118230843346 and parameters: {'w1': 0.9881942698915032}. Best is trial 10 with value: 1.0452109706603447.\n",
      "[I 2024-12-31 16:14:24,145] Trial 12 finished with value: 1.0452130911827595 and parameters: {'w1': 0.998085357697635}. Best is trial 10 with value: 1.0452109706603447.\n",
      "[I 2024-12-31 16:14:24,160] Trial 13 finished with value: 1.0452104395265833 and parameters: {'w1': 0.9760714502093434}. Best is trial 13 with value: 1.0452104395265833.\n",
      "[I 2024-12-31 16:14:24,170] Trial 14 finished with value: 1.0452067657064523 and parameters: {'w1': 0.8586577644638336}. Best is trial 14 with value: 1.0452067657064523.\n",
      "[I 2024-12-31 16:14:24,181] Trial 15 finished with value: 1.0452100618979139 and parameters: {'w1': 0.8133590649789343}. Best is trial 14 with value: 1.0452067657064523.\n",
      "[I 2024-12-31 16:14:24,194] Trial 16 finished with value: 1.04521327828177 and parameters: {'w1': 0.7863343628674486}. Best is trial 14 with value: 1.0452067657064523.\n",
      "[I 2024-12-31 16:14:24,208] Trial 17 finished with value: 1.0452120271630057 and parameters: {'w1': 0.7959471682328391}. Best is trial 14 with value: 1.0452067657064523.\n",
      "[I 2024-12-31 16:14:24,221] Trial 18 finished with value: 1.0452090358613073 and parameters: {'w1': 0.8241806551261633}. Best is trial 14 with value: 1.0452067657064523.\n",
      "[I 2024-12-31 16:14:24,233] Trial 19 finished with value: 1.045206860140491 and parameters: {'w1': 0.8565655101260544}. Best is trial 14 with value: 1.0452067657064523.\n",
      "[I 2024-12-31 16:14:24,244] Trial 20 finished with value: 1.0457118395802638 and parameters: {'w1': 0.0034334329578538103}. Best is trial 14 with value: 1.0452067657064523.\n",
      "[I 2024-12-31 16:14:24,255] Trial 21 finished with value: 1.0452064768848417 and parameters: {'w1': 0.866050268790626}. Best is trial 21 with value: 1.0452064768848417.\n",
      "[I 2024-12-31 16:14:24,266] Trial 22 finished with value: 1.045206246300719 and parameters: {'w1': 0.8739170428088979}. Best is trial 22 with value: 1.045206246300719.\n",
      "[I 2024-12-31 16:14:24,277] Trial 23 finished with value: 1.0452060199292705 and parameters: {'w1': 0.8903708336458085}. Best is trial 23 with value: 1.0452060199292705.\n",
      "[I 2024-12-31 16:14:24,289] Trial 24 finished with value: 1.0452212515418118 and parameters: {'w1': 0.7385492533631659}. Best is trial 23 with value: 1.0452060199292705.\n",
      "[I 2024-12-31 16:14:24,301] Trial 25 finished with value: 1.0452060163700985 and parameters: {'w1': 0.8938143136266649}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,312] Trial 26 finished with value: 1.045206229027999 and parameters: {'w1': 0.911159107169828}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,324] Trial 27 finished with value: 1.0452225415311585 and parameters: {'w1': 0.7321475774632861}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,336] Trial 28 finished with value: 1.0452060577072926 and parameters: {'w1': 0.9009922963079285}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,347] Trial 29 finished with value: 1.0452961967071548 and parameters: {'w1': 0.5173708966271884}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,358] Trial 30 finished with value: 1.0452264081429188 and parameters: {'w1': 0.7143287958101989}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,371] Trial 31 finished with value: 1.045206966741305 and parameters: {'w1': 0.9314615361128274}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,384] Trial 32 finished with value: 1.0452065467491263 and parameters: {'w1': 0.9217137626657768}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,395] Trial 33 finished with value: 1.0452063533185072 and parameters: {'w1': 0.9158729332803358}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,409] Trial 34 finished with value: 1.0452601239786428 and parameters: {'w1': 0.602020095736566}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,423] Trial 35 finished with value: 1.0452296878269511 and parameters: {'w1': 0.7005039712076264}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,436] Trial 36 finished with value: 1.0452160323523727 and parameters: {'w1': 0.7677488637478396}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,447] Trial 37 finished with value: 1.0452064385130286 and parameters: {'w1': 0.9186095093973112}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,461] Trial 38 finished with value: 1.0453394576226296 and parameters: {'w1': 0.4360885844881443}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,472] Trial 39 finished with value: 1.0452352919557015 and parameters: {'w1': 0.678938216857627}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,485] Trial 40 finished with value: 1.045271100393219 and parameters: {'w1': 0.5738765444821796}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,498] Trial 41 finished with value: 1.045206103859652 and parameters: {'w1': 0.8811685683349179}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,512] Trial 42 finished with value: 1.045206020015148 and parameters: {'w1': 0.8954569607728329}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,534] Trial 43 finished with value: 1.0452090531205442 and parameters: {'w1': 0.8239845694252977}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,550] Trial 44 finished with value: 1.045207978886686 and parameters: {'w1': 0.9483050314765132}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,564] Trial 45 finished with value: 1.0452060446829576 and parameters: {'w1': 0.8861844661298386}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,578] Trial 46 finished with value: 1.0452089076532964 and parameters: {'w1': 0.960146242395486}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,593] Trial 47 finished with value: 1.045215269883767 and parameters: {'w1': 0.7726065070828597}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,607] Trial 48 finished with value: 1.0452069905200745 and parameters: {'w1': 0.8538606972204328}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,620] Trial 49 finished with value: 1.0452119377239142 and parameters: {'w1': 0.989130260346886}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,631] Trial 50 finished with value: 1.0454563401952641 and parameters: {'w1': 0.26721621522816413}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,642] Trial 51 finished with value: 1.0452060406736965 and parameters: {'w1': 0.8866686473695737}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,654] Trial 52 finished with value: 1.0452060266494654 and parameters: {'w1': 0.8887886858918518}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,666] Trial 53 finished with value: 1.0452085367708341 and parameters: {'w1': 0.8301152661999163}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,677] Trial 54 finished with value: 1.0452153097361525 and parameters: {'w1': 0.7723477618470566}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,687] Trial 55 finished with value: 1.0452079803188152 and parameters: {'w1': 0.9483252377205675}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,699] Trial 56 finished with value: 1.0452485281037591 and parameters: {'w1': 0.6350671770206375}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,710] Trial 57 finished with value: 1.045208121426865 and parameters: {'w1': 0.8355201062464386}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,723] Trial 58 finished with value: 1.045206094569257 and parameters: {'w1': 0.8818049602164488}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,737] Trial 59 finished with value: 1.0452111477623234 and parameters: {'w1': 0.8033191501505735}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,750] Trial 60 finished with value: 1.045209519745722 and parameters: {'w1': 0.9669216406162939}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,763] Trial 61 finished with value: 1.0452060463300687 and parameters: {'w1': 0.899806008451616}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,776] Trial 62 finished with value: 1.0452060343958256 and parameters: {'w1': 0.8982878722934272}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,788] Trial 63 finished with value: 1.0452066191698914 and parameters: {'w1': 0.8621852630351194}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,800] Trial 64 finished with value: 1.0453826680959737 and parameters: {'w1': 0.36730019176820156}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,812] Trial 65 finished with value: 1.0452194683228377 and parameters: {'w1': 0.7478631289713464}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,824] Trial 66 finished with value: 1.0452131697668081 and parameters: {'w1': 0.9986678761465229}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,836] Trial 67 finished with value: 1.045206033396149 and parameters: {'w1': 0.8876606129782697}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,847] Trial 68 finished with value: 1.0455174341623836 and parameters: {'w1': 0.1950182812163621}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,858] Trial 69 finished with value: 1.0452117681115174 and parameters: {'w1': 0.7980592314952384}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,871] Trial 70 finished with value: 1.0452077974738125 and parameters: {'w1': 0.945682919584565}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,882] Trial 71 finished with value: 1.0452060164317583 and parameters: {'w1': 0.8938656388191749}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,894] Trial 72 finished with value: 1.0452074883701612 and parameters: {'w1': 0.8449151297423649}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,906] Trial 73 finished with value: 1.0452063644917262 and parameters: {'w1': 0.9162501144661798}. Best is trial 25 with value: 1.0452060163700985.\n",
      "[I 2024-12-31 16:14:24,917] Trial 74 finished with value: 1.0452060159062042 and parameters: {'w1': 0.8932313048306385}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:24,928] Trial 75 finished with value: 1.0452108781738663 and parameters: {'w1': 0.8057038283899459}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:24,940] Trial 76 finished with value: 1.0452095538873187 and parameters: {'w1': 0.9672813918019614}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:24,951] Trial 77 finished with value: 1.0452068023295886 and parameters: {'w1': 0.9279698600402349}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:24,963] Trial 78 finished with value: 1.0452078595298007 and parameters: {'w1': 0.8392071137120606}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:24,976] Trial 79 finished with value: 1.045206043203018 and parameters: {'w1': 0.8994423735425627}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:24,989] Trial 80 finished with value: 1.045301018331968 and parameters: {'w1': 0.5074620999997335}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,003] Trial 81 finished with value: 1.045206036043902 and parameters: {'w1': 0.8872794164842751}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,016] Trial 82 finished with value: 1.045206723815772 and parameters: {'w1': 0.8596279816048531}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,029] Trial 83 finished with value: 1.0452068585822245 and parameters: {'w1': 0.9292023354712302}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,042] Trial 84 finished with value: 1.0452063902957711 and parameters: {'w1': 0.8687026513278383}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,055] Trial 85 finished with value: 1.0452094694540133 and parameters: {'w1': 0.819412884155785}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,070] Trial 86 finished with value: 1.0457150017513759 and parameters: {'w1': 0.0006568253827450299}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,085] Trial 87 finished with value: 1.0452060293124532 and parameters: {'w1': 0.8974912034796884}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,100] Trial 88 finished with value: 1.045209478876791 and parameters: {'w1': 0.9664886906392478}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,115] Trial 89 finished with value: 1.0452070610098954 and parameters: {'w1': 0.9333277547150248}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,129] Trial 90 finished with value: 1.0452181491297279 and parameters: {'w1': 0.7551580453172485}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,142] Trial 91 finished with value: 1.045206046338352 and parameters: {'w1': 0.899806946160297}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,156] Trial 92 finished with value: 1.0452060333898083 and parameters: {'w1': 0.8876615591142476}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,171] Trial 93 finished with value: 1.0452070246088763 and parameters: {'w1': 0.8531838672411749}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,185] Trial 94 finished with value: 1.045211066266908 and parameters: {'w1': 0.9817681120628695}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,199] Trial 95 finished with value: 1.0452077395070842 and parameters: {'w1': 0.9448171667962173}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,212] Trial 96 finished with value: 1.0452061970927946 and parameters: {'w1': 0.9097361418107018}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,225] Trial 97 finished with value: 1.0452061751564052 and parameters: {'w1': 0.8771168391785301}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,240] Trial 98 finished with value: 1.045658078987088 and parameters: {'w1': 0.05203945743116811}. Best is trial 74 with value: 1.0452060159062042.\n",
      "[I 2024-12-31 16:14:25,257] Trial 99 finished with value: 1.045213298695234 and parameters: {'w1': 0.7861846977827573}. Best is trial 74 with value: 1.0452060159062042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Weights: {'w1': 0.8932313048306385}\n",
      "Best RMSE: 1.0452\n",
      "CPU times: user 1.23 s, sys: 35.9 ms, total: 1.26 s\n",
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def objective(trial):\n",
    "    w1 = trial.suggest_float('w1', 0.0, 1.0)\n",
    "    w2 = 1.0 - w1\n",
    "\n",
    "    if w2 < 0 or w2 > 1:\n",
    "        return float('inf')\n",
    "    \n",
    "    ensemble_vote = (w1 * meta_oof) + (w2 * meta_rid_OOF)\n",
    "    rmse = np.sqrt(mean_squared_error(y_log, ensemble_vote))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "study_vote = optuna.create_study(direction='minimize')\n",
    "study_vote.optimize(objective, n_trials=100)\n",
    "\n",
    "# ìµì  ê°ì¤ì¹ ë° RMSE ì¶ë ¥\n",
    "print(f\"Best Weights: {study_vote.best_params}\")\n",
    "print(f\"Best RMSE: {study_vote.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0452060159062042"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_weights = study_vote.best_params\n",
    "best_weights['w2'] = 1 - best_weights['w1']\n",
    "blend_oof = best_weights['w1'] * meta_oof + best_weights['w2'] * meta_rid_OOF\n",
    "root_mean_squared_error(blend_oof, y_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_preds = best_weights['w1'] * meta_pred + best_weights['w2'] * meta_rid_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_train = np.column_stack((meta_oof, meta_rid_OOF, blend_oof, train['transformed_Annual_Income'], train['Credit Score']))\n",
    "hybrid_test = np.column_stack((meta_pred, meta_rid_preds, blend_preds, test['transformed_Annual_Income'], test['Credit Score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 16:21:11,307] A new study created in memory with name: no-name-d84824a3-6467-45ef-8d03-6819aa8521b5\n",
      "[I 2024-12-31 16:22:42,815] Trial 0 finished with value: 1.0454540046966052 and parameters: {'learning_rate': 0.03751655787285152, 'depth': 12, 'l2_leaf_reg': 7.31996621871987, 'bagging_temperature': 0.5990598257128396, 'random_strength': 1.5610303857839227, 'border_count': 66, 'colsample_bylevel': 0.6232334448672797}. Best is trial 0 with value: 1.0454540046966052.\n",
      "[I 2024-12-31 16:23:48,153] Trial 1 finished with value: 1.0453203154173347 and parameters: {'learning_rate': 0.08663099696291603, 'depth': 9, 'l2_leaf_reg': 7.080754970702675, 'bagging_temperature': 0.021563909801506645, 'random_strength': 9.699128611767781, 'border_count': 218, 'colsample_bylevel': 0.6849356442713105}. Best is trial 1 with value: 1.0453203154173347.\n",
      "[I 2024-12-31 16:25:02,494] Trial 2 finished with value: 1.0454856036464477 and parameters: {'learning_rate': 0.01826431422398935, 'depth': 4, 'l2_leaf_reg': 3.0424920053710816, 'bagging_temperature': 0.5252316752006057, 'random_strength': 4.320018241402516, 'border_count': 97, 'colsample_bylevel': 0.8447411578889518}. Best is trial 1 with value: 1.0453203154173347.\n",
      "[I 2024-12-31 16:26:25,457] Trial 3 finished with value: 1.0456947170355666 and parameters: {'learning_rate': 0.01403543667913898, 'depth': 5, 'l2_leaf_reg': 3.663681796752588, 'bagging_temperature': 0.4566139142328189, 'random_strength': 7.851974437968744, 'border_count': 76, 'colsample_bylevel': 0.8056937753654446}. Best is trial 1 with value: 1.0453203154173347.\n",
      "[I 2024-12-31 16:27:30,858] Trial 4 finished with value: 1.0452745830239603 and parameters: {'learning_rate': 0.059282215429318046, 'depth': 3, 'l2_leaf_reg': 6.075487764529194, 'bagging_temperature': 0.17135359956360424, 'random_strength': 0.65145087825981, 'border_count': 244, 'colsample_bylevel': 0.9862528132298237}. Best is trial 4 with value: 1.0452745830239603.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 24s, sys: 34.9 s, total: 15min 58s\n",
      "Wall time: 6min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": 300,\n",
    "        \"loss_function\": \"RMSE\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 1e-1),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 3, 12),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-4, 10.0),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 1e-3, 1.0),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 1e-3, 10.0),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.6, 1.0),\n",
    "        \"random_seed\": SEED,\n",
    "        \"verbose\": 0\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, val_idx in folds.split(hybrid_train):\n",
    "        x_train, x_val = hybrid_train[train_idx], hybrid_train[val_idx]\n",
    "        y_train, y_val = y_log[train_idx], y_log[val_idx]\n",
    "\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(\n",
    "            x_train, y_train,\n",
    "            eval_set=(x_val, y_val),\n",
    "            early_stopping_rounds=50,\n",
    "        )\n",
    "        preds = model.predict(x_val)\n",
    "        score = np.sqrt(mean_squared_log_error(np.expm1(y_val), np.expm1(preds)))\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "study.optimize(objective, n_trials=5)\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.059282215429318046,\n",
       "  'depth': 3,\n",
       "  'l2_leaf_reg': 6.075487764529194,\n",
       "  'bagging_temperature': 0.17135359956360424,\n",
       "  'random_strength': 0.65145087825981,\n",
       "  'border_count': 244,\n",
       "  'colsample_bylevel': 0.9862528132298237},\n",
       " 1.0452745830239603)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Premium Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200000</td>\n",
       "      <td>1102.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200001</td>\n",
       "      <td>1102.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1200002</td>\n",
       "      <td>1102.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200003</td>\n",
       "      <td>1102.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200004</td>\n",
       "      <td>1102.545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Premium Amount\n",
       "0  1200000        1102.545\n",
       "1  1200001        1102.545\n",
       "2  1200002        1102.545\n",
       "3  1200003        1102.545\n",
       "4  1200004        1102.545"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = np.expm1(meta_pred)\n",
    "# final_preds = np.expm1(blend_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Premium Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200000</td>\n",
       "      <td>737.820780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200001</td>\n",
       "      <td>796.654444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1200002</td>\n",
       "      <td>802.376819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200003</td>\n",
       "      <td>806.981530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200004</td>\n",
       "      <td>747.843785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Premium Amount\n",
       "0  1200000      737.820780\n",
       "1  1200001      796.654444\n",
       "2  1200002      802.376819\n",
       "3  1200003      806.981530\n",
       "4  1200004      747.843785"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['Premium Amount'] = final_preds\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââââââââââââââââââââââââââââââ| 19.8M/19.8M [00:00<00:00, 38.0MB/s]\n",
      "Successfully submitted to Regression with an Insurance Dataset"
     ]
    }
   ],
   "source": [
    "submission.to_csv('./data/04_06.csv', index=False)\n",
    "!kaggle competitions submit -c playground-series-s4e12 -f \"./data/04_06.csv\" -m \"04_06_stacking_lgbm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¤ë ì ì¶ íì: 5\n",
      "ë¨ì ì ì¶ íì: 0\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from datetime import datetime\n",
    "\n",
    "# Kaggle API ì¸ì¦\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# ëí ì´ë¦ ì¤ì \n",
    "competition = 'playground-series-s4e12'\n",
    "\n",
    "# ì ì¶ ê¸°ë¡ ë¶ë¬ì¤ê¸°\n",
    "submissions = api.competition_submissions(competition)\n",
    "\n",
    "# ì¤ë ë ì§ (UTC ê¸°ì¤)\n",
    "today = datetime.utcnow().date()\n",
    "\n",
    "# ì ì¶ ë ì§ ë¹êµ ë° ì¤ë ì ì¶ íì ê³ì°\n",
    "today_submissions = [\n",
    "    sub for sub in submissions \n",
    "    if sub.date.date() == today  # ì¬ê¸°ì ë°ë¡ date() í¸ì¶\n",
    "]\n",
    "\n",
    "# ê²°ê³¼ ì¶ë ¥\n",
    "used_submissions = len(today_submissions)\n",
    "remaining_submissions = 5 - used_submissions\n",
    "\n",
    "print(f\"ì¤ë ì ì¶ íì: {used_submissions}\")\n",
    "print(f\"ë¨ì ì ì¶ íì: {remaining_submissions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìµì¢ ì±ì \n",
    "- public score : 1.04439\n",
    "- 378/2350 , 16.09%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16085106382978723"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "378/2350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
