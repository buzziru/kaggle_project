{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qq pytorch_tabnet\n",
    "# !pip install -q lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/muhammadabdullah0303/AbdML /teamspace/studios/this_studio/AbdML/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 830 ms, sys: 750 ms, total: 1.58 s\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "import category_encoders as ce\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, PowerTransformer, OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping  \n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier, Pool\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2024)\n",
    "random.seed(2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.22 s, sys: 2.69 s, total: 10.9 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def load_data():    \n",
    "    train = pd.read_csv('data/train.csv')\n",
    "    test = pd.read_csv('data/test.csv')    \n",
    "    all_df = pd.concat([train, test], sort=False).reset_index(drop=True)\n",
    "    return train, test, all_df\n",
    "\n",
    "def skewed(df, all_df):\n",
    "    pt = PowerTransformer(method='yeo-johnson')\n",
    "    pt.fit(df[['Annual Income']])\n",
    "    all_df['transformed_Annual_Income'] = pt.transform(all_df[['Annual Income']])\n",
    "\n",
    "    return all_df\n",
    "    \n",
    "def date(df):\n",
    "    df['Policy Start Date'] = pd.to_datetime(df['Policy Start Date'])\n",
    "    df['Year'] = df['Policy Start Date'].dt.year\n",
    "    df['Day'] = df['Policy Start Date'].dt.day\n",
    "    df['Month'] = df['Policy Start Date'].dt.month\n",
    "    df['Month_name'] = df['Policy Start Date'].dt.month_name()\n",
    "    df['Day_of_week'] = df['Policy Start Date'].dt.day_name()\n",
    "    df['Week'] = df['Policy Start Date'].dt.isocalendar().week\n",
    "    df['Year_sin'] = np.sin(2 * np.pi * df['Year'])\n",
    "    df['Year_cos'] = np.cos(2 * np.pi * df['Year'])\n",
    "    min_year = df['Year'].min()\n",
    "    max_year = df['Year'].max()\n",
    "    df['Year_sin'] = np.sin(2 * np.pi * (df['Year'] - min_year) / (max_year - min_year))\n",
    "    df['Year_cos'] = np.cos(2 * np.pi * (df['Year'] - min_year) / (max_year - min_year))\n",
    "    df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12) \n",
    "    df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)\n",
    "    df['Day_sin'] = np.sin(2 * np.pi * df['Day'] / 31)  \n",
    "    df['Day_cos'] = np.cos(2 * np.pi * df['Day'] / 31)\n",
    "    df['Group']=(df['Year']-2020)*48+df['Month']*4+df['Day']//7    \n",
    "    df.drop('Policy Start Date', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def fe(df):\n",
    "    df['contract length'] = pd.cut(\n",
    "        df[\"Insurance Duration\"].fillna(99),  \n",
    "        bins=[-float('inf'), 1, 3, float('inf')],  \n",
    "        labels=[0, 1, 2]  \n",
    "    ).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_nan_cols(df):\n",
    "    nan_cols = ['Marital Status', 'Customer Feedback', 'Health Score', 'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration']\n",
    "\n",
    "    for col in nan_cols:\n",
    "        col_name = col + '_NA'\n",
    "        df[col_name] = df[col].isnull().astype(int)\n",
    "    return df\n",
    "\n",
    "def get_encoding(df):\n",
    "    def encode_ordinal(df):\n",
    "        educ = {\"High School\":0, \"Bachelor's\":1, \"Master's\":2, \"PhD\":3}\n",
    "        policy = {'Basic':0, 'Comprehensive':1, 'Premium':2}\n",
    "        exerc = {'Rarely':0, 'Daily':1, 'Weekly':2, 'Monthly': 3}\n",
    "        feedback = {'Poor':0, 'Average':1, 'Good':2, \"Unknown\": 0}\n",
    "\n",
    "        df['Education Level'] = df['Education Level'].map(educ)\n",
    "        df['Policy Type'] = df['Policy Type'].map(policy)\n",
    "        df['Exercise Frequency'] = df['Exercise Frequency'].map(exerc)\n",
    "        df['Customer Feedback'] = df['Customer Feedback'].map(feedback)\n",
    "        return df\n",
    "\n",
    "    def encode_binary(df):\n",
    "        df['Gender'] = df['Gender'].map({'Male':0, 'Female':1})\n",
    "        df['Smoking Status'] = df['Smoking Status'].map({'Yes':1, 'No':0})\n",
    "        return df\n",
    "\n",
    "    def one_hot_dummies(df, categorical):\n",
    "        oh = pd.get_dummies(df[categorical])\n",
    "        df = df.drop(categorical, axis=1)\n",
    "        return pd.concat([df, oh], axis=1)\n",
    "        return df\n",
    "\n",
    "    df = encode_binary(df)\n",
    "    df = encode_ordinal(df)\n",
    "    \n",
    "    categorical_features = df.select_dtypes(include='object').columns\n",
    "    df = one_hot_dummies(df, categorical_features)\n",
    "    return df\n",
    "\n",
    "def add_new_features(df):\n",
    "    df['Income to Dependents Ratio'] = df['Annual Income'] / (df['Number of Dependents'].fillna(0) + 1)\n",
    "    df['Income_per_Dependent'] = df['Annual Income'] / (df['Number of Dependents'] + 1)\n",
    "    df['CreditScore_InsuranceDuration'] = df['Credit Score'] * df['Insurance Duration']\n",
    "    df['Health_Risk_Score'] = df['Smoking Status'].apply(lambda x: 1 if x == 'Smoker' else 0) + \\\n",
    "                                df['Exercise Frequency'].apply(lambda x: 1 if x == 'Low' else (0.5 if x == 'Medium' else 0)) + \\\n",
    "                                (100 - df['Health Score']) / 20\n",
    "    df['Credit_Health_Score'] = df['Credit Score'] * df['Health Score']\n",
    "    df['Health_Age_Interaction'] = df['Health Score'] * df['Age']\n",
    "    df['contract length'] = pd.cut(\n",
    "        df[\"Insurance Duration\"].fillna(99),  \n",
    "        bins=[-float('inf'), 1, 3, float('inf')],  \n",
    "        labels=[0, 1, 2]  \n",
    "    ).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def prep():\n",
    "    train, test, all_df = load_data()\n",
    "\n",
    "    all_df = skewed(train, all_df)\n",
    "    all_df = date(all_df)\n",
    "    all_df = fe(all_df)\n",
    "    all_df = get_nan_cols(all_df)\n",
    "    all_df = get_encoding(all_df)\n",
    "    all_df = add_new_features(all_df)\n",
    "\n",
    "    del all_df['Annual Income']\n",
    "    \n",
    "    train = all_df[~all_df['Premium Amount'].isnull()]\n",
    "    test = all_df[all_df['Premium Amount'].isnull()]\n",
    "\n",
    "    test.drop('Premium Amount', axis=1, inplace=True)\n",
    "\n",
    "    return train, test, all_df\n",
    "\n",
    "train, test, all_df = prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>Policy Type</th>\n",
       "      <th>Previous Claims</th>\n",
       "      <th>Vehicle Age</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Insurance Duration</th>\n",
       "      <th>Customer Feedback</th>\n",
       "      <th>Smoking Status</th>\n",
       "      <th>Exercise Frequency</th>\n",
       "      <th>Premium Amount</th>\n",
       "      <th>transformed_Annual_Income</th>\n",
       "      <th>Year</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Year_sin</th>\n",
       "      <th>Year_cos</th>\n",
       "      <th>Month_sin</th>\n",
       "      <th>Month_cos</th>\n",
       "      <th>Day_sin</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_name_April</th>\n",
       "      <th>Month_name_August</th>\n",
       "      <th>Month_name_December</th>\n",
       "      <th>Month_name_February</th>\n",
       "      <th>Month_name_January</th>\n",
       "      <th>Month_name_July</th>\n",
       "      <th>Month_name_June</th>\n",
       "      <th>Month_name_March</th>\n",
       "      <th>Month_name_May</th>\n",
       "      <th>Month_name_November</th>\n",
       "      <th>Month_name_October</th>\n",
       "      <th>Month_name_September</th>\n",
       "      <th>Day_of_week_Friday</th>\n",
       "      <th>Day_of_week_Monday</th>\n",
       "      <th>Day_of_week_Saturday</th>\n",
       "      <th>Day_of_week_Sunday</th>\n",
       "      <th>Day_of_week_Thursday</th>\n",
       "      <th>Day_of_week_Tuesday</th>\n",
       "      <th>Day_of_week_Wednesday</th>\n",
       "      <th>Income to Dependents Ratio</th>\n",
       "      <th>Income_per_Dependent</th>\n",
       "      <th>CreditScore_InsuranceDuration</th>\n",
       "      <th>Health_Risk_Score</th>\n",
       "      <th>Credit_Health_Score</th>\n",
       "      <th>Health_Age_Interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.598761</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2869.0</td>\n",
       "      <td>-0.596487</td>\n",
       "      <td>2023</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>-9.510565e-01</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.998717</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5024.5</td>\n",
       "      <td>5024.5</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>3.870062</td>\n",
       "      <td>8406.738970</td>\n",
       "      <td>429.376453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>15.569731</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1483.0</td>\n",
       "      <td>0.336563</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>-9.510565e-01</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7919.5</td>\n",
       "      <td>7919.5</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>4.221513</td>\n",
       "      <td>10805.393307</td>\n",
       "      <td>607.219509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.177549</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.140781</td>\n",
       "      <td>2023</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>-9.510565e-01</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6400.5</td>\n",
       "      <td>6400.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.641123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1085.083634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.938144</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>765.0</td>\n",
       "      <td>2.088459</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>47285.0</td>\n",
       "      <td>47285.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>4.453093</td>\n",
       "      <td>4014.298906</td>\n",
       "      <td>229.701027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.376094</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>0.555622</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>5.877853e-01</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>19825.5</td>\n",
       "      <td>19825.5</td>\n",
       "      <td>2392.0</td>\n",
       "      <td>3.981195</td>\n",
       "      <td>12184.903989</td>\n",
       "      <td>427.897966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   Age  Gender  Number of Dependents  Education Level  Health Score  \\\n",
       "0   0  19.0       1                   1.0                1     22.598761   \n",
       "1   1  39.0       1                   3.0                2     15.569731   \n",
       "2   2  23.0       0                   3.0                0     47.177549   \n",
       "3   3  21.0       0                   2.0                1     10.938144   \n",
       "4   4  21.0       0                   1.0                1     20.376094   \n",
       "\n",
       "   Policy Type  Previous Claims  Vehicle Age  Credit Score  \\\n",
       "0            2              2.0         17.0         372.0   \n",
       "1            1              1.0         12.0         694.0   \n",
       "2            2              1.0         14.0           NaN   \n",
       "3            0              1.0          0.0         367.0   \n",
       "4            2              0.0          8.0         598.0   \n",
       "\n",
       "   Insurance Duration  Customer Feedback  Smoking Status  Exercise Frequency  \\\n",
       "0                 5.0                0.0               0                   2   \n",
       "1                 2.0                1.0               1                   3   \n",
       "2                 3.0                2.0               1                   2   \n",
       "3                 1.0                0.0               1                   1   \n",
       "4                 4.0                0.0               1                   2   \n",
       "\n",
       "   Premium Amount  transformed_Annual_Income  Year  Day  Month  Week  \\\n",
       "0          2869.0                  -0.596487  2023   23     12    51   \n",
       "1          1483.0                   0.336563  2023   12      6    24   \n",
       "2           567.0                   0.140781  2023   30      9    39   \n",
       "3           765.0                   2.088459  2024   12      6    24   \n",
       "4          2022.0                   0.555622  2021    1     12    48   \n",
       "\n",
       "       Year_sin  Year_cos     Month_sin     Month_cos   Day_sin  ...  \\\n",
       "0 -9.510565e-01  0.309017 -2.449294e-16  1.000000e+00 -0.998717  ...   \n",
       "1 -9.510565e-01  0.309017  1.224647e-16 -1.000000e+00  0.651372  ...   \n",
       "2 -9.510565e-01  0.309017 -1.000000e+00 -1.836970e-16 -0.201299  ...   \n",
       "3 -2.449294e-16  1.000000  1.224647e-16 -1.000000e+00  0.651372  ...   \n",
       "4  5.877853e-01 -0.809017 -2.449294e-16  1.000000e+00  0.201299  ...   \n",
       "\n",
       "   Month_name_April  Month_name_August  Month_name_December  \\\n",
       "0             False              False                 True   \n",
       "1             False              False                False   \n",
       "2             False              False                False   \n",
       "3             False              False                False   \n",
       "4             False              False                 True   \n",
       "\n",
       "   Month_name_February  Month_name_January  Month_name_July  Month_name_June  \\\n",
       "0                False               False            False            False   \n",
       "1                False               False            False             True   \n",
       "2                False               False            False            False   \n",
       "3                False               False            False             True   \n",
       "4                False               False            False            False   \n",
       "\n",
       "   Month_name_March  Month_name_May  Month_name_November  Month_name_October  \\\n",
       "0             False           False                False               False   \n",
       "1             False           False                False               False   \n",
       "2             False           False                False               False   \n",
       "3             False           False                False               False   \n",
       "4             False           False                False               False   \n",
       "\n",
       "   Month_name_September  Day_of_week_Friday  Day_of_week_Monday  \\\n",
       "0                 False               False               False   \n",
       "1                 False               False                True   \n",
       "2                  True               False               False   \n",
       "3                 False               False               False   \n",
       "4                 False               False               False   \n",
       "\n",
       "   Day_of_week_Saturday  Day_of_week_Sunday  Day_of_week_Thursday  \\\n",
       "0                  True               False                 False   \n",
       "1                 False               False                 False   \n",
       "2                  True               False                 False   \n",
       "3                 False               False                 False   \n",
       "4                 False               False                 False   \n",
       "\n",
       "   Day_of_week_Tuesday  Day_of_week_Wednesday  Income to Dependents Ratio  \\\n",
       "0                False                  False                      5024.5   \n",
       "1                False                  False                      7919.5   \n",
       "2                False                  False                      6400.5   \n",
       "3                False                   True                     47285.0   \n",
       "4                False                   True                     19825.5   \n",
       "\n",
       "   Income_per_Dependent  CreditScore_InsuranceDuration  Health_Risk_Score  \\\n",
       "0                5024.5                         1860.0           3.870062   \n",
       "1                7919.5                         1388.0           4.221513   \n",
       "2                6400.5                            NaN           2.641123   \n",
       "3               47285.0                          367.0           4.453093   \n",
       "4               19825.5                         2392.0           3.981195   \n",
       "\n",
       "   Credit_Health_Score  Health_Age_Interaction  \n",
       "0          8406.738970              429.376453  \n",
       "1         10805.393307              607.219509  \n",
       "2                  NaN             1085.083634  \n",
       "3          4014.298906              229.701027  \n",
       "4         12184.903989              427.897966  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200000, 72), (800000, 71))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AbdML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../AbdML\"))\n",
    "\n",
    "from main import AbdBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200000, 71), (800000, 70))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m*** AbdBase ['V_1.3'] ***\n",
      "\n",
      "\u001b[31m *** Available Settings *** \n",
      "\n",
      "\u001b[31mAvailable Models: \u001b[36mLGBM, \u001b[36mCAT, \u001b[36mXGB, \u001b[36mVoting, \u001b[36mTABNET\n",
      "\u001b[31mAvailable Metrics: \u001b[36mroc_auc, \u001b[36maccuracy, \u001b[36mf1, \u001b[36mprecision, \u001b[36mrecall, \u001b[36mrmse, \u001b[36mwmae, \u001b[36mrmsle, \u001b[36mmae, \u001b[36mr2, \u001b[36mmse\n",
      "\u001b[31mAvailable Problem Types: \u001b[36mclassification, \u001b[36mregression\n",
      "\u001b[31mAvailable Fold Types: \u001b[36mSKF, \u001b[36mKF, \u001b[36mGKF, \u001b[36mGSKF, \u001b[36mRKF\n",
      "\u001b[31m\n",
      " *** Configuration *** \n",
      "\n",
      "\u001b[31mProblem Type Selected: \u001b[36mREGRESSION\n",
      "\u001b[31mMetric Selected: \u001b[36mRMSLE\n",
      "\u001b[31mFold Type Selected: \u001b[36mRKF\n",
      "\u001b[31mCalculate Train Probabilities: \u001b[36mFalse\n",
      "\u001b[31mCalculate Test Probabilities: \u001b[36mFalse\n",
      "\u001b[31mEarly Stopping: \u001b[36mTrue\n",
      "\u001b[31mGPU: \u001b[36mFalse\n"
     ]
    }
   ],
   "source": [
    "SEED = 2024\n",
    "n_splits = 10\n",
    "\n",
    "base = AbdBase(train_data=train, test_data=test, target_column='Premium Amount', gpu=False,\n",
    "                 problem_type=\"regression\", metric=\"rmsle\", seed=SEED,\n",
    "                 n_splits=n_splits, early_stop=True, num_classes=0, #cat_features = cat_c,\n",
    "                 fold_type='RKF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 03:59:17,820] A new study created in memory with name: no-name-dbd777b8-fe87-476c-8ffc-cb88de464c58\n",
      "Training Folds: 100%|██████████| 10/10 [02:08<00:00, 12.81s/it]\n",
      "[I 2024-12-27 04:01:25,998] Trial 0 finished with value: 1.0458 and parameters: {'num_leaves': 118, 'learning_rate': 0.07114476009343425, 'feature_fraction': 0.8720536237417198, 'bagging_fraction': 0.8146346649119967, 'bagging_freq': 6, 'min_data_in_leaf': 24, 'max_depth': -1, 'lambda_l1': 2.1423021757741068, 'lambda_l2': 0.10129197956845731, 'min_gain_to_split': 0.02607024758370768}. Best is trial 0 with value: 1.0458.\n",
      "Training Folds: 100%|██████████| 10/10 [01:21<00:00,  8.16s/it]\n",
      "[I 2024-12-27 04:02:47,663] Trial 1 finished with value: 1.0529 and parameters: {'num_leaves': 15, 'learning_rate': 0.0812324508558869, 'feature_fraction': 0.9179681421265244, 'bagging_fraction': 0.6687417180293094, 'bagging_freq': 6, 'min_data_in_leaf': 26, 'max_depth': 3, 'lambda_l1': 0.042051564509138675, 'lambda_l2': 0.01444525102276306, 'min_gain_to_split': 0.0038234752246751854}. Best is trial 0 with value: 1.0458.\n",
      "Training Folds: 100%|██████████| 10/10 [00:59<00:00,  5.92s/it]\n",
      "[I 2024-12-27 04:03:46,921] Trial 2 finished with value: 1.0954 and parameters: {'num_leaves': 188, 'learning_rate': 0.00026210878782654407, 'feature_fraction': 0.6965674483654352, 'bagging_fraction': 0.7234827275619211, 'bagging_freq': 8, 'min_data_in_leaf': 81, 'max_depth': 1, 'lambda_l1': 0.03725393839578886, 'lambda_l2': 0.09163741808778776, 'min_gain_to_split': 0.001238513729886093}. Best is trial 0 with value: 1.0458.\n",
      "Training Folds: 100%|██████████| 10/10 [01:25<00:00,  8.57s/it]\n",
      "[I 2024-12-27 04:05:12,635] Trial 3 finished with value: 1.0946 and parameters: {'num_leaves': 186, 'learning_rate': 0.00032476735706274504, 'feature_fraction': 0.6202729826779961, 'bagging_fraction': 0.974227356206172, 'bagging_freq': 12, 'min_data_in_leaf': 83, 'max_depth': 3, 'lambda_l1': 0.0003078651783619622, 'lambda_l2': 0.2637333993381525, 'min_gain_to_split': 0.007591104805282696}. Best is trial 0 with value: 1.0458.\n",
      "Training Folds: 100%|██████████| 10/10 [01:26<00:00,  8.70s/it]\n",
      "[I 2024-12-27 04:06:39,649] Trial 4 finished with value: 1.0862 and parameters: {'num_leaves': 45, 'learning_rate': 0.0030586566669785274, 'feature_fraction': 0.6106330420868968, 'bagging_fraction': 0.9547350016689365, 'bagging_freq': 7, 'min_data_in_leaf': 70, 'max_depth': 3, 'lambda_l1': 0.039841905944346875, 'lambda_l2': 0.05414413211338523, 'min_gain_to_split': 0.0023426581058204046}. Best is trial 0 with value: 1.0458.\n",
      "2024-12-27 04:06:39,649 - AbdBase - INFO - \u001b[31m--> Best Train Score for LGBM: \u001b[36m1.0373\n",
      "2024-12-27 04:06:39,650 - AbdBase - INFO - \u001b[31m--> Best Validation Score for LGBM: \u001b[36m1.0458\n",
      "2024-12-27 04:06:39,651 - AbdBase - INFO - \u001b[31m--> Best Parameters: \u001b[36m{'num_leaves': 118, 'learning_rate': 0.07114476009343425, 'feature_fraction': 0.8720536237417198, 'bagging_fraction': 0.8146346649119967, 'bagging_freq': 6, 'min_data_in_leaf': 24, 'max_depth': -1, 'lambda_l1': 2.1423021757741068, 'lambda_l2': 0.10129197956845731, 'min_gain_to_split': 0.02607024758370768}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 54s, sys: 25.6 s, total: 24min 20s\n",
      "Wall time: 7min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 118,\n",
       " 'learning_rate': 0.07114476009343425,\n",
       " 'feature_fraction': 0.8720536237417198,\n",
       " 'bagging_fraction': 0.8146346649119967,\n",
       " 'bagging_freq': 6,\n",
       " 'min_data_in_leaf': 24,\n",
       " 'max_depth': -1,\n",
       " 'lambda_l1': 2.1423021757741068,\n",
       " 'lambda_l2': 0.10129197956845731,\n",
       " 'min_gain_to_split': 0.02607024758370768}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_space = {\n",
    "    'estimators': 300,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': (10, 300),                        \n",
    "    'learning_rate': (1e-4, 1e-1),                  \n",
    "    'feature_fraction': (0.6, 1.0),                 \n",
    "    'bagging_fraction': (0.6, 1.0),                 \n",
    "    'bagging_freq': (5, 12),                        \n",
    "    'min_data_in_leaf': (10, 100),                  \n",
    "    'max_depth': (-1, 12),                          \n",
    "    'lambda_l1': (1e-4, 10.0),                      \n",
    "    'lambda_l2': (1e-4, 10.0),                      \n",
    "    'min_gain_to_split': (0.001, 0.1),\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "lgb_study = base.RUN_OPTUNA(\n",
    "    MODEL_NAME=\"LGBM\",\n",
    "    PARAMS=param_space,\n",
    "    DIRECTION='minimize',\n",
    "    TRIALS=5,\n",
    "    ENABLE_PRUNER=True,              # Early termination of ineffective attempts\n",
    "    PRUNER_PARAMS={'n_startup_trials': 3, 'n_warmup_steps': 3, 'interval_steps': 3},\n",
    "    y_log=True\n",
    ")\n",
    "\n",
    "lgb_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 10/10 [02:03<00:00, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Train RMSLE: 1.0373\n",
      "Overall OOF RMSLE: 1.0458 \n",
      "CPU times: user 7min 1s, sys: 5.78 s, total: 7min 7s\n",
      "Wall time: 2min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Params = lgb_study.best_params\n",
    "# Params['estimators'] = 1000\n",
    "\n",
    "Params = {\n",
    " 'estimators': 300,\n",
    " 'boosting_type': 'gbdt',\n",
    " 'num_leaves': 118,\n",
    " 'learning_rate': 0.07114476009343425,\n",
    " 'feature_fraction': 0.8720536237417198,\n",
    " 'bagging_fraction': 0.8146346649119967,\n",
    " 'bagging_freq': 6,\n",
    " 'min_data_in_leaf': 24,\n",
    " 'max_depth': -1,\n",
    " 'lambda_l1': 2.1423021757741068,\n",
    " 'lambda_l2': 0.10129197956845731,\n",
    " 'min_gain_to_split': 0.02607024758370768,\n",
    " 'n_jobs': -1\n",
    "}\n",
    "\n",
    "results_lgb = base.Train_ML(Params,'LGBM', e_stop=200, y_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([966.55530898, 734.93968814, 808.78972131, ..., 186.60993404,\n",
       "        759.51377062, 272.23902899]),\n",
       " array([827.78980521, 790.25433658, 793.97637455, ..., 805.35630968,\n",
       "        814.12190218, 787.19724619]),\n",
       " LGBMRegressor(bagging_fraction=0.8146346649119967, bagging_freq=6, device='cpu',\n",
       "               estimators=300, feature_fraction=0.8720536237417198,\n",
       "               lambda_l1=2.1423021757741068, lambda_l2=0.10129197956845731,\n",
       "               learning_rate=0.07114476009343425, min_data_in_leaf=24,\n",
       "               min_gain_to_split=0.02607024758370768, n_jobs=-1, num_leaves=118,\n",
       "               random_state=2024, verbose=-1),\n",
       " [LGBMRegressor(bagging_fraction=0.8146346649119967, bagging_freq=6, device='cpu',\n",
       "                estimators=300, feature_fraction=0.8720536237417198,\n",
       "                lambda_l1=2.1423021757741068, lambda_l2=0.10129197956845731,\n",
       "                learning_rate=0.07114476009343425, min_data_in_leaf=24,\n",
       "                min_gain_to_split=0.02607024758370768, n_jobs=-1, num_leaves=118,\n",
       "                random_state=2024, verbose=-1),\n",
       "  LGBMRegressor(bagging_fraction=0.8146346649119967, bagging_freq=6, device='cpu',\n",
       "                estimators=300, feature_fraction=0.8720536237417198,\n",
       "                lambda_l1=2.1423021757741068, lambda_l2=0.10129197956845731,\n",
       "                learning_rate=0.07114476009343425, min_data_in_leaf=24,\n",
       "                min_gain_to_split=0.02607024758370768, n_jobs=-1, num_leaves=118,\n",
       "                random_state=2024, verbose=-1),\n",
       "  LGBMRegressor(bagging_fraction=0.8146346649119967, bagging_freq=6, device='cpu',\n",
       "                estimators=300, feature_fraction=0.8720536237417198,\n",
       "                lambda_l1=2.1423021757741068, lambda_l2=0.10129197956845731,\n",
       "                learning_rate=0.07114476009343425, min_data_in_leaf=24,\n",
       "                min_gain_to_split=0.02607024758370768, n_jobs=-1, num_leaves=118,\n",
       "                random_state=2024, verbose=-1),\n",
       "  LGBMRegressor(bagging_fraction=0.8146346649119967, bagging_freq=6, device='cpu',\n",
       "                estimators=300, feature_fraction=0.8720536237417198,\n",
       "                lambda_l1=2.1423021757741068, lambda_l2=0.10129197956845731,\n",
       "                learning_rate=0.07114476009343425, min_data_in_leaf=24,\n",
       "                min_gain_to_split=0.02607024758370768, n_jobs=-1, num_leaves=118,\n",
       "                random_state=2024, verbose=-1),\n",
       "  LGBMRegressor(bagging_fraction=0.8146346649119967, bagging_freq=6, device='cpu',\n",
       "                estimators=300, feature_fraction=0.8720536237417198,\n",
       "                lambda_l1=2.1423021757741068, lambda_l2=0.10129197956845731,\n",
       "                learning_rate=0.07114476009343425, min_data_in_leaf=24,\n",
       "                min_gain_to_split=0.02607024758370768, n_jobs=-1, num_leaves=118,\n",
       "                random_state=2024, verbose=-1),\n",
       "  LGBMRegressor(bagging_fraction=0.8146346649119967, bagging_freq=6, device='cpu',\n",
       "                estimators=300, feature_fraction=0.8720536237417198,\n",
       "                lambda_l1=2.1423021757741068, lambda_l2=0.10129197956845731,\n",
       "                learning_rate=0.07114476009343425, min_data_in_leaf=24,\n",
       "                min_gain_to_split=0.02607024758370768, n_jobs=-1, num_leaves=118,\n",
       "                random_state=2024, verbose=-1),\n",
       "  LGBMRegressor(bagging_fraction=0.8146346649119967, bagging_freq=6, device='cpu',\n",
       "                estimators=300, feature_fraction=0.8720536237417198,\n",
       "                lambda_l1=2.1423021757741068, lambda_l2=0.10129197956845731,\n",
       "                learning_rate=0.07114476009343425, min_data_in_leaf=24,\n",
       "                min_gain_to_split=0.02607024758370768, n_jobs=-1, num_leaves=118,\n",
       "                random_state=2024, verbose=-1),\n",
       "  LGBMRegressor(bagging_fraction=0.8146346649119967, bagging_freq=6, device='cpu',\n",
       "                estimators=300, feature_fraction=0.8720536237417198,\n",
       "                lambda_l1=2.1423021757741068, lambda_l2=0.10129197956845731,\n",
       "                learning_rate=0.07114476009343425, min_data_in_leaf=24,\n",
       "                min_gain_to_split=0.02607024758370768, n_jobs=-1, num_leaves=118,\n",
       "                random_state=2024, verbose=-1),\n",
       "  LGBMRegressor(bagging_fraction=0.8146346649119967, bagging_freq=6, device='cpu',\n",
       "                estimators=300, feature_fraction=0.8720536237417198,\n",
       "                lambda_l1=2.1423021757741068, lambda_l2=0.10129197956845731,\n",
       "                learning_rate=0.07114476009343425, min_data_in_leaf=24,\n",
       "                min_gain_to_split=0.02607024758370768, n_jobs=-1, num_leaves=118,\n",
       "                random_state=2024, verbose=-1),\n",
       "  LGBMRegressor(bagging_fraction=0.8146346649119967, bagging_freq=6, device='cpu',\n",
       "                estimators=300, feature_fraction=0.8720536237417198,\n",
       "                lambda_l1=2.1423021757741068, lambda_l2=0.10129197956845731,\n",
       "                learning_rate=0.07114476009343425, min_data_in_leaf=24,\n",
       "                min_gain_to_split=0.02607024758370768, n_jobs=-1, num_leaves=118,\n",
       "                random_state=2024, verbose=-1)],\n",
       " '1.0458',\n",
       " '1.0373')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lgb\n",
    "\n",
    "# 1. OOF 에측결과, 2. test 예측결과, 3. 최종학습모델 4.fold별 모델 리스트, 5. OOF 스코어, 6. 학습데이터 스코어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Public Score : 1.04476"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 05:31:08,488] A new study created in memory with name: no-name-e5a97b98-2a66-46c7-924d-bb5e0f409fbf\n",
      "Training Folds: 100%|██████████| 10/10 [09:58<00:00, 59.86s/it]\n",
      "[I 2024-12-27 05:41:07,157] Trial 0 finished with value: 1.0703 and parameters: {'learning_rate': 0.0013292918943162175, 'depth': 12, 'l2_leaf_reg': 0.4570563099801455, 'bagging_temperature': 0.06251373574521749, 'random_strength': 0.004207988669606638, 'border_count': 66, 'colsample_bylevel': 0.6180690932801379}. Best is trial 0 with value: 1.0703.\n",
      "Training Folds: 100%|██████████| 10/10 [05:16<00:00, 31.66s/it]\n",
      "[I 2024-12-27 05:46:23,778] Trial 1 finished with value: 1.0523 and parameters: {'learning_rate': 0.0396760507705299, 'depth': 9, 'l2_leaf_reg': 0.3470266988650412, 'bagging_temperature': 0.00115279871282324, 'random_strength': 7.579479953348009, 'border_count': 218, 'colsample_bylevel': 0.6687417180293094}. Best is trial 1 with value: 1.0523.\n",
      "Training Folds: 100%|██████████| 10/10 [03:02<00:00, 18.29s/it]\n",
      "[I 2024-12-27 05:49:26,676] Trial 2 finished with value: 1.0914 and parameters: {'learning_rate': 0.0003511356313970409, 'depth': 4, 'l2_leaf_reg': 0.0033205591037519565, 'bagging_temperature': 0.03752055855124281, 'random_strength': 0.05342937261279776, 'border_count': 97, 'colsample_bylevel': 0.8201438828989662}. Best is trial 1 with value: 1.0523.\n",
      "Training Folds: 100%|██████████| 10/10 [03:23<00:00, 20.31s/it]\n",
      "[I 2024-12-27 05:52:49,810] Trial 3 finished with value: 1.0917 and parameters: {'learning_rate': 0.00026210878782654407, 'depth': 5, 'l2_leaf_reg': 0.0067890532716984855, 'bagging_temperature': 0.023345864076016236, 'random_strength': 1.382623217936987, 'border_count': 76, 'colsample_bylevel': 0.7802495332778758}. Best is trial 1 with value: 1.0523.\n",
      "Training Folds: 100%|██████████| 10/10 [02:37<00:00, 15.72s/it]\n",
      "[I 2024-12-27 05:55:27,047] Trial 4 finished with value: 1.0721 and parameters: {'learning_rate': 0.005987474910461402, 'depth': 3, 'l2_leaf_reg': 0.10907475835157694, 'bagging_temperature': 0.0032476735706274485, 'random_strength': 0.0018205657658407262, 'border_count': 244, 'colsample_bylevel': 0.9825971712021712}. Best is trial 1 with value: 1.0523.\n",
      "2024-12-27 05:55:27,048 - AbdBase - INFO - \u001b[31m--> Best Train Score for CAT: \u001b[36m1.0488\n",
      "2024-12-27 05:55:27,048 - AbdBase - INFO - \u001b[31m--> Best Validation Score for CAT: \u001b[36m1.0523\n",
      "2024-12-27 05:55:27,048 - AbdBase - INFO - \u001b[31m--> Best Parameters: \u001b[36m{'learning_rate': 0.0396760507705299, 'depth': 9, 'l2_leaf_reg': 0.3470266988650412, 'bagging_temperature': 0.00115279871282324, 'random_strength': 7.579479953348009, 'border_count': 218, 'colsample_bylevel': 0.6687417180293094}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 20min 15s, sys: 1min 32s, total: 1h 21min 47s\n",
      "Wall time: 24min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0396760507705299,\n",
       " 'depth': 9,\n",
       " 'l2_leaf_reg': 0.3470266988650412,\n",
       " 'bagging_temperature': 0.00115279871282324,\n",
       " 'random_strength': 7.579479953348009,\n",
       " 'border_count': 218,\n",
       " 'colsample_bylevel': 0.6687417180293094}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_space = {\n",
    "    \"iterations\":300,\n",
    "    \"learning_rate\": (1e-4, 1e-1),\n",
    "    \"depth\": (3, 12),\n",
    "    \"l2_leaf_reg\": (1e-4, 10.0),\n",
    "    \"bagging_temperature\": (1e-3, 1.0),\n",
    "    \"random_strength\": (1e-3, 10.0),\n",
    "    \"border_count\": (32, 255),\n",
    "    \"colsample_bylevel\": (0.6, 1.0),\n",
    "}\n",
    "\n",
    "cat_study = base.RUN_OPTUNA(\n",
    "    MODEL_NAME=\"CAT\",\n",
    "    PARAMS=param_space,\n",
    "    DIRECTION='minimize',\n",
    "    TRIALS=5,\n",
    "    ENABLE_PRUNER=True,              # Early termination of ineffective attempts\n",
    "    PRUNER_PARAMS={'n_startup_trials': 3, 'n_warmup_steps': 3, 'interval_steps': 3},\n",
    "    y_log=True\n",
    ")\n",
    "\n",
    "cat_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 10/10 [17:39<00:00, 105.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Train RMSLE: 1.0331\n",
      "Overall OOF RMSLE: 1.0470 \n",
      "CPU times: user 56min 24s, sys: 2min 26s, total: 58min 50s\n",
      "Wall time: 17min 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Params = cat_study.best_params\n",
    "Params['iterations'] = 1000\n",
    "\n",
    "results_cat = base.Train_ML(Params,'CAT', e_stop=200, y_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([948.54578956, 750.34836391, 804.01920793, ..., 183.65217835,\n",
       "        737.65949109, 290.38160347]),\n",
       " array([791.53121895, 777.52688274, 762.57050624, ..., 819.85472178,\n",
       "        799.67671511, 763.55549787]),\n",
       " <catboost.core.CatBoostRegressor at 0x7fe0ce627940>,\n",
       " [<catboost.core.CatBoostRegressor at 0x7fe0cd3fe770>,\n",
       "  <catboost.core.CatBoostRegressor at 0x7fe0ce208f40>,\n",
       "  <catboost.core.CatBoostRegressor at 0x7fe0cc8d7640>,\n",
       "  <catboost.core.CatBoostRegressor at 0x7fe0cc8d64a0>,\n",
       "  <catboost.core.CatBoostRegressor at 0x7fe0bed8c820>,\n",
       "  <catboost.core.CatBoostRegressor at 0x7fe0bedd87f0>,\n",
       "  <catboost.core.CatBoostRegressor at 0x7fe0ceb32200>,\n",
       "  <catboost.core.CatBoostRegressor at 0x7fe0ce9b84c0>,\n",
       "  <catboost.core.CatBoostRegressor at 0x7fe0bed8c760>,\n",
       "  <catboost.core.CatBoostRegressor at 0x7fe0ce627940>],\n",
       " '1.0470',\n",
       " '1.0331')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-27 06:13:50,513] A new study created in memory with name: no-name-f9b1792d-9712-40d4-b200-e6d54bff001d\n",
      "[I 2024-12-27 06:13:50,530] Trial 0 finished with value: 1.0457973797810431 and parameters: {'w1': 0.5738049154531849}. Best is trial 0 with value: 1.0457973797810431.\n",
      "[I 2024-12-27 06:13:50,543] Trial 1 finished with value: 1.0462403546306638 and parameters: {'w1': 0.2812729924615003}. Best is trial 0 with value: 1.0457973797810431.\n",
      "[I 2024-12-27 06:13:50,555] Trial 2 finished with value: 1.0457072389813378 and parameters: {'w1': 0.7136440114053322}. Best is trial 2 with value: 1.0457072389813378.\n",
      "[I 2024-12-27 06:13:50,567] Trial 3 finished with value: 1.0465784933914017 and parameters: {'w1': 0.14006825934310196}. Best is trial 2 with value: 1.0457072389813378.\n",
      "[I 2024-12-27 06:13:50,580] Trial 4 finished with value: 1.045693008461401 and parameters: {'w1': 0.7744819362300569}. Best is trial 4 with value: 1.045693008461401.\n",
      "[I 2024-12-27 06:13:50,591] Trial 5 finished with value: 1.046018561799615 and parameters: {'w1': 0.4003482272790616}. Best is trial 4 with value: 1.045693008461401.\n",
      "[I 2024-12-27 06:13:50,604] Trial 6 finished with value: 1.0462239142038587 and parameters: {'w1': 0.28914763740981164}. Best is trial 4 with value: 1.045693008461401.\n",
      "[I 2024-12-27 06:13:50,615] Trial 7 finished with value: 1.0456920138489552 and parameters: {'w1': 0.7865929400490812}. Best is trial 7 with value: 1.0456920138489552.\n",
      "[I 2024-12-27 06:13:50,628] Trial 8 finished with value: 1.0457085279054368 and parameters: {'w1': 0.7101308183556596}. Best is trial 7 with value: 1.0456920138489552.\n",
      "[I 2024-12-27 06:13:50,639] Trial 9 finished with value: 1.046608621182161 and parameters: {'w1': 0.12896194087502522}. Best is trial 7 with value: 1.0456920138489552.\n",
      "[I 2024-12-27 06:13:50,655] Trial 10 finished with value: 1.045756101159764 and parameters: {'w1': 0.9729960061535865}. Best is trial 7 with value: 1.0456920138489552.\n",
      "[I 2024-12-27 06:13:50,670] Trial 11 finished with value: 1.0457590549654345 and parameters: {'w1': 0.9768595189138414}. Best is trial 7 with value: 1.0456920138489552.\n",
      "[I 2024-12-27 06:13:50,684] Trial 12 finished with value: 1.0456917938443806 and parameters: {'w1': 0.8088782389918708}. Best is trial 12 with value: 1.0456917938443806.\n",
      "[I 2024-12-27 06:13:50,699] Trial 13 finished with value: 1.045694351414053 and parameters: {'w1': 0.8359405528550788}. Best is trial 12 with value: 1.0456917938443806.\n",
      "[I 2024-12-27 06:13:50,714] Trial 14 finished with value: 1.0458144212884866 and parameters: {'w1': 0.5561082343711856}. Best is trial 12 with value: 1.0456917938443806.\n",
      "[I 2024-12-27 06:13:50,730] Trial 15 finished with value: 1.0456972829893902 and parameters: {'w1': 0.8517159673226128}. Best is trial 12 with value: 1.0456917938443806.\n",
      "[I 2024-12-27 06:13:50,744] Trial 16 finished with value: 1.045750619286386 and parameters: {'w1': 0.6314414569819744}. Best is trial 12 with value: 1.0456917938443806.\n",
      "[I 2024-12-27 06:13:50,761] Trial 17 finished with value: 1.0459033301411702 and parameters: {'w1': 0.4790035185653304}. Best is trial 12 with value: 1.0456917938443806.\n",
      "[I 2024-12-27 06:13:50,780] Trial 18 finished with value: 1.0457040312139496 and parameters: {'w1': 0.8764401827487671}. Best is trial 12 with value: 1.0456917938443806.\n",
      "[I 2024-12-27 06:13:50,797] Trial 19 finished with value: 1.0457287780717697 and parameters: {'w1': 0.66644814724185}. Best is trial 12 with value: 1.0456917938443806.\n",
      "[I 2024-12-27 06:13:50,816] Trial 20 finished with value: 1.045714584031367 and parameters: {'w1': 0.9037787751089403}. Best is trial 12 with value: 1.0456917938443806.\n",
      "[I 2024-12-27 06:13:50,832] Trial 21 finished with value: 1.045693534364355 and parameters: {'w1': 0.769982188861038}. Best is trial 12 with value: 1.0456917938443806.\n",
      "[I 2024-12-27 06:13:50,847] Trial 22 finished with value: 1.0456916324186272 and parameters: {'w1': 0.7991948084299498}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:50,862] Trial 23 finished with value: 1.0469716837898222 and parameters: {'w1': 0.007843956329476431}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:50,878] Trial 24 finished with value: 1.0456919159724503 and parameters: {'w1': 0.7884445800656273}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:50,894] Trial 25 finished with value: 1.0457296350374916 and parameters: {'w1': 0.9332376980073045}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:50,910] Trial 26 finished with value: 1.0457582545712656 and parameters: {'w1': 0.6207847740951558}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:50,926] Trial 27 finished with value: 1.0457050146615685 and parameters: {'w1': 0.720064356233779}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:50,943] Trial 28 finished with value: 1.045908324788764 and parameters: {'w1': 0.47520563416616773}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:50,957] Trial 29 finished with value: 1.0457895492110951 and parameters: {'w1': 0.5824088724455385}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:50,973] Trial 30 finished with value: 1.0456923987263407 and parameters: {'w1': 0.8191540585527763}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:50,989] Trial 31 finished with value: 1.0456932712402585 and parameters: {'w1': 0.7721432085722575}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,006] Trial 32 finished with value: 1.0456916359999726 and parameters: {'w1': 0.8016641946736294}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,023] Trial 33 finished with value: 1.0457157190543733 and parameters: {'w1': 0.9062933796000348}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,039] Trial 34 finished with value: 1.0457099108592813 and parameters: {'w1': 0.7065062263232392}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,056] Trial 35 finished with value: 1.04582971839308 and parameters: {'w1': 0.5412331979126492}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,073] Trial 36 finished with value: 1.0457752020378033 and parameters: {'w1': 0.9965828709206703}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,088] Trial 37 finished with value: 1.0457001998226683 and parameters: {'w1': 0.7361057982426772}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,104] Trial 38 finished with value: 1.0460130578246092 and parameters: {'w1': 0.40375449345246583}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,120] Trial 39 finished with value: 1.0457331388333901 and parameters: {'w1': 0.6587760562999595}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,136] Trial 40 finished with value: 1.0456917020598424 and parameters: {'w1': 0.8059006266073457}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,152] Trial 41 finished with value: 1.045692991458022 and parameters: {'w1': 0.8254581574246804}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,168] Trial 42 finished with value: 1.0456917731460331 and parameters: {'w1': 0.7918618430834933}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,184] Trial 43 finished with value: 1.0457292488688765 and parameters: {'w1': 0.9325658825557203}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,198] Trial 44 finished with value: 1.0457001263826937 and parameters: {'w1': 0.8633380969594326}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,214] Trial 45 finished with value: 1.0457218339023566 and parameters: {'w1': 0.6796533511991792}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,229] Trial 46 finished with value: 1.0456964802549447 and parameters: {'w1': 0.7519928926032037}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,244] Trial 47 finished with value: 1.0456918632458825 and parameters: {'w1': 0.8105825817676535}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,259] Trial 48 finished with value: 1.045709445501293 and parameters: {'w1': 0.891513003867561}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,275] Trial 49 finished with value: 1.045744934936947 and parameters: {'w1': 0.9574970451083937}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,291] Trial 50 finished with value: 1.045763936709786 and parameters: {'w1': 0.6132415112242746}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,306] Trial 51 finished with value: 1.0456917339955025 and parameters: {'w1': 0.807082106947868}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,321] Trial 52 finished with value: 1.0456949232933141 and parameters: {'w1': 0.8395207919251421}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,336] Trial 53 finished with value: 1.0456916468675808 and parameters: {'w1': 0.7973193812300617}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,352] Trial 54 finished with value: 1.0456987923169765 and parameters: {'w1': 0.7416117730648953}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,368] Trial 55 finished with value: 1.045721278723211 and parameters: {'w1': 0.6807711994982653}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,384] Trial 56 finished with value: 1.0463086391405247 and parameters: {'w1': 0.24977836793524466}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,399] Trial 57 finished with value: 1.0456916488541395 and parameters: {'w1': 0.8030162284048857}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,414] Trial 58 finished with value: 1.045700141625491 and parameters: {'w1': 0.8633945893217141}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,429] Trial 59 finished with value: 1.0457231646606022 and parameters: {'w1': 0.9214760013603394}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,445] Trial 60 finished with value: 1.0457135191434774 and parameters: {'w1': 0.697644425984519}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,461] Trial 61 finished with value: 1.0456916870071853 and parameters: {'w1': 0.7949173099362669}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,476] Trial 62 finished with value: 1.0456963219359674 and parameters: {'w1': 0.7527863440981589}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,491] Trial 63 finished with value: 1.045696451616868 and parameters: {'w1': 0.8477794827987216}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,506] Trial 64 finished with value: 1.0456922228662742 and parameters: {'w1': 0.8168313130315312}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,521] Trial 65 finished with value: 1.045705912048489 and parameters: {'w1': 0.8819967498113155}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,536] Trial 66 finished with value: 1.0456917988278287 and parameters: {'w1': 0.7911506428991462}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,552] Trial 67 finished with value: 1.0456927227057302 and parameters: {'w1': 0.7772947466507376}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,567] Trial 68 finished with value: 1.0457421453226678 and parameters: {'w1': 0.6441030316200802}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,582] Trial 69 finished with value: 1.0457088814311077 and parameters: {'w1': 0.7091906741863647}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,597] Trial 70 finished with value: 1.045742251513491 and parameters: {'w1': 0.9535294030935124}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,612] Trial 71 finished with value: 1.0456916781708023 and parameters: {'w1': 0.7953406129991866}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,627] Trial 72 finished with value: 1.045695656846461 and parameters: {'w1': 0.8436820208013669}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,646] Trial 73 finished with value: 1.045701980377439 and parameters: {'w1': 0.7297502774670171}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,663] Trial 74 finished with value: 1.0456940759218827 and parameters: {'w1': 0.7659606129386286}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,678] Trial 75 finished with value: 1.0457086541791076 and parameters: {'w1': 0.8894714834270875}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,693] Trial 76 finished with value: 1.045691648362712 and parameters: {'w1': 0.8029761923986737}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,709] Trial 77 finished with value: 1.0456991693159492 and parameters: {'w1': 0.8596825519243168}. Best is trial 22 with value: 1.0456916324186272.\n",
      "[I 2024-12-27 06:13:51,725] Trial 78 finished with value: 1.045691631794929 and parameters: {'w1': 0.7993802602017795}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,741] Trial 79 finished with value: 1.0457021914453613 and parameters: {'w1': 0.7290342227686125}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,756] Trial 80 finished with value: 1.045776669467685 and parameters: {'w1': 0.5973375906072433}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,771] Trial 81 finished with value: 1.045691635683866 and parameters: {'w1': 0.7985548320675345}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,791] Trial 82 finished with value: 1.0456929693166324 and parameters: {'w1': 0.7748487854746179}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,807] Trial 83 finished with value: 1.045718421618622 and parameters: {'w1': 0.91204862266331}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,822] Trial 84 finished with value: 1.0456931693101479 and parameters: {'w1': 0.8270628709126377}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,838] Trial 85 finished with value: 1.0456956265496735 and parameters: {'w1': 0.7564406796059359}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,856] Trial 86 finished with value: 1.0456916795017885 and parameters: {'w1': 0.7952744715932277}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,873] Trial 87 finished with value: 1.0457021099754802 and parameters: {'w1': 0.8703042003377691}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,889] Trial 88 finished with value: 1.0457205358541983 and parameters: {'w1': 0.6822833097485614}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,908] Trial 89 finished with value: 1.0457076279111643 and parameters: {'w1': 0.7125692289811542}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,923] Trial 90 finished with value: 1.045835219458095 and parameters: {'w1': 0.5360849945414128}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,939] Trial 91 finished with value: 1.0456917358934124 and parameters: {'w1': 0.8071460937221947}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,954] Trial 92 finished with value: 1.0456949624415923 and parameters: {'w1': 0.8397539828056005}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,970] Trial 93 finished with value: 1.0456934969348095 and parameters: {'w1': 0.7702800774747873}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:51,988] Trial 94 finished with value: 1.0456916324350642 and parameters: {'w1': 0.80098052920229}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:52,008] Trial 95 finished with value: 1.0456937034539573 and parameters: {'w1': 0.8313894859509842}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:52,031] Trial 96 finished with value: 1.045699901082407 and parameters: {'w1': 0.7372344428216823}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:52,050] Trial 97 finished with value: 1.0459874934700013 and parameters: {'w1': 0.4199706617621648}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:52,067] Trial 98 finished with value: 1.0456916593365664 and parameters: {'w1': 0.7964016158743097}. Best is trial 78 with value: 1.045691631794929.\n",
      "[I 2024-12-27 06:13:52,087] Trial 99 finished with value: 1.045709793575349 and parameters: {'w1': 0.8923964284043182}. Best is trial 78 with value: 1.045691631794929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Weights: {'w1': 0.7993802602017795}\n",
      "Best RMSLE: 1.0457\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    global results_lgb, results_cat, train\n",
    "    \n",
    "    w1 = trial.suggest_float('w1', 0.0, 1.0)\n",
    "    w2 = 1.0 - w1\n",
    "    \n",
    "    ensemble_vote = (w1 * results_lgb[0]) + (w2 * results_cat[0])\n",
    "    rmsle = root_mean_squared_log_error(train['Premium Amount'], ensemble_vote)\n",
    "    \n",
    "    return rmsle\n",
    "\n",
    "study_vote = optuna.create_study(direction='minimize')\n",
    "study_vote.optimize(objective, n_trials=100)\n",
    "\n",
    "print(f\"Best Weights: {study_vote.best_params}\")\n",
    "print(f\"Best RMSLE: {study_vote.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = study_vote.best_params\n",
    "best_weights['w2'] = 1 - best_weights['w1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Metrics:\n",
      "-------------------------\n",
      "RMSE: 1.0457\n",
      "MAE: 621.1012\n",
      "R²: -0.1383\n"
     ]
    }
   ],
   "source": [
    "ensemble_vote = (best_weights['w1'] * results_lgb[0]) + (best_weights['w2'] * results_cat[0])\n",
    "\n",
    "rmse = root_mean_squared_log_error(train['Premium Amount'], ensemble_vote)\n",
    "mae = mean_absolute_error(train['Premium Amount'], ensemble_vote)\n",
    "r2 = r2_score(train['Premium Amount'], ensemble_vote)\n",
    "\n",
    "print(f\"\\nPerformance Metrics:\\n{'-'*25}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Premium Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200000</td>\n",
       "      <td>1102.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200001</td>\n",
       "      <td>1102.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1200002</td>\n",
       "      <td>1102.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200003</td>\n",
       "      <td>1102.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200004</td>\n",
       "      <td>1102.545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Premium Amount\n",
       "0  1200000        1102.545\n",
       "1  1200001        1102.545\n",
       "2  1200002        1102.545\n",
       "3  1200003        1102.545\n",
       "4  1200004        1102.545"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Premium Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200000</td>\n",
       "      <td>820.515617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200001</td>\n",
       "      <td>787.700958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1200002</td>\n",
       "      <td>787.675737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200003</td>\n",
       "      <td>803.375572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200004</td>\n",
       "      <td>757.157465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Premium Amount\n",
       "0  1200000      820.515617\n",
       "1  1200001      787.700958\n",
       "2  1200002      787.675737\n",
       "3  1200003      803.375572\n",
       "4  1200004      757.157465"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = (best_weights['w1'] * results_lgb[1]) + (best_weights['w2'] * results_cat[1])\n",
    "submission['Premium Amount'] = preds\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 19.8M/19.8M [00:00<00:00, 37.4MB/s]\n",
      "Successfully submitted to Regression with an Insurance Dataset"
     ]
    }
   ],
   "source": [
    "submission.to_csv('./data/04_01_AbdML.csv', index=False)\n",
    "!kaggle competitions submit -c playground-series-s4e12 -f \"./data/04_01_AbdML.csv\" -m \"04_01_AbdML_ensemble\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Public Score Comparison**\n",
    "\n",
    "- **Baseline Model:**\n",
    "  - **Public Score:** 1.04849  \n",
    "  - **Rank:** 498 / 1653 (30.12%)  \n",
    "\n",
    "- **Second Model (Feature Engineering + PowerTransformer):**\n",
    "  - **Public Score:** 1.04506  \n",
    "  - **Rank:** 334 / 1693 (19.72%)\n",
    "\n",
    "- **NaN (NA col + No imputer):**\n",
    "  - **Public Score:** 1.04496  \n",
    "  - **Rank:** 378 / 1895 (19.94%)\n",
    "\n",
    "- **Ensemble(lgbm + xgb + catboost):**\n",
    "  - **Public Score:** 1.04475  \n",
    "  - **Rank:** 346 / 1906 (18.15%)\n",
    "\n",
    "- **AbdML(RKF) + Ensemble(lgbm + catboost):**\n",
    "  - **Public Score:** 1.04473  \n",
    "  - **Rank:** 357 / 1951 (18.29%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
