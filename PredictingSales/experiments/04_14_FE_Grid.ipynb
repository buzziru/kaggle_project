{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "168f0516",
   "metadata": {},
   "source": [
    "# 데이터 전처리 방안 수정\n",
    "- 그리드 생성 로직 변경\n",
    "    - 테스트셋에 처음 등장하는 아이템에 대한 학습 : 테스트셋에 있는 아이템이 무조건 등장하도록\n",
    "    - sales_train은 무언가 팔린 기록이 있는 데이터 -> 아무것도 안 팔리는 상황을 학습하는데 부족\n",
    "    - shop 기준: 해당 월에 매출이 발생한 상점만 선택(폐업했거나 아직 개업 안 한 상점 제외)\n",
    "    - item 기준: 해당 월에 매출이 발생한 아이템 + test 셋에 있는 모든 아이템\n",
    "- 가격 변수 결측치를 ffill, bfill, 카테고리 평균 등으로 처리\n",
    "- 아이템 이름 전처리 -> platform_type, meta_type -> lag_1 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a157db",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308cc443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import calendar\n",
    "from collections import Counter\n",
    "import re\n",
    "from itertools import product\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn-v0_8-white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e46c19",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27bed89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/\"\n",
    "\n",
    "sales_train = pd.read_csv(data_path + 'sales_train.csv')\n",
    "items = pd.read_csv(data_path + 'items.csv')\n",
    "item_categories = pd.read_csv(data_path + 'item_categories.csv')\n",
    "shops = pd.read_csv(data_path + 'shops.csv')\n",
    "\n",
    "test = pd.read_csv(data_path + 'test.csv')\n",
    "sub = pd.read_csv(data_path + 'sample_submission.csv')\n",
    "\n",
    "# print('Before Filter ShopID:', len(sales_train))\n",
    "# unique_test_shop_id = test['shop_id'].unique()\n",
    "# sales_train = sales_train[sales_train['shop_id'].isin(unique_test_shop_id)]\n",
    "# print('After Filter ShopID :', len(sales_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71cd71cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def downcast(df, include_floats=None, verbose=True):\n",
    "#     start_memory = df.memory_usage().sum() / 1024**2\n",
    "    \n",
    "#     if include_floats is None:\n",
    "#         include_floats = []\n",
    "\n",
    "#     for col in df.columns:\n",
    "#         dtype_name = df[col].dtype.name\n",
    "        \n",
    "#         if dtype_name == 'object':\n",
    "#             pass\n",
    "            \n",
    "#         elif dtype_name == 'bool':\n",
    "#             df[col] = df[col].astype('int8')\n",
    "            \n",
    "#         elif dtype_name.startswith('int') or (df[col]%1==0).all():\n",
    "#             df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "            \n",
    "#         elif dtype_name.startswith('float'):\n",
    "#             if col in include_floats:\n",
    "#                 df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "\n",
    "#     end_memory = df.memory_usage().sum() / 1024**2\n",
    "#     if verbose:\n",
    "#         print(f\"Memory usage reduced from {start_memory:.2f} MB to {end_memory:.2f} MB\")\n",
    "        \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6b84a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast(df, verbose=True):\n",
    "    start_memory = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        dtype_name = df[col].dtype.name\n",
    "        if dtype_name == 'object':\n",
    "            pass\n",
    "        elif dtype_name == 'bool':\n",
    "            df[col] = df[col].astype('int8')\n",
    "        elif dtype_name.startswith('int') or (df[col]%1==0).all():\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "        elif dtype_name.startswith('float'):\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    end_memory = df.memory_usage().sum() / 1024**2\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Memory usage reduced from {start_memory:.2f} MB to {end_memory:.2f} MB\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c14f108",
   "metadata": {},
   "source": [
    "## Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117be2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train.loc[sales_train['shop_id']==0, 'shop_id'] = 57\n",
    "sales_train.loc[sales_train['shop_id']==1, 'shop_id'] = 58\n",
    "sales_train.loc[sales_train['shop_id']==10, 'shop_id'] = 11\n",
    "sales_train.loc[sales_train['shop_id']==39, 'shop_id'] = 40\n",
    "\n",
    "test.loc[test['shop_id']==0, 'shop_id'] = 57\n",
    "test.loc[test['shop_id']==1, 'shop_id'] = 58\n",
    "test.loc[test['shop_id']==10, 'shop_id'] = 11\n",
    "test.loc[test['shop_id']==39, 'shop_id'] = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd021178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # option1: by month\n",
    "# all_shops = sales_train['shop_id'].unique()\n",
    "# test_items = test['item_id'].unique()\n",
    "# all_months = sales_train['date_block_num'].unique()\n",
    "\n",
    "# matrix = []\n",
    "\n",
    "# for i in range(34):\n",
    "#     sales = sales_train[sales_train['date_block_num'] == i]\n",
    "#     shops_in_month = sales['shop_id'].unique()\n",
    "#     items_in_month = sales['item_id'].unique()\n",
    "    \n",
    "#     items_to_grid = np.unique(np.concatenate([items_in_month, test_items]))\n",
    "#     matrix.append(np.array(list(product([i], shops_in_month, items_to_grid)), dtype=np.int16))\n",
    "    \n",
    "# idx_features = ['date_block_num', 'shop_id', 'item_id']\n",
    "# train_matrix = pd.DataFrame(np.vstack(matrix), columns=idx_features)\n",
    "# train_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eef2c574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Matrix Table ==========\n",
      "   date_block_num  shop_id  item_id\n",
      "0               0       59    22154\n",
      "1               0       59     2552\n",
      "2               0       59     2554\n",
      "3               0       59     2555\n",
      "4               0       59     2564\n",
      "========== Matrix Table Info ==========\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15343898 entries, 0 to 18124908\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Dtype\n",
      "---  ------          -----\n",
      " 0   date_block_num  int32\n",
      " 1   shop_id         int32\n",
      " 2   item_id         int32\n",
      "dtypes: int32(3)\n",
      "memory usage: 292.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# option2: all items x all shops\n",
    "def create_grid(sales, test_df):\n",
    "    months = list(range(34))\n",
    "    # all_shops = sales['shop_id'].unique()\n",
    "    # all_items = sales['item_id'].unique()\n",
    "    grid = []\n",
    "    for month in months:\n",
    "        shops_in_month = sales.loc[sales['date_block_num'] == month, 'shop_id'].unique()\n",
    "        items_in_month = sales.loc[sales['date_block_num'] == month, 'item_id'].unique()\n",
    "        grid.append(np.array(list(product([month], shops_in_month, items_in_month)), dtype='int32'))\n",
    "\n",
    "    # 월별로 생성된 그리드를 결합\n",
    "    grid_df = pd.DataFrame(np.vstack(grid), columns=['date_block_num', 'shop_id', 'item_id'])\n",
    "    \n",
    "    # 테스트셋에만 존재하는 (상점, 아이템) 조합을 그리드에 추가\n",
    "    test_shops = test_df['shop_id'].unique()\n",
    "    test_items = test_df['item_id'].unique()\n",
    "    test_grid_addition = []\n",
    "    for month in months:\n",
    "        test_grid_addition.append(np.array(list(product([month], test_shops, test_items)), dtype='int32'))\n",
    "        \n",
    "    test_grid_df = pd.DataFrame(np.vstack(test_grid_addition), columns=['date_block_num', 'shop_id', 'item_id'])\n",
    "    full_grid = pd.concat([grid_df, test_grid_df], ignore_index=True, sort=False).drop_duplicates()\n",
    "\n",
    "    return full_grid\n",
    "\n",
    "\n",
    "train_matrix = create_grid(sales_train, test)\n",
    "idx_features = ['date_block_num', 'shop_id', 'item_id']\n",
    "print('='*10, 'Matrix Table', '='*10)\n",
    "print(train_matrix.head())\n",
    "print('='*10, 'Matrix Table Info', '='*10)\n",
    "print(train_matrix.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f820c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Origin\n",
    "# train = []\n",
    "\n",
    "# for i in sales_train['date_block_num'].unique():\n",
    "#     all_shop = sales_train.loc[sales_train['date_block_num'] == i, 'shop_id'].unique()\n",
    "#     all_item = sales_train.loc[sales_train['date_block_num'] == i, 'item_id'].unique()\n",
    "#     train.append(np.array(list(product([i], all_shop, all_item))))\n",
    "\n",
    "# # idx features        \n",
    "# idx_features = ['date_block_num', 'shop_id', 'item_id']\n",
    "# train = pd.DataFrame(np.vstack(train), columns=idx_features)\n",
    "\n",
    "# test['date_block_num'] = 34\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804866dc",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482696cc",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "- `-1` 같은 음수값은 반품을 의미할 수 있음. 제거하지 않고 `item_cnt_month`로 집계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a09d9a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before :  2935849\n",
      "After item_cnt_day :  2935847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After item_price :  2935844\n"
     ]
    }
   ],
   "source": [
    "print(\"Before : \",len(sales_train))\n",
    "sales_train = sales_train[sales_train['item_cnt_day'] < 1000]\n",
    "print(\"After item_cnt_day : \",len(sales_train))\n",
    "sales_train = sales_train[sales_train['item_price'] < 50000]\n",
    "print(\"After item_price : \",len(sales_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a3e92f",
   "metadata": {},
   "source": [
    "## Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac3579c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mean_features(df: pd.DataFrame, groupby_features: list, mean_feature_list: list = None):\n",
    "    col_name = [col for col in groupby_features if col != 'date_block_num']\n",
    "    base_name = '_'.join([col.replace('_id', '') for col in col_name])\n",
    "    feature_name = f'{base_name}_avg_date_sales'\n",
    "    \n",
    "    agg_rules = {\n",
    "        feature_name: ('item_cnt_month', 'mean')\n",
    "    }\n",
    "    group = df.groupby(groupby_features).agg(**agg_rules).reset_index()\n",
    "    df = df.merge(group, on=groupby_features, how='left')\n",
    "    del group\n",
    "    \n",
    "    if mean_feature_list is not None:\n",
    "        mean_feature_list.append(feature_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_lag_features(df: pd.DataFrame, key_features: list, lag_feature_cols: list, lag_period: list):\n",
    "    df_result = df.copy()\n",
    "\n",
    "    for i in lag_period:\n",
    "        df_lag = df[key_features + lag_feature_cols].copy()\n",
    "        df_lag['date_block_num'] += i\n",
    "        lag_col_names = {col: f'{col}_lag_{i}' for col in lag_feature_cols}\n",
    "        df_lag = df_lag.rename(columns=lag_col_names)\n",
    "        df_result = pd.merge(df_result, df_lag, on=key_features, how='left')\n",
    "\n",
    "    all_lag_cols = [f'{col}_lag_{i}' for col in lag_feature_cols for i in lag_period]\n",
    "    for col in all_lag_cols:\n",
    "        if 'cnt' in col or 'sales' in col:\n",
    "            df_result[col] = df_result[col].fillna(0)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba87c35",
   "metadata": {},
   "source": [
    "## shops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bfbb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 수정\n",
    "shops['city'] = shops['shop_name'].str.split(' ').str[0]\n",
    "shops.loc[shops['city'] == '!Якутск', 'city'] = 'Якутск'\n",
    "\n",
    "# 특수 상점(온라인/이동식)을 별도 도시 'Special'로 분류\n",
    "shops.loc[shops['city'].isin(['Выездная', 'Интернет-магазин']), 'city'] = 'Special'\n",
    "\n",
    "# 약어 및 오표기 수정\n",
    "shops.loc[shops['city'] == 'СПб', 'city'] = 'Санкт-Петербург'\n",
    "shops.loc[shops['city'] == 'Н.Новгород', 'city'] = 'НижнийНовгород'\n",
    "shops.loc[shops['city'] == 'РостовНаДону', 'city'] = 'Ростов-на-Дону'\n",
    "\n",
    "# 모스크바 위성 도시 통합\n",
    "moscow_satellite_cities = ['Жуковский', 'Мытищи', 'Химки', 'Чехов', 'Балашиха', 'Сергиев']\n",
    "shops.loc[shops['city'].isin(moscow_satellite_cities), 'city'] = 'МоскваОбласть'\n",
    "\n",
    "# 쇼핑몰/센터를 나타내는 러시아어 약어로 상점 구분\n",
    "# mall_keywords = ['ТЦ', 'ТРК', 'ТРЦ', 'MALL', 'Молл']\n",
    "# is_mall = shops['shop_name'].apply(lambda x: any(keyword in x for keyword in mall_keywords))\n",
    "\n",
    "# shops['shop_type'] = np.where(is_mall, 'Mall', 'Standalone')\n",
    "\n",
    "for col in ['city']: # , 'shop_type'\n",
    "    encoder = LabelEncoder()\n",
    "    shops[col] = encoder.fit_transform(shops[col])\n",
    "\n",
    "shops = shops.drop(columns=[\"shop_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c191f5a",
   "metadata": {},
   "source": [
    "## items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2788cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sale_mon = sales_train.groupby('item_id').agg({'date_block_num': 'min'})['date_block_num']\n",
    "items['first_sale_month'] = items['item_id'].map(first_sale_mon).fillna(34)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71168d01",
   "metadata": {},
   "source": [
    "##### 월별 아이템 평균가격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36cc6dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_item_avg_price = sales_train.groupby(['date_block_num', 'item_id']).agg(date_item_avg_price=('item_price', 'mean')).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19de8647",
   "metadata": {},
   "source": [
    "### meta, platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8be762a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('версия', 3599),\n",
       " ('pc', 2683),\n",
       " ('bd', 2322),\n",
       " ('цифровая', 2003),\n",
       " ('регион', 1849),\n",
       " ('2', 1821),\n",
       " ('русская', 1452),\n",
       " ('jewel', 1370),\n",
       " ('и', 1251),\n",
       " ('1', 1244),\n",
       " ('the', 1185),\n",
       " ('3', 1133),\n",
       " ('1с', 1120),\n",
       " ('cd', 1019),\n",
       " ('of', 955),\n",
       " ('в', 949),\n",
       " ('mp3', 948),\n",
       " ('dvd', 899),\n",
       " ('фирм', 757),\n",
       " ('xbox', 754),\n",
       " ('ps3', 735),\n",
       " ('edition', 681),\n",
       " ('фигурка', 667),\n",
       " ('для', 638),\n",
       " ('s', 615),\n",
       " ('коллекция', 576),\n",
       " ('360', 571),\n",
       " ('3d', 566),\n",
       " ('digipack', 553),\n",
       " ('4', 551),\n",
       " ('на', 535),\n",
       " ('lp', 524),\n",
       " ('с', 504),\n",
       " ('арт', 465),\n",
       " ('2cd', 452),\n",
       " ('a', 437),\n",
       " ('русские', 420),\n",
       " ('игра', 418),\n",
       " ('сб', 406),\n",
       " ('субтитры', 402),\n",
       " ('7', 367),\n",
       " ('v', 367),\n",
       " ('5', 356),\n",
       " ('футболка', 356),\n",
       " ('игрушка', 352),\n",
       " ('английская', 345),\n",
       " ('box', 336),\n",
       " ('набор', 334),\n",
       " ('8', 332),\n",
       " ('издание', 308)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9а-яА-Я\\s]', ' ', text) \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "items['cleaned_item_name'] = items['item_name'].apply(clean_text)\n",
    "all_words = ' '.join(items['cleaned_item_name'].values).split()\n",
    "Counter(all_words).most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83bc43f",
   "metadata": {},
   "source": [
    "- 대상이 되는 1C COMPANY는 게임 소프트웨어를 취급하는 러시아 기업\n",
    "- pc(2위), цифровая(디지털, 4위) -> 디지털 다운로드는 cd/dvd 제품과 판매형태가 전혀 다름. 온라인 위주로 판매될 것\n",
    "- xbox(19위), ps3는 콘솔게임기고 360(46위)도 xbox360 콘솔을 지칭하는 것으로 추정됨\n",
    "- jewel(8위, 저가판), dvd(18위), cd(14위), bd(블루레이 디스크, 3위), box(47위), edition(41위) 등은 제품형태를 뜻하는 걸로 보임\n",
    "    - 상대적으로 저렴한 저가판의 판매가 많고, 고가의 에디션은 판매량이 상대적으로 적을 것으로 추정\n",
    "- фигурка (피규어, 23위), футболка (티셔츠, 44위), игрушка (장난감, 45위) -> 게임 및 콘솔과 판매 패턴이 다를 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b18eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_platform(name):\n",
    "    if 'pc' in name or 'пк' in name: return 'PC'\n",
    "    if 'ps3' in name: return 'PS3'\n",
    "    if 'ps4' in name: return 'PS4'\n",
    "    if 'xbox' in name or 'x360' in name: return 'Xbox' # 360도 Xbox로 통합\n",
    "    if 'psp' in name: return 'PSP'\n",
    "    if 'vita' in name or 'psv' in name: return 'PSVita'\n",
    "    if 'wii' in name: return 'Wii'\n",
    "    if 'mac' in name: return 'Mac'\n",
    "    if 'android' in name: return 'Android'\n",
    "    return 'Etc'\n",
    "\n",
    "def get_meta_type(name):\n",
    "    # 디지털/버전 정보\n",
    "    if 'цифровая' in name or 'digital' in name: return 'Digital'\n",
    "    if 'версия' in name: return 'Version' # Version 보통 일반판   \n",
    "    # 실물 미디어\n",
    "    if 'bd' in name or 'blu-ray' in name: return 'BluRay'\n",
    "    if 'dvd' in name: return 'DVD'\n",
    "    if 'cd' in name: return 'CD'\n",
    "    if 'lp' in name: return 'Vinyl'\n",
    "    # 패키지 형태\n",
    "    if 'jewel' in name: return 'Jewel' # 저가판\n",
    "    if 'region' in name or 'регион' in name: return 'Region' # 현지화/지역한정\n",
    "    if 'edition' in name or 'издание' in name: return 'Edition' # 특별판 등\n",
    "    if 'box' in name: return 'Box'\n",
    "    # 굿즈\n",
    "    if 'фигурка' in name: return 'Figure'\n",
    "    if 'футболка' in name: return 'TShirt'\n",
    "    if 'игрушка' in name: return 'Toy'\n",
    "    if 'арт' in name: return 'Art'\n",
    "    return 'Normal'\n",
    "\n",
    "\n",
    "items['platform_type'] = items['cleaned_item_name'].apply(get_platform)\n",
    "items['meta_type'] = items['cleaned_item_name'].apply(get_meta_type)\n",
    "for col in ['platform_type', 'meta_type']:\n",
    "    items[col] = LabelEncoder().fit_transform(items[col])\n",
    "items = items.drop(columns=['item_name', 'cleaned_item_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385f2dc6",
   "metadata": {},
   "source": [
    "## item_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f8d1163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "Игры                15\n",
      "Книги               13\n",
      "Подарки             12\n",
      "Игровые консоли      8\n",
      "Аксессуары           7\n",
      "Музыка               6\n",
      "Программы            6\n",
      "Кино                 5\n",
      "Карты оплаты         4\n",
      "Служебные            2\n",
      "Чистые носители      2\n",
      "PC                   1\n",
      "Билеты (Цифра)       1\n",
      "Доставка товара      1\n",
      "Элементы питания     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def clean_category_type(df):\n",
    "    df['type'] = df['item_category_name'].apply(lambda x: x.split('-')[0].strip())\n",
    "    df['type'] = df['type'].apply(lambda x: 'Игры' if 'Игры' in x else x) # 모든 게임(PC, Android, Mac)을 'Игры'로 통합\n",
    "    df['type'] = df['type'].apply(lambda x: 'Карты оплаты' if 'Карты' in x else x) # 카드류 통합\n",
    "    df['type'] = df['type'].apply(lambda x: 'Чистые носители' if 'Чистые' in x else x) # 미디어류 통합\n",
    "    print(df['type'].value_counts())\n",
    "    common_types = df['type'].value_counts()\n",
    "    etc_types = common_types[common_types < 4].index.tolist()\n",
    "    df['type'] = df['type'].apply(lambda x: 'etc' if x in etc_types else x)\n",
    "    return df\n",
    "\n",
    "item_categories = clean_category_type(item_categories)\n",
    "item_categories['type'] = LabelEncoder().fit_transform(item_categories['type'])\n",
    "item_categories = item_categories.drop('item_category_name', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc65181",
   "metadata": {},
   "source": [
    "## revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2901cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train['revenue'] = sales_train['item_cnt_day'] * sales_train['item_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4b1772",
   "metadata": {},
   "source": [
    "## set up matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51330945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage reduced from 179.19 MB to 106.39 MB\n",
      "Memory usage reduced from 0.00 MB to 0.00 MB\n",
      "Memory usage reduced from 0.85 MB to 0.13 MB\n",
      "Memory usage reduced from 0.00 MB to 0.00 MB\n",
      "Memory usage reduced from 292.66 MB to 175.60 MB\n"
     ]
    }
   ],
   "source": [
    "data_files = [sales_train, shops, items, item_categories, train_matrix]\n",
    "for file in data_files:\n",
    "    file = downcast(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a7b659f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 최종 데이터 정보 ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15558098 entries, 0 to 15558097\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   date_block_num       int8   \n",
      " 1   shop_id              int8   \n",
      " 2   item_id              int16  \n",
      " 3   item_cnt_month       float16\n",
      " 4   transaction_cnt      float64\n",
      " 5   date_revenue         float64\n",
      " 6   city                 int8   \n",
      " 7   item_category_id     int8   \n",
      " 8   first_sale_month     int8   \n",
      " 9   platform_type        int8   \n",
      " 10  meta_type            int8   \n",
      " 11  date_item_avg_price  float64\n",
      " 12  type                 int8   \n",
      "dtypes: float16(1), float64(3), int16(1), int8(8)\n",
      "memory usage: 534.1 MB\n",
      "\n",
      "--- 최종 데이터 샘플 ---\n",
      "          date_block_num  shop_id  item_id  item_cnt_month  transaction_cnt  \\\n",
      "15558093              34       45    18454             0.0              0.0   \n",
      "15558094              34       45    16188             0.0              0.0   \n",
      "15558095              34       45    15757             0.0              0.0   \n",
      "15558096              34       45    19648             0.0              0.0   \n",
      "15558097              34       45      969             0.0              0.0   \n",
      "\n",
      "          date_revenue  city  item_category_id  first_sale_month  \\\n",
      "15558093           0.0    16                55                23   \n",
      "15558094           0.0    16                64                32   \n",
      "15558095           0.0    16                55                 0   \n",
      "15558096           0.0    16                40                23   \n",
      "15558097           0.0    16                37                17   \n",
      "\n",
      "          platform_type  meta_type  date_item_avg_price  type  \n",
      "15558093              1          9                  NaN     7  \n",
      "15558094              1          9                  NaN     8  \n",
      "15558095              1          9                  NaN     7  \n",
      "15558096              1         10                  NaN     5  \n",
      "15558097              1          1                  NaN     5  \n"
     ]
    }
   ],
   "source": [
    "# new grid\n",
    "group = sales_train.groupby(idx_features).agg(\n",
    "    item_cnt_month=('item_cnt_day', 'sum'),\n",
    "    transaction_cnt=('item_cnt_day', 'count'),\n",
    "    date_revenue=('revenue', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "train_matrix = train_matrix.merge(group, on=idx_features, how='left')\n",
    "train_matrix['item_cnt_month'] = train_matrix['item_cnt_month'].fillna(0) # 판매량 결측치\n",
    "train_matrix['item_cnt_month'] = train_matrix['item_cnt_month'].clip(0, 20) # 클리핑 미리\n",
    "\n",
    "# 메모리 최적화\n",
    "train_matrix['date_block_num'] = train_matrix['date_block_num'].astype(np.int8)\n",
    "train_matrix['shop_id'] = train_matrix['shop_id'].astype(np.int8)\n",
    "train_matrix['item_id'] = train_matrix['item_id'].astype(np.int16)\n",
    "train_matrix['item_cnt_month'] = train_matrix['item_cnt_month'].astype(np.float16)\n",
    "\n",
    "test['date_block_num'] = 34\n",
    "test['date_block_num'] = test['date_block_num'].astype(np.int8)\n",
    "test['shop_id'] = test['shop_id'].astype(np.int8)\n",
    "test['item_id'] = test['item_id'].astype(np.int16)\n",
    "test['item_cnt_month'] = 0.0\n",
    "test['item_cnt_month'] = test['item_cnt_month'].astype(np.float16)\n",
    "\n",
    "all_data = pd.concat([train_matrix, test.drop(columns=['ID'])], ignore_index=True, sort=False)\n",
    "all_data.fillna(0, inplace=True)\n",
    "all_data = all_data.merge(shops, on='shop_id', how='left')\n",
    "all_data = all_data.merge(items, on='item_id', how='left')\n",
    "all_data = all_data.merge(date_item_avg_price, on=['date_block_num', 'item_id'], how='left')\n",
    "all_data = all_data.merge(item_categories, on='item_category_id', how='left')\n",
    "\n",
    "# 최종 데이터 확인\n",
    "print(\"--- 최종 데이터 정보 ---\")\n",
    "all_data.info()\n",
    "print(\"\\n--- 최종 데이터 샘플 ---\")\n",
    "print(all_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35fecf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old grid\n",
    "# group = sales_train.groupby(idx_features).agg(\n",
    "#     item_cnt_month = ('item_cnt_day', 'sum'),\n",
    "#     transaction_cnt = ('item_cnt_day', 'count'),\n",
    "#     date_revenue = ('revenue', 'sum')\n",
    "# ).reset_index()\n",
    "\n",
    "# train = train.merge(group, on=idx_features, how='left')\n",
    "# all_data = pd.concat([train, test.drop('ID', axis=1)], ignore_index=True, keys=idx_features)\n",
    "# all_data = all_data.merge(shops, on='shop_id', how='left')\n",
    "# all_data = all_data.merge(items, on='item_id', how='left')\n",
    "# all_data = all_data.merge(date_item_avg_price, on=['date_block_num', 'item_id'], how='left')\n",
    "# all_data = all_data.merge(item_categories, on='item_category_id', how='left')\n",
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703232be",
   "metadata": {},
   "source": [
    "## fill nan price feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9948343b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_item_avg_price    4572549\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = all_data.isna().sum()\n",
    "temp[temp > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a882559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_price_nan(df):\n",
    "    # 처리할 모든 가격 관련 컬럼 식별\n",
    "    price_cols = ['date_item_avg_price'] + [col for col in df.columns if 'price_lag_' in col]\n",
    "\n",
    "    df = df.sort_values(by=['shop_id', 'item_id', 'date_block_num'])\n",
    "    df[price_cols] = df.groupby(['shop_id', 'item_id'])[price_cols].ffill()\n",
    "    # df[price_cols] = df.groupby(['shop_id', 'item_id'])[price_cols].bfill()\n",
    "\n",
    "    # 데이터 누수 최소화를 위해 기간 단축\n",
    "    train_data = df[df['date_block_num'] < 33]\n",
    "    # 아이템별 전체 평균\n",
    "    item_overall_avg_price_map = train_data.groupby('item_id')['date_item_avg_price'].mean()\n",
    "    # 카테고리별 전체 평균\n",
    "    cat_overall_avg_price_map = train_data.groupby('item_category_id')['date_item_avg_price'].mean()\n",
    "    # 전역 평균\n",
    "    global_avg_price = train_data['date_item_avg_price'].mean()\n",
    "    \n",
    "    for col in price_cols:\n",
    "        df[col].fillna(df['item_id'].map(item_overall_avg_price_map), inplace=True)\n",
    "        df[col].fillna(df['item_category_id'].map(cat_overall_avg_price_map), inplace=True)\n",
    "        df[col].fillna(global_avg_price, inplace=True)\n",
    "\n",
    "    del train_data, item_overall_avg_price_map, cat_overall_avg_price_map\n",
    "    gc.collect()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "all_data = fill_price_nan(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d906dc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage reduced from 652.84 MB to 534.14 MB\n"
     ]
    }
   ],
   "source": [
    "lag_1_list = []\n",
    "lag_3_list = []\n",
    "long_lag_list = []\n",
    "features_to_drop = []\n",
    "\n",
    "lag_3_list.extend(['transaction_cnt', 'date_item_avg_price'])\n",
    "long_lag_list.extend(['item_cnt_month'])\n",
    "\n",
    "all_data = downcast(all_data)\n",
    "del shops, items, item_categories, group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e5e48d",
   "metadata": {},
   "source": [
    "## month, days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb2e5f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.228580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.212143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.221940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.182514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.185639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.194358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.189267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.213281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.202719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.206917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.179649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.315950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  item_cnt_month\n",
       "0       0        0.228580\n",
       "1       1        0.212143\n",
       "2       2        0.221940\n",
       "3       3        0.182514\n",
       "4       4        0.185639\n",
       "5       5        0.194358\n",
       "6       6        0.189267\n",
       "7       7        0.213281\n",
       "8       8        0.202719\n",
       "9       9        0.206917\n",
       "10     10        0.179649\n",
       "11     11        0.315950"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['month'] = all_data['date_block_num'] % 12\n",
    "# days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "# all_data['days'] = all_data['month'].map(days).astype(np.int8)\n",
    "all_data.groupby('month')['item_cnt_month'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0177aa99",
   "metadata": {},
   "source": [
    "- 12월의 평균 판매량이 특히 높게 나타남. 1월도 비교적 높음\n",
    "- 3월과 9월의 평균 판매량이 상대적으로 높음(신학기 영향 예상)\n",
    "- 테스트 데이터에 해당하는 11월은 평균 판매량이 1년 중 가장 낮음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32fbd6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 0: Low (11월 포함), 1: Normal, 2: High, 3: Peak\n",
    "# season_dict = {\n",
    "#     11: 3, # 연말\n",
    "#     0: 2, 2: 2, 8: 2, # 0: 연초 / 2, 8: 신학기 \n",
    "#     7: 2, 1:2, # 7: 저조한 6대비 판매량 회복. 신학기 준비\n",
    "#     3: 1, 4: 1, 5: 1, 6:1, 9: 1, # 평범\n",
    "#     10: 0  # 6: 비수기, 휴가철 / 10: pre holiday\n",
    "# }\n",
    "\n",
    "# all_data['season_type'] = all_data['month'].map(season_dict).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8052871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_weekends(date_block_num):\n",
    "#     year = 2013 + date_block_num // 12\n",
    "#     month = 1 + date_block_num % 12\n",
    "    \n",
    "#     _, last_day = calendar.monthrange(year, month)\n",
    "#     dates = pd.date_range(start=f'{year}-{month}-01', end=f'{year}-{month}-{last_day}')\n",
    "#     weekend_count = dates.weekday.isin([5, 6]).sum()\n",
    "    \n",
    "#     return weekend_count\n",
    "\n",
    "# weekend_map = {i: count_weekends(i) for i in range(35)}\n",
    "# all_data['num_weekends'] = all_data['date_block_num'].map(weekend_map).astype('int8')\n",
    "# all_data[['date_block_num', 'month', 'num_weekends']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70e8a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data['num_weekends'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad7fe3",
   "metadata": {},
   "source": [
    "## mean features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d19420b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_block_num', 'shop_id', 'item_id', 'item_cnt_month',\n",
       "       'transaction_cnt', 'date_revenue', 'city', 'item_category_id',\n",
       "       'first_sale_month', 'platform_type', 'meta_type', 'date_item_avg_price',\n",
       "       'type', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "485107c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_feature_groups = [\n",
    "    ['date_block_num', 'shop_id'],\n",
    "    ['date_block_num', 'shop_id', 'item_category_id'],\n",
    "    ['date_block_num', 'shop_id', 'type'],\n",
    "    ['date_block_num', 'item_id'],\n",
    "    ['date_block_num', 'item_category_id'],\n",
    "    ['date_block_num', 'city', 'item_id'],\n",
    "    ['date_block_num', 'city', 'type'],\n",
    "    ['date_block_num', 'shop_id', 'platform_type'],\n",
    "    ['date_block_num', 'shop_id', 'meta_type'],\n",
    "]\n",
    "for group in mean_feature_groups:\n",
    "    all_data = add_mean_features(all_data, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f82d2d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Features: 8 ['shop_avg_date_sales', 'shop_item_category_avg_date_sales', 'shop_type_avg_date_sales', 'item_category_avg_date_sales', 'city_type_avg_date_sales', 'shop_platform_type_avg_date_sales', 'shop_meta_type_avg_date_sales', 'city_item_avg_date_sales']\n"
     ]
    }
   ],
   "source": [
    "mean_feature_list = [col for col in all_data.columns if '_avg_date_sales' in col and 'item_avg_date_sales' not in col]\n",
    "long_lag_list.append('item_avg_date_sales')\n",
    "mean_feature_list.append('city_item_avg_date_sales')\n",
    "print('Mean Features:', len(mean_feature_list), mean_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f67dfe",
   "metadata": {},
   "source": [
    "## shop revenue share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c304e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rev = all_data.groupby('date_block_num')['date_revenue'].sum().reset_index()\n",
    "total_rev.columns = ['date_block_num', 'total_revenue']\n",
    "\n",
    "shop_rev = all_data.groupby(['date_block_num', 'shop_id'])['date_revenue'].sum().reset_index()\n",
    "shop_rev.columns = ['date_block_num', 'shop_id', 'shop_revenue_month']\n",
    "\n",
    "shop_rev = pd.merge(shop_rev, total_rev, on='date_block_num', how='left')\n",
    "shop_rev['shop_revenue_share'] = shop_rev['shop_revenue_month'] / shop_rev['total_revenue']\n",
    "shop_rev['shop_revenue_share'] = shop_rev['shop_revenue_share'].fillna(0)\n",
    "\n",
    "all_data = pd.merge(all_data, shop_rev[['date_block_num', 'shop_id', 'shop_revenue_share']], on=['date_block_num', 'shop_id'], how='left')\n",
    "\n",
    "del total_rev, shop_rev\n",
    "gc.collect()\n",
    "lag_1_list.append('shop_revenue_share')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2244e811",
   "metadata": {},
   "source": [
    "## Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b37f525a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Lag Features: 2 ['item_cnt_month', 'item_avg_date_sales']\n",
      "Lag 1 Features: 9 ['shop_revenue_share', 'shop_avg_date_sales', 'shop_item_category_avg_date_sales', 'shop_type_avg_date_sales', 'item_category_avg_date_sales', 'city_type_avg_date_sales', 'shop_platform_type_avg_date_sales', 'shop_meta_type_avg_date_sales', 'city_item_avg_date_sales']\n",
      "Lag 3 Features: 2 ['transaction_cnt', 'date_item_avg_price']\n"
     ]
    }
   ],
   "source": [
    "lag_1_list.extend(mean_feature_list)\n",
    "print('Long Lag Features:', len(long_lag_list), long_lag_list)\n",
    "print('Lag 1 Features:', len(lag_1_list), lag_1_list)\n",
    "print('Lag 3 Features:', len(lag_3_list), lag_3_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c07a25ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_cnt_month', 'item_avg_date_sales']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_lag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3465e42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage reduced from 1617.27 MB to 1023.78 MB\n",
      "CPU times: user 2.49 s, sys: 816 ms, total: 3.31 s\n",
      "Wall time: 3.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_data = downcast(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c52f54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage reduced from 1557.92 MB to 1557.92 MB\n",
      "CPU times: user 16.5 s, sys: 4.11 s, total: 20.6 s\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_data = all_data.sort_values(by=['date_block_num', 'shop_id', 'item_id']).reset_index(drop=True)\n",
    "\n",
    "all_data = add_lag_features(all_data, \n",
    "                            key_features=idx_features,\n",
    "                            lag_feature_cols=lag_1_list,\n",
    "                            lag_period=[1])\n",
    "\n",
    "all_data = downcast(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e68a215c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage reduced from 2270.12 MB to 1958.53 MB\n",
      "CPU times: user 20.2 s, sys: 9.93 s, total: 30.1 s\n",
      "Wall time: 30.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_data = all_data.sort_values(by=['date_block_num', 'shop_id', 'item_id']).reset_index(drop=True)\n",
    "all_data = add_lag_features(all_data, \n",
    "                            key_features=idx_features,\n",
    "                            lag_feature_cols=lag_3_list,\n",
    "                            lag_period=[1, 2, 3])\n",
    "\n",
    "all_data = downcast(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfdd3a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.4 s, sys: 21.6 s, total: 49 s\n",
      "Wall time: 49.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_data = all_data.sort_values(by=['date_block_num', 'shop_id', 'item_id']).reset_index(drop=True)\n",
    "all_data = add_lag_features(all_data, \n",
    "                            key_features=idx_features,\n",
    "                            lag_feature_cols=long_lag_list,\n",
    "                            lag_period=[1,2,3,6,12])\n",
    "\n",
    "all_data['shop_revenue_share_lag_1'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1a6af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop.extend(lag_1_list)\n",
    "features_to_drop.extend(lag_3_list)\n",
    "features_to_drop.extend(long_lag_list)\n",
    "features_to_drop.remove('item_cnt_month')\n",
    "features_to_drop.remove('date_item_avg_price')\n",
    "\n",
    "all_data = all_data.drop(columns=features_to_drop)\n",
    "gc.collect()\n",
    "\n",
    "all_data = all_data.copy()\n",
    "features_to_drop = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4a4e8e",
   "metadata": {},
   "source": [
    "## price trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a13fca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_item_avg_price_lag_1    2287873\n",
       "date_item_avg_price_lag_2    2954060\n",
       "date_item_avg_price_lag_3    3612060\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = all_data.isna().sum()\n",
    "temp[temp > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9b7d592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_lag_cols = [col for col in all_data.columns if 'date_item_avg_price_lag' in col]\n",
    "all_data = fill_price_nan(all_data)\n",
    "\n",
    "temp = all_data.isna().sum()\n",
    "temp[temp > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dbf3ad13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>delta_price_lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10318199</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10327249</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10336299</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10345349</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10354399</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          item_id  date_block_num  delta_price_lag\n",
       "10318199        0              20              0.0\n",
       "10327249        0              20              0.0\n",
       "10336299        0              20              0.0\n",
       "10345349        0              20              0.0\n",
       "10354399        0              20              0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# price trend\n",
    "all_data = all_data.sort_values(by=['item_id', 'date_block_num'])\n",
    "df_temp = all_data[['item_id', 'date_item_avg_price']].copy()\n",
    "\n",
    "\n",
    "grp = df_temp.groupby('item_id')['date_item_avg_price']\n",
    "cumsum = grp.cumsum()\n",
    "cumcount = df_temp['date_item_avg_price'].notnull().astype(int).groupby(df_temp['item_id']).cumsum()\n",
    "df_temp['date_item_price_expanding_mean'] = cumsum / cumcount\n",
    "df_temp['date_item_price_expanding_mean'] = df_temp['date_item_price_expanding_mean'].shift(1)\n",
    "\n",
    "# 아이템 변경 지점 처리\n",
    "mask = df_temp['item_id'] != df_temp['item_id'].shift(1)\n",
    "df_temp.loc[mask, 'date_item_price_expanding_mean'] = 0\n",
    "all_data['item_avg_price_expanding'] = df_temp['date_item_price_expanding_mean']\n",
    "\n",
    "\n",
    "# 시나리오: expanding = 0 -> 미출시 혹은 신상품 -> nan -> 이전 시간 대비 가격변화 없음 -> 0으로 대체 \n",
    "temp_lag_1 = all_data['date_item_avg_price_lag_1'].fillna(all_data['item_avg_price_expanding'])\n",
    "all_data['delta_price_lag'] = (temp_lag_1 - all_data['item_avg_price_expanding']) / all_data['item_avg_price_expanding']\n",
    "all_data['delta_price_lag'] = all_data['delta_price_lag'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "del df_temp, grp, cumsum, cumcount, mask, temp_lag_1\n",
    "gc.collect()\n",
    "\n",
    "all_data[['item_id', 'date_block_num', 'delta_price_lag']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed660163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['delta_price_lag'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf09c89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5119012"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data[all_data['delta_price_lag']==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8468b3",
   "metadata": {},
   "source": [
    "## shop revenue trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eafe15a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>delta_shop_revenue_lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.588033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.054119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.076263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  date_block_num  delta_shop_revenue_lag\n",
       "0        2              20                0.000553\n",
       "1        2              15                0.588033\n",
       "2        2              18                0.054119\n",
       "3        2              19               -0.076263\n",
       "4        2              20                0.000553"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = all_data.sort_values(by=['shop_id', 'item_id', 'date_block_num'])\n",
    "\n",
    "all_shop = all_data['shop_id'].unique()\n",
    "all_months = all_data['date_block_num'].unique()\n",
    "full_shop_df = pd.DataFrame(list(product(all_shop, all_months)), columns=['shop_id', 'date_block_num'])\n",
    "\n",
    "shop_monthly_raw = all_data.groupby(['shop_id', 'date_block_num'])['date_revenue'].sum().reset_index().rename(columns={'date_revenue':'shop_revenue'})\n",
    "shop_monthly = full_shop_df.merge(shop_monthly_raw, on=['shop_id', 'date_block_num'], how='left')\n",
    "shop_monthly['shop_revenue'] = shop_monthly['shop_revenue'].fillna(0)\n",
    "\n",
    "shop_monthly = shop_monthly.sort_values(by=['shop_id', 'date_block_num'])\n",
    "grp = shop_monthly.groupby('shop_id')['shop_revenue']\n",
    "cumsum = grp.cumsum()\n",
    "cumcount = grp.cumcount() + 1\n",
    "shop_monthly['shop_rev_expanding_mean'] = cumsum / cumcount\n",
    "\n",
    "shop_monthly['shop_rev_expanding_mean'] = shop_monthly['shop_rev_expanding_mean'].shift(1)\n",
    "mask = shop_monthly['shop_id'] != shop_monthly['shop_id'].shift(1)\n",
    "shop_monthly.loc[mask, 'shop_rev_expanding_mean'] = 0\n",
    "shop_monthly['shop_rev_expanding_mean'] = shop_monthly['shop_rev_expanding_mean'].fillna(0)\n",
    "\n",
    "shop_monthly['shop_revenue_lag_1'] = grp.shift(1).fillna(0)\n",
    "shop_monthly['delta_shop_revenue_lag'] = (shop_monthly['shop_revenue_lag_1'] - shop_monthly['shop_rev_expanding_mean']) / shop_monthly['shop_rev_expanding_mean']\n",
    "shop_monthly['delta_shop_revenue_lag'] = shop_monthly['delta_shop_revenue_lag'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "all_data = pd.merge(all_data, shop_monthly[['shop_id', 'date_block_num', 'delta_shop_revenue_lag']], \n",
    "                    on=['shop_id', 'date_block_num'], how='left')\n",
    "\n",
    "del all_shop, all_months, full_shop_df, shop_monthly_raw, shop_monthly, grp, cumsum, cumcount, mask\n",
    "features_to_drop.append('date_revenue')\n",
    "gc.collect()\n",
    "all_data[['shop_id', 'date_block_num', 'delta_shop_revenue_lag']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde3fbd",
   "metadata": {},
   "source": [
    "## Item Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10d07a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_age\n",
    "all_data['item_age'] = all_data['date_block_num'] - all_data['first_sale_month']\n",
    "\n",
    "all_data.loc[all_data['item_age'] <= 0, 'item_age'] = 0 # 출시전 기간을 모두 0으로 처리 -> 출시(혹은 판매)까지 남은 기간을 모델이 알 수 없도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f61bf732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_age</th>\n",
       "      <th>item_shop_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  item_age  item_shop_age\n",
       "0              20         0            0.0\n",
       "1              15         0            0.0\n",
       "2              18         3            0.0\n",
       "3              19         4            0.0\n",
       "4              20         5            0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# item_shop_age\n",
    "shop_first_sale = sales_train.groupby(['shop_id', 'item_id'])['date_block_num'].min()\n",
    "all_data['item_shop_first_sale'] = all_data.set_index(['shop_id', 'item_id']).index.map(shop_first_sale)\n",
    "all_data['item_shop_first_sale'] = all_data['item_shop_first_sale'].fillna(34)\n",
    "all_data['item_shop_age'] = all_data['date_block_num'] - all_data['item_shop_first_sale']\n",
    "all_data.loc[all_data['item_shop_age'] <= 0, 'item_shop_age'] = 0\n",
    "\n",
    "features_to_drop.extend(['first_sale_month', 'item_shop_first_sale'])\n",
    "all_data[['date_block_num', 'item_age', 'item_shop_age']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bf76d6",
   "metadata": {},
   "source": [
    "## Last Sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f895b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = all_data[['date_block_num', 'shop_id', 'item_id', 'item_cnt_month']].copy()\n",
    "temp_df = temp_df.sort_values(by=['shop_id', 'item_id', 'date_block_num']).reset_index(drop=True)\n",
    "\n",
    "temp_df['item_shop_last_sale'] = np.nan\n",
    "temp_df.loc[temp_df['item_cnt_month'] > 0, 'item_shop_last_sale'] = temp_df['date_block_num']\n",
    "last_sale_record = temp_df.groupby(['item_id', 'shop_id'])['item_shop_last_sale'].shift(1).ffill()\n",
    "temp_df['item_shop_last_sale'] = (temp_df['date_block_num'] - last_sale_record)\n",
    "temp_df['item_shop_last_sale'] = temp_df['item_shop_last_sale'].fillna(-1)\n",
    "\n",
    "all_data = pd.merge(\n",
    "    all_data, \n",
    "    temp_df[['date_block_num', 'shop_id', 'item_id', 'item_shop_last_sale']],\n",
    "    on=['date_block_num', 'shop_id', 'item_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "del temp_df, last_sale_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0be2e3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   item_id  item_cnt_month  item_cnt_month_lag_1  decay_rate_feature  \\\n",
      "0        0               0                   0.0            0.000000   \n",
      "1        1               0                   0.0            0.000000   \n",
      "2        1               0                   0.0            0.000000   \n",
      "3        1               0                   0.0            0.005426   \n",
      "4        1               0                   0.0            0.005217   \n",
      "5        1               0                   0.0            0.004894   \n",
      "6        2               0                   0.0            0.000000   \n",
      "7        2               0                   0.0            0.000000   \n",
      "8        3               0                   0.0            0.000000   \n",
      "9        3               0                   0.0            0.041230   \n",
      "\n",
      "   item_age  item_shop_age  \n",
      "0         0            0.0  \n",
      "1         0            0.0  \n",
      "2         3            0.0  \n",
      "3         4            0.0  \n",
      "4         5            0.0  \n",
      "5         6            0.0  \n",
      "6         0            0.0  \n",
      "7         3            0.0  \n",
      "8         0            0.0  \n",
      "9         1            0.0  \n"
     ]
    }
   ],
   "source": [
    "# 출시 후 시간이 지날수록 판매량 가중치를 줄이는 피처\n",
    "temp_sales_proxy = np.where(\n",
    "    all_data['item_cnt_month_lag_1'] > 0, \n",
    "    all_data['item_cnt_month_lag_1'], \n",
    "    all_data['item_category_avg_date_sales_lag_1']\n",
    ")\n",
    "\n",
    "\n",
    "all_data['decay_rate_feature'] = temp_sales_proxy / (np.e + all_data['item_age'])\n",
    "print(all_data[['item_id', 'item_cnt_month', 'item_cnt_month_lag_1', 'decay_rate_feature', 'item_age', 'item_shop_age']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ce86a",
   "metadata": {},
   "source": [
    "## rolling mean/std & lag_1 and lag_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae0ff388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage reduced from 2833.94 MB to 1928.86 MB\n"
     ]
    }
   ],
   "source": [
    "all_data = all_data.drop(columns=features_to_drop)\n",
    "features_to_drop = []\n",
    "all_data = downcast(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bfc50231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage reduced from 2284.95 MB to 2166.25 MB\n"
     ]
    }
   ],
   "source": [
    "# 최근 3 평균 판매량 & 표준편차 item_cnt_month_lag\n",
    "all_data['rolling_3m_cnt_mean'] = all_data[['item_cnt_month_lag_1', 'item_cnt_month_lag_2', 'item_cnt_month_lag_3']].mean(axis=1)\n",
    "all_data['rolling_3m_cnt_std'] = all_data[['item_cnt_month_lag_1', 'item_cnt_month_lag_2', 'item_cnt_month_lag_3']].std(axis=1)\n",
    "\n",
    "# 최근 3개월 평균 item_avg_date_sales\n",
    "all_data['rolling_3m_item_mean'] = all_data[['item_avg_date_sales_lag_1', 'item_avg_date_sales_lag_2', 'item_avg_date_sales_lag_3']].mean(axis=1)\n",
    "all_data['rolling_3m_item_std'] = all_data[['item_avg_date_sales_lag_1', 'item_avg_date_sales_lag_2', 'item_avg_date_sales_lag_3']].std(axis=1)\n",
    "all_data = downcast(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "700cf149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage reduced from 2403.65 MB to 2344.30 MB\n"
     ]
    }
   ],
   "source": [
    "# 최근 3개월 월별 아이템 가격 평균 & 표준편차\n",
    "all_data['rolling_3m_price_mean'] = all_data[['date_item_avg_price_lag_1', 'date_item_avg_price_lag_2', 'date_item_avg_price_lag_3']].mean(axis=1)\n",
    "all_data['rolling_3m_price_std'] = all_data[['date_item_avg_price_lag_1', 'date_item_avg_price_lag_2', 'date_item_avg_price_lag_3']].std(axis=1)\n",
    "features_to_drop.extend(['date_item_avg_price'])\n",
    "all_data = downcast(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc41a9c",
   "metadata": {},
   "source": [
    "## items per transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d8852c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_col = ['item_cnt_month_lag_1', 'item_cnt_month_lag_2', 'item_cnt_month_lag_3']\n",
    "transaction_col = ['transaction_cnt_lag_1', 'transaction_cnt_lag_2', 'transaction_cnt_lag_3']\n",
    "new_cols_dict = {}\n",
    "\n",
    "for i in range(3):\n",
    "    col_name = f'items_per_transaction_lag_{i+1}'\n",
    "    new_series = all_data[sales_col[i]] / all_data[transaction_col[i]]\n",
    "    new_cols_dict[col_name] = new_series.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "all_data = all_data.assign(**new_cols_dict)\n",
    "all_data = all_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06945133",
   "metadata": {},
   "source": [
    "## removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b3817c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date_item_avg_price']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c4c0bbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date_item_avg_price_lag_2', 'date_item_avg_price_lag_3', 'item_avg_date_sales_lag_2', 'item_avg_date_sales_lag_3', 'item_cnt_month_lag_2', 'item_cnt_month_lag_3', 'items_per_transaction_lag_2', 'items_per_transaction_lag_3', 'transaction_cnt_lag_2', 'transaction_cnt_lag_3']\n"
     ]
    }
   ],
   "source": [
    "print(sorted([col for col in all_data.columns if '_lag_2' in col or '_lag_3' in col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "387dbdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping lag features: (15558098, 45)\n"
     ]
    }
   ],
   "source": [
    "all_data = all_data.drop(columns=features_to_drop)\n",
    "features_to_drop = []\n",
    "\n",
    "target_cols = [\n",
    "    col for col in all_data.columns \n",
    "    if re.search(r'_lag_[2-3]', col)\n",
    "]\n",
    "# 오래된 시차 변수들 제거\n",
    "features_to_drop.extend(target_cols)\n",
    "features_to_drop.remove('item_avg_date_sales_lag_2')\n",
    "features_to_drop.remove('item_cnt_month_lag_2')\n",
    "features_to_drop.remove('item_cnt_month_lag_3')\n",
    "features_to_drop.remove('transaction_cnt_lag_2')\n",
    "all_data = all_data.drop(columns=features_to_drop)\n",
    "\n",
    "print(\"Shape after dropping lag features:\", all_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fd53d7",
   "metadata": {},
   "source": [
    "## expanding means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_expanding_mean_features(df, group_cols, target_col='item_cnt_month'):\n",
    "    df = df.sort_values(by=['date_block_num', 'shop_id', 'item_id'])\n",
    "    \n",
    "    col_name = [col for col in group_cols if col != 'date_block_num']\n",
    "    base_name = '_'.join([col.replace('_id', '') for col in col_name])\n",
    "    feature_name = f'{base_name}_expanding_mean'\n",
    "    \n",
    "    grouped = df.groupby(group_cols)[target_col]\n",
    "    df[feature_name] = grouped.cumsum().shift(1) / grouped.cumcount().shift(1)\n",
    "    df[feature_name] = df[feature_name].fillna(0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ac4df5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage reduced from 2032.72 MB to 1973.37 MB\n"
     ]
    }
   ],
   "source": [
    "all_data = downcast(all_data)\n",
    "gc.collect()\n",
    "\n",
    "expanding_feature_groups = [\n",
    "    ['shop_id'],\n",
    "    ['item_category_id'],\n",
    "    ['item_id'],\n",
    "    ['shop_id', 'item_category_id'],\n",
    "]\n",
    "for group in expanding_feature_groups:\n",
    "    all_data = add_expanding_mean_features(all_data, group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16892cb1",
   "metadata": {},
   "source": [
    "## `date_block_num` >= 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7b090aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after filtering: (9020210, 49)\n"
     ]
    }
   ],
   "source": [
    "temp_all_data = all_data.copy()\n",
    "all_data = all_data[all_data['date_block_num']>=12]\n",
    "print(f\"Shape after filtering: {all_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "01ad9a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted([col for col in all_data.columns if 'item_name_svd_' not in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c63944da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city',\n",
       " 'city_item_avg_date_sales_lag_1',\n",
       " 'city_type_avg_date_sales_lag_1',\n",
       " 'date_block_num',\n",
       " 'date_item_avg_price_lag_1',\n",
       " 'decay_rate_feature',\n",
       " 'delta_price_lag',\n",
       " 'delta_shop_revenue_lag',\n",
       " 'item_age',\n",
       " 'item_avg_date_sales_lag_1',\n",
       " 'item_avg_date_sales_lag_12',\n",
       " 'item_avg_date_sales_lag_2',\n",
       " 'item_avg_date_sales_lag_6',\n",
       " 'item_avg_price_expanding',\n",
       " 'item_category_avg_date_sales_lag_1',\n",
       " 'item_category_expanding_mean',\n",
       " 'item_category_id',\n",
       " 'item_cnt_month',\n",
       " 'item_cnt_month_lag_1',\n",
       " 'item_cnt_month_lag_12',\n",
       " 'item_cnt_month_lag_2',\n",
       " 'item_cnt_month_lag_3',\n",
       " 'item_cnt_month_lag_6',\n",
       " 'item_expanding_mean',\n",
       " 'item_id',\n",
       " 'item_shop_age',\n",
       " 'item_shop_last_sale',\n",
       " 'items_per_transaction_lag_1',\n",
       " 'meta_type',\n",
       " 'month',\n",
       " 'platform_type',\n",
       " 'rolling_3m_cnt_mean',\n",
       " 'rolling_3m_cnt_std',\n",
       " 'rolling_3m_item_mean',\n",
       " 'rolling_3m_item_std',\n",
       " 'rolling_3m_price_mean',\n",
       " 'rolling_3m_price_std',\n",
       " 'shop_avg_date_sales_lag_1',\n",
       " 'shop_expanding_mean',\n",
       " 'shop_id',\n",
       " 'shop_item_category_avg_date_sales_lag_1',\n",
       " 'shop_item_category_expanding_mean',\n",
       " 'shop_meta_type_avg_date_sales_lag_1',\n",
       " 'shop_platform_type_avg_date_sales_lag_1',\n",
       " 'shop_revenue_share_lag_1',\n",
       " 'shop_type_avg_date_sales_lag_1',\n",
       " 'transaction_cnt_lag_1',\n",
       " 'transaction_cnt_lag_2',\n",
       " 'type']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([col for col in all_data.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a15801",
   "metadata": {},
   "source": [
    "## clip\n",
    "- 데이터에 대한 설명에 따라 상점별 아이템 월간 판매량에 대한 피처들을 (0, 20)으로 클립\n",
    "- 모델이 극단적인 값에 대해 학습하지 않도록 방지함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a877c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_clip =['item_cnt_month', 'item_cnt_month_lag_1', 'item_cnt_month_lag_12', 'item_cnt_month_lag_2', 'item_cnt_month_lag_3', \\\n",
    "      'item_cnt_month_lag_6', 'rolling_3m_cnt_mean',]\n",
    "\n",
    "for col in cols_to_clip:\n",
    "    all_data[col] = all_data[col].clip(0, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c251cd69",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "87f096d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9020210, 49)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c5a2091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = all_data.isna().sum()\n",
    "temp[temp > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e49404e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage reduced from 1488.21 MB to 1350.57 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./data/all_data1.joblib']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = downcast(all_data)\n",
    "joblib.dump(all_data, data_path + 'all_data1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a50c5003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_cnt_month\n",
       "0     7577139\n",
       "1      130668\n",
       "2       21346\n",
       "3        6481\n",
       "4        2669\n",
       "20       2620\n",
       "5        1284\n",
       "6         749\n",
       "7         471\n",
       "8         273\n",
       "9         175\n",
       "10        125\n",
       "11         82\n",
       "12         61\n",
       "13         45\n",
       "14         32\n",
       "15         26\n",
       "17         17\n",
       "19         15\n",
       "18         12\n",
       "16         10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.loc[(all_data['item_cnt_month_lag_1'] == all_data['item_cnt_month'])]['item_cnt_month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f4567bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8400180261878604"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_counts = all_data.loc[(all_data['item_cnt_month_lag_1'] == all_data['item_cnt_month'])]['item_cnt_month'].value_counts()\n",
    "same_counts[0] / len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad4220c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9020210 entries, 46 to 15558092\n",
      "Data columns (total 49 columns):\n",
      " #   Column                                   Dtype  \n",
      "---  ------                                   -----  \n",
      " 0   date_block_num                           int8   \n",
      " 1   shop_id                                  int8   \n",
      " 2   item_id                                  int16  \n",
      " 3   item_cnt_month                           int8   \n",
      " 4   city                                     int8   \n",
      " 5   item_category_id                         int8   \n",
      " 6   platform_type                            int8   \n",
      " 7   meta_type                                int8   \n",
      " 8   type                                     int8   \n",
      " 9   month                                    int8   \n",
      " 10  shop_revenue_share_lag_1                 float32\n",
      " 11  shop_avg_date_sales_lag_1                float32\n",
      " 12  shop_item_category_avg_date_sales_lag_1  float32\n",
      " 13  shop_type_avg_date_sales_lag_1           float32\n",
      " 14  item_category_avg_date_sales_lag_1       float32\n",
      " 15  city_type_avg_date_sales_lag_1           float32\n",
      " 16  shop_platform_type_avg_date_sales_lag_1  float32\n",
      " 17  shop_meta_type_avg_date_sales_lag_1      float32\n",
      " 18  city_item_avg_date_sales_lag_1           float32\n",
      " 19  transaction_cnt_lag_1                    int8   \n",
      " 20  date_item_avg_price_lag_1                float64\n",
      " 21  transaction_cnt_lag_2                    int8   \n",
      " 22  item_cnt_month_lag_1                     int8   \n",
      " 23  item_avg_date_sales_lag_1                float32\n",
      " 24  item_cnt_month_lag_2                     int8   \n",
      " 25  item_avg_date_sales_lag_2                float32\n",
      " 26  item_cnt_month_lag_3                     int8   \n",
      " 27  item_cnt_month_lag_6                     int8   \n",
      " 28  item_avg_date_sales_lag_6                float32\n",
      " 29  item_cnt_month_lag_12                    int8   \n",
      " 30  item_avg_date_sales_lag_12               float32\n",
      " 31  item_avg_price_expanding                 float64\n",
      " 32  delta_price_lag                          float32\n",
      " 33  delta_shop_revenue_lag                   float32\n",
      " 34  item_age                                 int8   \n",
      " 35  item_shop_age                            int8   \n",
      " 36  item_shop_last_sale                      int8   \n",
      " 37  decay_rate_feature                       float32\n",
      " 38  rolling_3m_cnt_mean                      float32\n",
      " 39  rolling_3m_cnt_std                       float32\n",
      " 40  rolling_3m_item_mean                     float32\n",
      " 41  rolling_3m_item_std                      float32\n",
      " 42  rolling_3m_price_mean                    float64\n",
      " 43  rolling_3m_price_std                     float32\n",
      " 44  items_per_transaction_lag_1              float32\n",
      " 45  shop_expanding_mean                      float32\n",
      " 46  item_category_expanding_mean             float32\n",
      " 47  item_expanding_mean                      float32\n",
      " 48  shop_item_category_expanding_mean        float32\n",
      "dtypes: float32(26), float64(3), int16(1), int8(19)\n",
      "memory usage: 1.3 GB\n"
     ]
    }
   ],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96ca93c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
